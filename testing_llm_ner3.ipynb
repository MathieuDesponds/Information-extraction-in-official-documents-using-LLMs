{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "[nltk_data] Downloading package punkt to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "ggml_init_cublas: found 1 CUDA devices:\n",
      "  Device 0: NVIDIA A40, compute capability 8.6\n",
      "llama_model_loader: loaded meta data with 20 key-value pairs and 291 tensors from llm/models/mistral-7b-v0.1/mistral-7b-v0.1.Q5_0.gguf (version GGUF V2 (latest))\n",
      "llama_model_loader: - tensor    0:                token_embd.weight q5_0     [  4096, 32000,     1,     1 ]\n",
      "llama_model_loader: - tensor    1:              blk.0.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor    2:              blk.0.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor    3:              blk.0.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor    4:         blk.0.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor    5:            blk.0.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor    6:              blk.0.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor    7:            blk.0.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor    8:           blk.0.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor    9:            blk.0.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   10:              blk.1.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   11:              blk.1.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   12:              blk.1.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   13:         blk.1.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   14:            blk.1.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   15:              blk.1.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   16:            blk.1.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   17:           blk.1.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   18:            blk.1.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   19:              blk.2.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   20:              blk.2.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   21:              blk.2.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   22:         blk.2.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   23:            blk.2.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   24:              blk.2.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   25:            blk.2.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   26:           blk.2.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   27:            blk.2.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   28:              blk.3.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   29:              blk.3.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   30:              blk.3.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   31:         blk.3.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   32:            blk.3.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   33:              blk.3.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   34:            blk.3.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   35:           blk.3.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   36:            blk.3.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   37:              blk.4.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   38:              blk.4.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   39:              blk.4.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   40:         blk.4.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   41:            blk.4.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   42:              blk.4.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   43:            blk.4.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   44:           blk.4.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   45:            blk.4.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   46:              blk.5.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   47:              blk.5.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   48:              blk.5.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   49:         blk.5.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   50:            blk.5.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   51:              blk.5.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   52:            blk.5.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   53:           blk.5.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   54:            blk.5.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   55:              blk.6.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   56:              blk.6.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   57:              blk.6.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   58:         blk.6.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   59:            blk.6.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   60:              blk.6.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   61:            blk.6.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   62:           blk.6.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   63:            blk.6.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   64:              blk.7.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   65:              blk.7.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   66:              blk.7.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   67:         blk.7.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   68:            blk.7.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   69:              blk.7.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   70:            blk.7.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   71:           blk.7.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   72:            blk.7.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   73:              blk.8.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   74:              blk.8.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   75:              blk.8.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   76:         blk.8.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   77:            blk.8.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   78:              blk.8.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   79:            blk.8.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   80:           blk.8.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   81:            blk.8.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   82:              blk.9.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   83:              blk.9.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   84:              blk.9.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   85:         blk.9.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   86:            blk.9.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   87:              blk.9.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   88:            blk.9.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   89:           blk.9.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   90:            blk.9.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   91:             blk.10.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   92:             blk.10.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   93:             blk.10.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   94:        blk.10.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   95:           blk.10.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   96:             blk.10.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   97:           blk.10.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   98:          blk.10.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   99:           blk.10.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  100:             blk.11.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  101:             blk.11.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  102:             blk.11.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  103:        blk.11.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  104:           blk.11.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  105:             blk.11.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  106:           blk.11.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  107:          blk.11.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  108:           blk.11.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  109:             blk.12.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  110:             blk.12.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  111:             blk.12.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  112:        blk.12.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  113:           blk.12.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  114:             blk.12.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  115:           blk.12.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  116:          blk.12.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  117:           blk.12.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  118:             blk.13.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  119:             blk.13.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  120:             blk.13.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  121:        blk.13.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  122:           blk.13.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  123:             blk.13.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  124:           blk.13.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  125:          blk.13.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  126:           blk.13.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  127:             blk.14.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  128:             blk.14.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  129:             blk.14.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  130:        blk.14.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  131:           blk.14.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  132:             blk.14.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  133:           blk.14.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  134:          blk.14.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  135:           blk.14.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  136:             blk.15.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  137:             blk.15.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  138:             blk.15.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  139:        blk.15.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  140:           blk.15.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  141:             blk.15.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  142:           blk.15.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  143:          blk.15.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  144:           blk.15.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  145:             blk.16.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  146:             blk.16.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  147:             blk.16.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  148:        blk.16.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  149:           blk.16.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  150:             blk.16.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  151:           blk.16.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  152:          blk.16.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  153:           blk.16.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  154:             blk.17.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  155:             blk.17.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  156:             blk.17.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  157:        blk.17.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  158:           blk.17.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  159:             blk.17.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  160:           blk.17.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  161:          blk.17.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  162:           blk.17.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  163:             blk.18.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  164:             blk.18.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  165:             blk.18.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  166:        blk.18.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  167:           blk.18.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  168:             blk.18.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  169:           blk.18.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  170:          blk.18.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  171:           blk.18.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  172:             blk.19.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  173:             blk.19.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  174:             blk.19.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  175:        blk.19.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  176:           blk.19.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  177:             blk.19.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  178:           blk.19.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  179:          blk.19.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  180:           blk.19.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  181:             blk.20.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  182:             blk.20.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  183:             blk.20.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  184:        blk.20.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  185:           blk.20.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  186:             blk.20.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  187:           blk.20.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  188:          blk.20.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  189:           blk.20.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  190:             blk.21.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  191:             blk.21.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  192:             blk.21.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  193:        blk.21.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  194:           blk.21.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  195:             blk.21.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  196:           blk.21.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  197:          blk.21.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  198:           blk.21.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  199:             blk.22.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  200:             blk.22.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  201:             blk.22.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  202:        blk.22.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  203:           blk.22.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  204:             blk.22.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  205:           blk.22.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  206:          blk.22.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  207:           blk.22.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  208:             blk.23.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  209:             blk.23.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  210:             blk.23.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  211:        blk.23.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  212:           blk.23.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  213:             blk.23.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  214:           blk.23.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  215:          blk.23.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  216:           blk.23.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  217:             blk.24.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  218:             blk.24.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  219:             blk.24.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  220:        blk.24.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  221:           blk.24.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  222:             blk.24.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  223:           blk.24.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  224:          blk.24.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  225:           blk.24.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  226:             blk.25.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  227:             blk.25.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  228:             blk.25.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  229:        blk.25.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  230:           blk.25.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  231:             blk.25.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  232:           blk.25.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  233:          blk.25.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  234:           blk.25.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  235:             blk.26.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  236:             blk.26.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  237:             blk.26.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  238:        blk.26.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  239:           blk.26.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  240:             blk.26.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  241:           blk.26.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  242:          blk.26.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  243:           blk.26.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  244:             blk.27.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  245:             blk.27.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  246:             blk.27.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  247:        blk.27.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  248:           blk.27.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  249:             blk.27.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  250:           blk.27.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  251:          blk.27.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  252:           blk.27.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  253:             blk.28.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  254:             blk.28.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  255:             blk.28.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  256:        blk.28.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  257:           blk.28.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  258:             blk.28.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  259:           blk.28.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  260:          blk.28.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  261:           blk.28.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  262:             blk.29.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  263:             blk.29.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  264:             blk.29.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  265:        blk.29.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  266:           blk.29.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  267:             blk.29.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  268:           blk.29.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  269:          blk.29.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  270:           blk.29.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  271:             blk.30.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  272:             blk.30.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  273:             blk.30.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  274:        blk.30.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  275:           blk.30.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  276:             blk.30.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  277:           blk.30.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  278:          blk.30.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  279:           blk.30.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  280:             blk.31.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  281:             blk.31.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  282:             blk.31.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  283:        blk.31.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  284:           blk.31.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  285:             blk.31.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  286:           blk.31.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  287:          blk.31.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  288:           blk.31.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  289:               output_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  290:                    output.weight q6_K     [  4096, 32000,     1,     1 ]\n",
      "llama_model_loader: - kv   0:                       general.architecture str     \n",
      "llama_model_loader: - kv   1:                               general.name str     \n",
      "llama_model_loader: - kv   2:                       llama.context_length u32     \n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32     \n",
      "llama_model_loader: - kv   4:                          llama.block_count u32     \n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32     \n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32     \n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32     \n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32     \n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32     \n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32     \n",
      "llama_model_loader: - kv  11:                          general.file_type u32     \n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str     \n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr     \n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr     \n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr     \n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32     \n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32     \n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32     \n",
      "llama_model_loader: - kv  19:               general.quantization_version u32     \n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q5_0:  225 tensors\n",
      "llama_model_loader: - type q6_K:    1 tensors\n",
      "llm_load_print_meta: format         = GGUF V2 (latest)\n",
      "llm_load_print_meta: arch           = llama\n",
      "llm_load_print_meta: vocab type     = SPM\n",
      "llm_load_print_meta: n_vocab        = 32000\n",
      "llm_load_print_meta: n_merges       = 0\n",
      "llm_load_print_meta: n_ctx_train    = 32768\n",
      "llm_load_print_meta: n_ctx          = 2048\n",
      "llm_load_print_meta: n_embd         = 4096\n",
      "llm_load_print_meta: n_head         = 32\n",
      "llm_load_print_meta: n_head_kv      = 8\n",
      "llm_load_print_meta: n_layer        = 32\n",
      "llm_load_print_meta: n_rot          = 128\n",
      "llm_load_print_meta: n_gqa          = 4\n",
      "llm_load_print_meta: f_norm_eps     = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps = 1.0e-05\n",
      "llm_load_print_meta: n_ff           = 14336\n",
      "llm_load_print_meta: freq_base      = 10000.0\n",
      "llm_load_print_meta: freq_scale     = 1\n",
      "llm_load_print_meta: model type     = 7B\n",
      "llm_load_print_meta: model ftype    = mostly Q5_0\n",
      "llm_load_print_meta: model params   = 7.24 B\n",
      "llm_load_print_meta: model size     = 4.65 GiB (5.52 BPW) \n",
      "llm_load_print_meta: general.name   = mistralai_mistral-7b-v0.1\n",
      "llm_load_print_meta: BOS token = 1 '<s>'\n",
      "llm_load_print_meta: EOS token = 2 '</s>'\n",
      "llm_load_print_meta: UNK token = 0 '<unk>'\n",
      "llm_load_print_meta: LF token  = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.09 MB\n",
      "llm_load_tensors: using CUDA for GPU acceleration\n",
      "llm_load_tensors: mem required  =   86.03 MB (+  256.00 MB per state)\n",
      "llm_load_tensors: offloading 32 repeating layers to GPU\n",
      "llm_load_tensors: offloading non-repeating layers to GPU\n",
      "llm_load_tensors: offloading v cache to GPU\n",
      "llm_load_tensors: offloading k cache to GPU\n",
      "llm_load_tensors: offloaded 35/35 layers to GPU\n",
      "llm_load_tensors: VRAM used: 4936 MB\n",
      "..................................................................................................\n",
      "llama_new_context_with_model: kv self size  =  256.00 MB\n",
      "llama_new_context_with_model: compute buffer total size =  153.47 MB\n",
      "llama_new_context_with_model: VRAM scratch buffer: 152.00 MB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with no-shots\n",
      "      and discussion\n",
      "./ner/saves/datasets/ontonote5_test_1403.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('one', 'CARDINAL'), ('thing', 'NORP')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:01<03:12,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('And', 'CARDINAL'), ('that', 'ORDINAL'), ('is', 'VERB'), ('the', 'STOPWORDS'), ('whole', 'NOUN'), ('notion', 'NOUN'), ('of', 'PREPOSITION'), ('the', 'STOPWORDS'), ('use', 'VERB'), ('and', 'CONJUNCTION'), ('abuse', 'VERB'), ('of', 'PREPOSITION'), ('confidential', 'ADJECTIVE'), ('sources', 'NOUN'), ('the', 'STOPWORDS'), ('protections', 'NOUN'), ('that', 'ORDINAL'), ('reporters', 'NOUN'), ('do', 'VERB'), ('or', 'CONJUNCTION'), ('don't', 'ADJECTIVE'), ('have', 'VERB'), ('and', 'CONJUNCTION'), ('the', 'STOPWORDS'), ('propensity', 'NOUN'), ('of', 'PREPOSITION'), ('uh', 'PR"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [00:10<09:39,  5.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [()]. Returned [('And', 'CARDINAL'), ('that', 'ORDINAL'), ('is', 'VERB'), ('the', 'STOPWORDS'), ('whole', 'NOUN'), ('notion', 'NOUN'), ('of', 'PREPOSITION'), ('the', 'STOPWORDS'), ('use', 'VERB'), ('and', 'CONJUNCTION'), ('abuse', 'VERB'), ('of', 'PREPOSITION'), ('confidential', 'ADJECTIVE'), ('sources', 'NOUN'), ('the', 'STOPWORDS'), ('protections', 'NOUN'), ('that', 'ORDINAL'), ('reporters', 'NOUN'), ('do', 'VERB'), ('or', 'CONJUNCTION'), ('don't', 'ADJECTIVE'), ('have', 'VERB'), ('and', 'CONJUNCTION'), ('the', 'STOPWORDS'), ('propensity', 'NOUN'), ('of', 'PREPOSITION'), ('uh', 'PR\n",
      "-----------------------------------------------\n",
      "('True', 'PERSON'), ('you', 'PRONOUN')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [00:11<06:04,  3.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('four', 'CARDINAL'), ('savings', 'PRODUCT')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [00:12<04:16,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('last', 'DATE'), ('week\\'s', 'ORDINAL')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [00:14<03:23,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('gasoline', 'PRODUCT'), ('picture', 'WORK_OF_ART')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/100 [00:15<02:53,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Watergate', 'GPE'), ('dirty', 'NORP')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/100 [00:16<02:31,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Mr.', 'PERSON'), ('Heinemann', 'PERSON'), ('changes', 'WORK_OF_ART'), ('represent', 'VERB'), ('a', 'STOPWORD'), ('magazine', 'PRODUCT'), (\"'s\", \"STOPWORD\"), ('net', 'QUANTITY'), ('revenue', 'MONEY'), ('per', 'PREPOSITION'), ('subscriber', 'PERSON'), (',', 'PUNCTUATION'), ('or', 'CONJUNCTION'), ('the', 'ARTICLE'), (\"'s\", \"STOPWORD\"), ('actual', 'ADJECTIVE'), ('revenue', 'MONEY'), ('from', 'PREPOSITION'), ('subscribers', 'PERSON'), (',', 'PUNCTUATION'), ('after', 'VERB'), ('discounts', 'QUANTITY'), ('and', 'CONJUNCTION'), ('the', 'ARTICLE'), (\"'s\", \"STOPWORD\"), ('cost', '"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/100 [00:24<05:49,  3.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [()]. Returned [('Mr.', 'PERSON'), ('Heinemann', 'PERSON'), ('changes', 'WORK_OF_ART'), ('represent', 'VERB'), ('a', 'STOPWORD'), ('magazine', 'PRODUCT'), (\"'s\", \"STOPWORD\"), ('net', 'QUANTITY'), ('revenue', 'MONEY'), ('per', 'PREPOSITION'), ('subscriber', 'PERSON'), (',', 'PUNCTUATION'), ('or', 'CONJUNCTION'), ('the', 'ARTICLE'), (\"'s\", \"STOPWORD\"), ('actual', 'ADJECTIVE'), ('revenue', 'MONEY'), ('from', 'PREPOSITION'), ('subscribers', 'PERSON'), (',', 'PUNCTUATION'), ('after', 'VERB'), ('discounts', 'QUANTITY'), ('and', 'CONJUNCTION'), ('the', 'ARTICLE'), (\"'s\", \"STOPWORD\"), ('cost', '\n",
      "-----------------------------------------------\n",
      "('Dongguan', 'GPE'), ('Chinese', 'NORP')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9/100 [00:26<04:35,  3.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Characters', 'NORP'), ('proliferate', 'VERB'), ('out', 'ADV'), ('of', 'PREPOSITION'), ('the', 'STOPWORDS'), ('imagination', 'NOUN'), ('of', 'PREPOSITION'), ('the', 'STOPWORDS'), ('narrator', 'PERSON'), ('so', 'CONJUNCTION'), ('that', 'ADV'), ('at', 'VERB'), ('a', 'DET'), ('certain', 'ADJECTIVE'), ('point', 'NOUN'), (',', 'PUNCTUATION'), ('you', 'PRONOUN'), ('have', 'AUXILIARY_VERBS'), ('a', 'DET'), ('new', 'ADJECTIVE'), ('he', 'PERSON'), ('you', 'PRONOUN'), ('have', 'AUXILIARY_VERBS'), ('a', 'DET'), ('new', 'ADJECTIVE'), ('she', 'PER"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/100 [00:34<07:10,  4.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [()]. Returned [('Characters', 'NORP'), ('proliferate', 'VERB'), ('out', 'ADV'), ('of', 'PREPOSITION'), ('the', 'STOPWORDS'), ('imagination', 'NOUN'), ('of', 'PREPOSITION'), ('the', 'STOPWORDS'), ('narrator', 'PERSON'), ('so', 'CONJUNCTION'), ('that', 'ADV'), ('at', 'VERB'), ('a', 'DET'), ('certain', 'ADJECTIVE'), ('point', 'NOUN'), (',', 'PUNCTUATION'), ('you', 'PRONOUN'), ('have', 'AUXILIARY_VERBS'), ('a', 'DET'), ('new', 'ADJECTIVE'), ('he', 'PERSON'), ('you', 'PRONOUN'), ('have', 'AUXILIARY_VERBS'), ('a', 'DET'), ('new', 'ADJECTIVE'), ('she', 'PER\n",
      "-----------------------------------------------\n",
      "('Christy', 'PERSON'), ('Whitman', 'PERSON')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 11/100 [00:35<05:21,  3.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Van Nuys', 'GPE'), ('Calif.', 'GPE'), ('Oklahoma City', 'GPE'), ('Pontiac', 'FAC')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 12/100 [00:37<04:34,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Shandong', 'GPE')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 13/100 [00:38<03:32,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Hence', 'TIME'), ('I', 'NORP'), ('think', 'VERB'), ('this', 'DET'), ('is', 'AUX'), ('a', 'DET'), ('test', 'WORK_OF_ART'), ('of', 'ADV'), ('e-government', 'PRODUCT'), ('because', 'CONJUNCTION'), (',', 'PUNCTUATION'), ('as', 'PRONOUN'), ('I', 'NORP'), ('remember', 'VERB'), ('during', 'PREPOSITION'), ('SARS', 'GPE'), ('in', 'IN'), ('2003', 'DATE'), (',', 'PUNCTUATION'), ('people', 'PRODUCT'), ('at', 'ADV'), ('that', 'PRONOUN'), ('time', 'TIME'), ('criticized', 'VERB'), ('e-government', 'PRODUCT'), ('during', 'PREPOSITION'), ('the"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 14/100 [00:47<06:05,  4.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [()]. Returned [('Hence', 'TIME'), ('I', 'NORP'), ('think', 'VERB'), ('this', 'DET'), ('is', 'AUX'), ('a', 'DET'), ('test', 'WORK_OF_ART'), ('of', 'ADV'), ('e-government', 'PRODUCT'), ('because', 'CONJUNCTION'), (',', 'PUNCTUATION'), ('as', 'PRONOUN'), ('I', 'NORP'), ('remember', 'VERB'), ('during', 'PREPOSITION'), ('SARS', 'GPE'), ('in', 'IN'), ('2003', 'DATE'), (',', 'PUNCTUATION'), ('people', 'PRODUCT'), ('at', 'ADV'), ('that', 'PRONOUN'), ('time', 'TIME'), ('criticized', 'VERB'), ('e-government', 'PRODUCT'), ('during', 'PREPOSITION'), ('the\n",
      "-----------------------------------------------\n",
      "('We', 'NORP'), ('are', 'VERB'), ('still', 'ADV'), ('in', 'PREP'), ('crisis', 'CARDINAL'), ('and', 'CONJ'), ('we', 'PRON'), ('will', 'AUX'), ('be', 'VERB'), ('I', 'PROPN'), ('think', 'VERB'), ('for', 'ADV'), ('a', 'DET'), ('while', 'SCONJ'), (',', 'PUNCT'), ('but', 'CCONJ'), ('the', 'ART'), ('current', 'ADJ'), ('crisis', 'NORP')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 15/100 [00:53<06:46,  4.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Christmas', 'DATE'), ('Linpien', 'GPE')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 16/100 [00:54<05:11,  3.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Beirut', 'GPE')] </stop_output>"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 17/100 [00:55<03:58,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Analysts', 'NORP'), ('oil', 'PRODUCT'), ('climb', 'TIME')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 18/100 [00:56<03:22,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Shanghai', 'GPE')] [('latest statistics', 'DATE')] [('218 trade - oriented companies and organizations abroad' , 'PRODUCT')] [('6 regional overseas group companies' , 'FAC')] [('it has approved overseas non-trade enterprises reaching 200 million US dollars .' , 'MONEY')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 19/100 [01:00<03:45,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Scooter', 'PERSON')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20/100 [01:01<02:57,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('six', 'NORP')] </output>"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 21/100 [01:02<02:22,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Royal', 'ORG'), ('Trustco', 'ORG'), ('Toronto', 'GPE')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 22/100 [01:03<02:13,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Mexico', 'GPE'), ('Treasury Department', 'ORG'), ('1997', 'DATE'), ('US dollars', 'MONEY')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 23/100 [01:05<02:22,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('month', 'DATE'), ('ago', 'TIME'), ('I', 'PERSON'), ('was', 'VERB'), ('really', 'ADV'), ('desperate', 'ADJP'), ('lost', 'VERB'), ('my', 'DET'), ('current', 'ADJ'), ('job', 'PRODUCT'), ('which', 'CONJ'), ('I', 'PERSON'), ('was', 'VERB'), ('completely', 'ADV'), ('unprepared', 'ADJP'), ('for', 'PREP'), (',', 'STOPWORDS'), ('and', 'CONJ'), ('had', 'AUX'), ('to', 'TO'), ('find', 'VERB'), ('a', 'DET'), ('job', 'PRODUCT'), ('within', 'ADV'), ('a', 'DET'), ('month', 'DATE'), ('to', 'TO'), ('keep', 'VERB'), ('myself', 'PRON'), ('going', 'VER"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 24/100 [01:14<04:56,  3.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [()]. Returned [('month', 'DATE'), ('ago', 'TIME'), ('I', 'PERSON'), ('was', 'VERB'), ('really', 'ADV'), ('desperate', 'ADJP'), ('lost', 'VERB'), ('my', 'DET'), ('current', 'ADJ'), ('job', 'PRODUCT'), ('which', 'CONJ'), ('I', 'PERSON'), ('was', 'VERB'), ('completely', 'ADV'), ('unprepared', 'ADJP'), ('for', 'PREP'), (',', 'STOPWORDS'), ('and', 'CONJ'), ('had', 'AUX'), ('to', 'TO'), ('find', 'VERB'), ('a', 'DET'), ('job', 'PRODUCT'), ('within', 'ADV'), ('a', 'DET'), ('month', 'DATE'), ('to', 'TO'), ('keep', 'VERB'), ('myself', 'PRON'), ('going', 'VER\n",
      "-----------------------------------------------\n",
      "('left', 'CARDINAL'), ('behind', 'LOC')] [('approximately', 'ORDINAL'), ('50 percent', 'PERCENT')] [('talked', 'TIME'), ('on the phone', 'FAC'), ('for three minutes or so', 'QUANTITY')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 25/100 [01:17<04:32,  3.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Pudong', 'FAC')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 26/100 [01:18<03:28,  2.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Analysts', 'ORG'), ('price', 'MONEY'), ('data', 'QUANTITY'), ('the', 'STOPWORDS'), ('grimmest', 'STOPWORDS'), ('inflation', 'EVENT'), ('news', 'WORK_OF_ART'), ('months', 'ORDINAL'), ('as', 'VERB'), ('evidence', 'PRODUCT'), ('that', 'CONJUNCTION'), ('the', 'STOPWORDS'), ('Federal', 'ORG'), ('Reserve', 'ORG'), ('was', 'VERB'), ('unlikely', 'ADJECTIVE'), ('to', 'PREPOSITION'), ('allow', 'VERB'), ('interest', 'MONEY'), ('rates', 'QUANTITY'), ('fall', 'VERB'), ('as', 'CONJUNCTION'), ('many', 'CARDINAL'), ('investors', 'ORG'), ('had', 'VERB'), ('hoped', 'WORK_OF_ART')"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 27/100 [01:26<05:30,  4.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [()]. Returned [('Analysts', 'ORG'), ('price', 'MONEY'), ('data', 'QUANTITY'), ('the', 'STOPWORDS'), ('grimmest', 'STOPWORDS'), ('inflation', 'EVENT'), ('news', 'WORK_OF_ART'), ('months', 'ORDINAL'), ('as', 'VERB'), ('evidence', 'PRODUCT'), ('that', 'CONJUNCTION'), ('the', 'STOPWORDS'), ('Federal', 'ORG'), ('Reserve', 'ORG'), ('was', 'VERB'), ('unlikely', 'ADJECTIVE'), ('to', 'PREPOSITION'), ('allow', 'VERB'), ('interest', 'MONEY'), ('rates', 'QUANTITY'), ('fall', 'VERB'), ('as', 'CONJUNCTION'), ('many', 'CARDINAL'), ('investors', 'ORG'), ('had', 'VERB'), ('hoped', 'WORK_OF_ART')\n",
      "-----------------------------------------------\n",
      "('I', 'PERSON'), ('think', 'VERB'), ('it', 'PRONOUN'), ('is', 'VERB'), ('a', 'DET'), ('measure', 'NOUN'), ('of', 'PREP'), ('how', 'ADV'), ('much', 'NUMERAL'), ('we', 'PRONOUN'), (\"'ve\", 'AUXILIARY_VERB'), ('kind', 'ADJ'), ('of', 'PREP'), ('lost', 'VERB'), (',', 'PUNCTUATION'), ('been', 'VERB'), ('numbed', 'NOUN'), ('by', 'PREP'), ('all', 'NUMERAL'), ('of', 'PREP'), ('this', 'PRONOUN'), (\"'ve\", 'AUXILIARY_VERB'), ('that', 'CONJUNCTION'), ('.', 'PUNCTUATION')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 28/100 [01:35<06:53,  5.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Young', 'ORG'), ('&', 'PRODUCT'), ('Rubicam', 'ORG')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 29/100 [01:37<05:18,  4.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Linpien', 'GPE')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 30/100 [01:37<03:55,  3.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('August', 'DATE'), ('23rd', 'ORDINAL')] [('US', 'GPE'), ('president', 'PERSON'), ('signed', 'VERB'), (\"'1995 financial year overseas activities fund appropriation act'\", 'WORK_OF_ART')] [('UN', 'ORG'), ('population fund', 'PRODUCT'), ('must not be used in China', 'QUANTITY')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 31/100 [01:42<04:11,  3.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Tianjin', 'GPE'), ('Port Bonded Area', 'FAC')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 32/100 [01:43<03:19,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('crude', 'PRODUCT')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 33/100 [01:44<02:35,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Weatherford', 'ORG'), ('preferred - dividend payment', 'MONEY')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 34/100 [01:45<02:16,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('bonded', 'FAC'), ('zone', 'FAC')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 35/100 [01:47<01:57,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Oklahoma City', 'GPE'), ('A-body mid-sized cars', 'PRODUCT')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 36/100 [01:48<01:49,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('four', 'CARDINAL'), ('dissenters', 'PERSON')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 37/100 [01:49<01:35,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Li', 'PERSON'), ('Yung', 'PERSON')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 38/100 [01:50<01:27,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Brazil', 'GPE')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 39/100 [01:51<01:17,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('$', 'MONEY'), ('60', 'CARDINAL')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 40/100 [01:52<01:16,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Pursuing', 'NORP'), ('some', 'STOPWORDS'), ('dream', 'STOPWORDS'), ('of', 'STOPWORDS'), ('really', 'STOPWORDS'), ('making', 'STOPWORDS'), ('it', 'STOPWORDS'), ('big' , 'STOPWORDS')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 41/100 [01:56<01:47,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Beijing', 'GPE')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 42/100 [01:56<01:29,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('boundless', 'QUANTITY'), ('industrial park', 'FAC')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 43/100 [01:58<01:23,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('scale', 'QUANTITY'), ('our', 'NORP'), ('urbanization', 'GPE'), ('1', 'CARDINAL'), ('%', 'PERCENT')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 44/100 [02:00<01:31,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('POW', 'ORG')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 45/100 [02:01<01:18,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Arianna Huffington', 'PERSON'), ('Times piece', 'ORG'), ('lengthy piece', 'WORK_OF_ART'), ('Judy Miller', 'PERSON'), ('WMD reporting', 'PRODUCT')] /. "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 46/100 [02:03<01:37,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('He', 'PERSON'), ('sat', 'VERB'), ('out', 'VERB'), ('1', 'CARDINAL'), ('term', 'WORK_OF_ART'), ('after', 'PREP'), ('losing', 'VERB'), ('a', 'DET'), ('U.S.', 'ORG'), ('Senate', 'PRODUCT'), ('race', 'NOUN'), ('in', 'INFINITIVE'), ('the', 'DET'), ('1960s', 'DATE'), (',', 'PUNCTUATION'), ('but', 'CONJ'), ('for', 'PREP'), ('24', 'CARDINAL'), ('terms', 'NOUN'), (',', 'PUNCTUATION'), ('Yates', 'PERSON'), ('represented', 'VERB'), ('Chicago\\'s', 'DET'), ('northern', 'ADJ'), ('lake', 'WORK_OF_ART'), ('front', '"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 47/100 [02:12<03:23,  3.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [()]. Returned [('He', 'PERSON'), ('sat', 'VERB'), ('out', 'VERB'), ('1', 'CARDINAL'), ('term', 'WORK_OF_ART'), ('after', 'PREP'), ('losing', 'VERB'), ('a', 'DET'), ('U.S.', 'ORG'), ('Senate', 'PRODUCT'), ('race', 'NOUN'), ('in', 'INFINITIVE'), ('the', 'DET'), ('1960s', 'DATE'), (',', 'PUNCTUATION'), ('but', 'CONJ'), ('for', 'PREP'), ('24', 'CARDINAL'), ('terms', 'NOUN'), (',', 'PUNCTUATION'), ('Yates', 'PERSON'), ('represented', 'VERB'), ('Chicago\\'s', 'DET'), ('northern', 'ADJ'), ('lake', 'WORK_OF_ART'), ('front', '\n",
      "-----------------------------------------------\n",
      "('Time', 'ORG')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 48/100 [02:13<02:33,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Today', 'DATE'), ('Brown', 'PERSON'), ('Westinghouse', 'PRODUCT'), ('Shanghai Electric Group', 'FAC'), ('General Electric Capital Company', 'ORG')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 49/100 [02:15<02:21,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('FBI', 'ORG'), ('Yemen', 'GPE')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50/100 [02:16<01:55,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Export', 'NORP'), ('credits', 'MONEY'), ('international', 'GPE'), ('financing', 'LAW'), ('leaseholds', 'FAC'), ('compensation', 'QUANTITY'), ('trades', 'PRODUCT'), ('with', 'VERB'), ('foreign', 'NORP'), ('exchange', 'MONEY'), ('repayment', 'PERCENT'), ('methods', 'LAW'), ('overseas', 'GPE'), ('institution''s', 'ORG'), ('and', 'CONJUNCTION'), ('individual ''s', 'NORP'), ('foreign', 'NORP'), ('exchange', 'MONEY'), ('deposits', 'QUANTITY'), ('-LRB-', 'STOPWORDS'), ('excluding', 'VERB'), ('foreign', 'NORP'), ('exchange', 'MONEY'), ('deposits', 'QUANTITY'),"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 51/100 [02:25<03:30,  4.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [()]. Returned [('Export', 'NORP'), ('credits', 'MONEY'), ('international', 'GPE'), ('financing', 'LAW'), ('leaseholds', 'FAC'), ('compensation', 'QUANTITY'), ('trades', 'PRODUCT'), ('with', 'VERB'), ('foreign', 'NORP'), ('exchange', 'MONEY'), ('repayment', 'PERCENT'), ('methods', 'LAW'), ('overseas', 'GPE'), ('institution''s', 'ORG'), ('and', 'CONJUNCTION'), ('individual ''s', 'NORP'), ('foreign', 'NORP'), ('exchange', 'MONEY'), ('deposits', 'QUANTITY'), ('-LRB-', 'STOPWORDS'), ('excluding', 'VERB'), ('foreign', 'NORP'), ('exchange', 'MONEY'), ('deposits', 'QUANTITY'),\n",
      "-----------------------------------------------\n",
      "('We', 'NORP')] [('are', 'VERB')] [('currently', 'ADV')] [('re-evaluating', 'VERB')] [('our', 'PRON')] [('positions' , 'PRODUCT')] [(',', 'STOPWORDS')] [('we', 'NORP')] [('want', 'VERB')] [('to', 'ADV')] [('stop', 'VERB')] [('the', 'PRON')] [('bloodshed' , 'PRODUCT')] [(',', 'STOPWORDS')] [('on', 'PREP')] [('both', 'CARDINAL')] [('sides' , 'GPE')] [('and', 'CONJUNCTION')] [('so', 'ADV')] [('our', 'PRON')] [('offer' , 'PRODUCT')] [(',', 'STOP"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 52/100 [02:34<04:30,  5.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Rod', 'PERSON')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 53/100 [02:35<03:18,  4.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Looking', 'TIME'), ('back', 'TIME'), ('at', 'WORK_OF_ART'), ('my', 'NORP'), ('life', 'GPE'), (',', 'STOPWORDS'), (\"'ve\", 'VERB')]\n",
      "### ASSISTANT : <start_output> [('Looking', 'TIME'), ('back', 'TIME'), ('at', 'WORK_OF_ART'), ('my', 'NORP'), ('life', 'GPE'), (',', 'STOPWORDS'), (\"'ve\", 'VERB')]\n",
      "### ASSISTANT : <start_output> [('Looking', 'TIME'), ('back', 'TIME'), ('at', 'WORK_OF_ART'), ('my', 'NORP'), ('life', 'GPE'), (',', 'STOPWORDS'), (\"'ve\", 'VERB')]\n",
      "### ASSISTANT : <start_output> [('Looking', 'TIME'), ('back', 'TIME'), ('at"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 54/100 [02:44<04:21,  5.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('one', 'CARDINAL'), ('friend', 'PERSON'), ('offer', 'PRODUCT')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 55/100 [02:46<03:19,  4.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Interestingly', 'NORP'), ('enough', 'ORDINAL'), ('she', 'PERSON'), ('is', 'VERB'), ('quoted', 'WORK_OF_ART'), ('as', 'ADV'), ('telling', 'VERB'), ('General', 'PRODUCT'), ('Sanholi', 'PERSON'), ('back', 'ADP'), ('to', 'TO'), ('the', 'STOPWORDS'), ('US', 'GPE'), ('that', 'CONJUNCTION'), ('she', 'PERSON'), ('did', 'VERB'), ('not', 'NEGATION'), ('really', 'ADV'), ('get', 'VERB'), ('too', 'ORDINAL'), ('much', 'STOPWORDS'), ('of', 'PREPOSITION'), ('a', 'ARTICLE'), ('reception', 'WORK_OF_ART'), ('from', 'PREPOSITION'), ('Bashar', 'PERSON'), ('Al', 'PRODUCT"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 56/100 [02:55<04:15,  5.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [()]. Returned [('Interestingly', 'NORP'), ('enough', 'ORDINAL'), ('she', 'PERSON'), ('is', 'VERB'), ('quoted', 'WORK_OF_ART'), ('as', 'ADV'), ('telling', 'VERB'), ('General', 'PRODUCT'), ('Sanholi', 'PERSON'), ('back', 'ADP'), ('to', 'TO'), ('the', 'STOPWORDS'), ('US', 'GPE'), ('that', 'CONJUNCTION'), ('she', 'PERSON'), ('did', 'VERB'), ('not', 'NEGATION'), ('really', 'ADV'), ('get', 'VERB'), ('too', 'ORDINAL'), ('much', 'STOPWORDS'), ('of', 'PREPOSITION'), ('a', 'ARTICLE'), ('reception', 'WORK_OF_ART'), ('from', 'PREPOSITION'), ('Bashar', 'PERSON'), ('Al', 'PRODUCT\n",
      "-----------------------------------------------\n",
      "('Unseasonably', 'TIME'), ('hot' , 'ORDINAL')] [('dry', 'QUANTITY')] [('weather', 'WORK_OF_ART')] [('across', 'LOC')] [('large', 'CARDINAL')] [('portions', 'NORP')] [('of' , 'PREPOSITION')] [('the' , 'DET')] [('Great Plains', 'GPE')] [('and' , 'CONJUNCTION')] [('in' , 'PREPOSITION')] [('wheat- growing areas' , 'FAC')] [('in' , 'PREPOSITION')] [('Washington' , 'LOC')] [('and', 'CONJUNCTION')] [('Oregon' , 'GPE')] [('is' , 'VERB')] [('threatening' , 'WORK_OF_ART')] [('to' , '"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 57/100 [03:03<04:45,  6.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('wonders', 'WORK_OF_ART')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 58/100 [03:04<03:27,  4.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('China', 'GPE'), ('unreported income', 'MONEY')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 59/100 [03:06<02:38,  3.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('more', 'CARDINAL'), ('than', 'ORDINAL'), ('50', 'CARDINAL'), ('new', 'NORP'), ('breeds', 'PRODUCT'), ('such', 'QUANTIFIER'), ('as', 'CONJUNCTION'), ('melons', 'WORK_OF_ART'), ('vegetables', 'PRODUCT'), ('flowers', 'WORK_OF_ART'), ('and', 'CONJUNCTION'), ('fruit trees', 'PRODUCT'), ('.', 'PUNCTUATION'), ('etc.', 'OTHERS'), ('have', 'VERB'), ('successively', 'ADV'), ('been', 'AUXILIARY'), ('introduced', 'VERB'), ('from', 'PREPOSITION'), ('countries', 'GPE'), (',', 'PUNCTUATION'), ('such', 'QUANTIFIER'), ('as', 'CONJUNCTION'), ('US', 'GPE'),"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 60/100 [03:14<03:30,  5.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [()]. Returned [('more', 'CARDINAL'), ('than', 'ORDINAL'), ('50', 'CARDINAL'), ('new', 'NORP'), ('breeds', 'PRODUCT'), ('such', 'QUANTIFIER'), ('as', 'CONJUNCTION'), ('melons', 'WORK_OF_ART'), ('vegetables', 'PRODUCT'), ('flowers', 'WORK_OF_ART'), ('and', 'CONJUNCTION'), ('fruit trees', 'PRODUCT'), ('.', 'PUNCTUATION'), ('etc.', 'OTHERS'), ('have', 'VERB'), ('successively', 'ADV'), ('been', 'AUXILIARY'), ('introduced', 'VERB'), ('from', 'PREPOSITION'), ('countries', 'GPE'), (',', 'PUNCTUATION'), ('such', 'QUANTIFIER'), ('as', 'CONJUNCTION'), ('US', 'GPE'),\n",
      "-----------------------------------------------\n",
      "('last', 'ORDINAL'), ('two', 'CARDINAL'), ('years', 'DATE')] [('he', 'PERSON')] [('led', 'VERB')] [('task force', 'ORG')] [('to conduct', 'VERB')] [('many', 'QUANTITY')] [('field interviews and investigations on left - behind children in numerous rural areas in central and western China , including Shaanxi , Ningxia , Hebei , and Beijing .', 'DATE'), ('Shaanxi', 'GPE'), ('Ningxia', 'GPE'), ('Hebei', 'GPE'), ('Beijing', 'GPE')] [('in the last two years , he has led the task force to conduct many field interviews and investigations on left - behind children in numerous rural areas in central and western China , including Shaanxi , Ningxia , Hebei , and Beijing .', 'DATE'), ('last', '"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 61/100 [03:23<04:05,  6.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Lee', 'PERSON'), ('Yuan - tseh', 'PERSON')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 62/100 [03:24<03:00,  4.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('dancer', 'PERSON')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 63/100 [03:25<02:12,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('North', 'GPE'), ('Koreans', 'PERSON')] </output>"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 64/100 [03:26<01:43,  2.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('3', 'CARDINAL'), ('Taiwan', 'GPE')] [('Dong', 'FAC')] [('guan', 'FAC')] [('area', 'LOC')] [('has', 'VERB')] [('already', 'ADV')] [('developed', 'VERB')] [('economic circle', 'NORP')] [('in which', 'PREP')] [('Taiwan firms', 'ORG')] [('can', 'AUX')] [('conduct', 'VERB')] [('most', 'CARDINAL')] [('of their business', 'NOUN')] [('among themselves', 'ADV')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 65/100 [03:33<02:20,  4.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('new', 'WORK_OF_ART'), ('show', 'PRODUCT')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 66/100 [03:34<01:48,  3.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Taichung', 'GPE'), ('Goose', 'WORK_OF_ART'), ('Ah - shui Shih ', 'PERSON'), ('Pig Knuckle Kingdom', 'PRODUCT'), ('Yungho Soy Milk', 'PRODUCT'), ('Mantu Hair Salon', 'FAC')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 67/100 [03:37<01:44,  3.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Students', 'PERSON')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 68/100 [03:38<01:19,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Lee', 'PERSON'), ('Teng', 'PERSON'), ('hui', 'PERSON')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 69/100 [03:39<01:07,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('west', 'GPE')] [('east', 'GPE')] [('news', 'LAW')] </stop_output>"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 70/100 [03:41<00:57,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Formosa', 'ORG'), ('Plastics', 'PRODUCT')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 71/100 [03:42<00:49,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('North', 'GPE')] </end_output>"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 72/100 [03:43<00:41,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Many', 'NORP'), ('others', 'NORP'), ('at', 'TIME'), ('the', 'STOPWORDS'), ('same', 'NORP'), ('time', 'TIME'), ('in', 'PREPOSITION'), ('life', 'GPE'), ('have', 'VERB'), ('opted', 'VERB'), ('to', 'PREPOSITION'), ('take', 'VERB'), ('early', 'ADJECTIVE'), ('retirement', 'PRODUCT'), ('and', 'CONJUNCTION'), ('find', 'VERB'), ('a', 'ARTICLE'), ('guru', 'PERSON'), ('in', 'PREPOSITION'), ('India', 'GPE'), (',', ',') ,('work', 'VERB'), ('as', 'PREPOSITION'), ('a', 'ARTICLE'), ('volunteer', 'PRODUCT'), ('or', 'CONJUNCTION'), ('do', 'VERB'), ('whatever', 'ADJECTIVE"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 73/100 [03:52<01:38,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [()]. Returned [('Many', 'NORP'), ('others', 'NORP'), ('at', 'TIME'), ('the', 'STOPWORDS'), ('same', 'NORP'), ('time', 'TIME'), ('in', 'PREPOSITION'), ('life', 'GPE'), ('have', 'VERB'), ('opted', 'VERB'), ('to', 'PREPOSITION'), ('take', 'VERB'), ('early', 'ADJECTIVE'), ('retirement', 'PRODUCT'), ('and', 'CONJUNCTION'), ('find', 'VERB'), ('a', 'ARTICLE'), ('guru', 'PERSON'), ('in', 'PREPOSITION'), ('India', 'GPE'), (',', ',') ,('work', 'VERB'), ('as', 'PREPOSITION'), ('a', 'ARTICLE'), ('volunteer', 'PRODUCT'), ('or', 'CONJUNCTION'), ('do', 'VERB'), ('whatever', 'ADJECTIVE\n",
      "-----------------------------------------------\n",
      "('companies', 'ORG')] [('buy-outs', 'PRODUCT')] [('federal tax refunds', 'MONEY')] [('interest payments on debt issued to finance the buy - outs' , 'QUANTITY')] [('Aug. 2, 1989', 'DATE')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 74/100 [03:55<01:31,  3.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Iraq', 'GPE')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 75/100 [03:56<01:08,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('We', 'MONEY'), ('make', 'VERB'), ('our', 'PRONOUN'), ('money', 'MONEY'), ('here', 'LOC'), (',', 'STOPWORDS'), (\"but\", \"CONJ\"), ('we', 'PRONOUN'), ('pay', 'VERB'), ('taxes', 'MONEY'), ('in', 'PREP'), ('Taiwan', 'GPE'), ',', 'STOPWORDS'], [('and', 'CONJ'), ('most', 'QUANTITY'), ('of', 'DET'), ('our', 'PRONOUN'), ('families', 'ORG'), ('and', 'CONJ'), ('children', 'PERSON'), ('do', 'VERB'), ('most', 'QUANTITY'), ('their', 'PRONOUN'), ('consumer', 'PRODUCT'), ('spending', 'NORP'), ('in', 'PREP'), ('Taiwan', 'GPE')],"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 76/100 [04:07<02:07,  5.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('National', 'GPE'), ('Economy', 'NORP')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 77/100 [04:08<01:31,  3.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Republican', 'ORG'), ('senators', 'PERSON')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 78/100 [04:10<01:13,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('one', 'PERSON'), ('quiver', 'FAC'), ('arrows', 'QUANTITY'), ('opportunities', 'PRODUCT')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 79/100 [04:13<01:06,  3.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Chinese', 'GPE'), ('society', 'GPE'), ('people', 'NORP')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 80/100 [04:15<00:57,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('CIA', 'ORG'), ('Pentagon', 'FAC')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 81/100 [04:17<00:48,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Cocom', 'ORG')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 82/100 [04:17<00:36,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Time', 'ORG')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 83/100 [04:19<00:30,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('the', 'ORDINAL'), ('first', 'CARDINAL')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 84/100 [04:20<00:28,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Rumsfeld', 'PERSON'), ('we', 'MISC')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 85/100 [04:22<00:27,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Miller', 'PERSON'), ('Scooter Libby', 'ORG'), ('Dick Cheney', 'PERSON')] </end_output>"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 86/100 [04:25<00:28,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('It', 'PRON')] [('is', 'VERB')] [('not', 'ADV')] [('only', 'ADJ')] [(',', ',')] [('for', 'PREP')] [(',', ',')] [('this', 'DET')] [('kind', 'NOUN')] [('of', 'CONJ')] [('sudden', 'ADV')] [('road', 'NOUN')] [('cave - in', 'VERB')] , it also includes , for instance , security incidents , ah , in our society , as well as natural disasters , ah , and including public health incidents . "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 87/100 [04:34<00:54,  4.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('He', 'PERSON'), ('concluded', 'VERB'), ('his', 'PRONOUN'), ('remarks', 'NOUN'), ('by', 'PREP'), ('quoting', 'VERB'), (',', 'STOPWORDS'), ('emotionally', 'ADV'), ('and', 'CONJ'), ('at', 'PREP'), ('some', 'DET'), ('length', 'NOUN'), (',', 'STOPWORDS'), ('according', 'VERB'), ('to', 'PREP'), ('those', 'PRONOUN'), ('present', 'ADV'), (',', 'STOPWORDS'), ('the', 'ARTICLE'), ('late', 'ADJ'), ('Martin', 'PERSON'), ('Luther', 'PERSON'), ('King', 'PERSON'), ('''s', 'POSSESSIVE_PRONOUN'), ('famous', 'ADJ'), (``, '', 'STOPWORDS'), ('I', 'ARTICLE"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 88/100 [04:46<01:19,  6.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [()]. Returned [('He', 'PERSON'), ('concluded', 'VERB'), ('his', 'PRONOUN'), ('remarks', 'NOUN'), ('by', 'PREP'), ('quoting', 'VERB'), (',', 'STOPWORDS'), ('emotionally', 'ADV'), ('and', 'CONJ'), ('at', 'PREP'), ('some', 'DET'), ('length', 'NOUN'), (',', 'STOPWORDS'), ('according', 'VERB'), ('to', 'PREP'), ('those', 'PRONOUN'), ('present', 'ADV'), (',', 'STOPWORDS'), ('the', 'ARTICLE'), ('late', 'ADJ'), ('Martin', 'PERSON'), ('Luther', 'PERSON'), ('King', 'PERSON'), ('''s', 'POSSESSIVE_PRONOUN'), ('famous', 'ADJ'), (``, '', 'STOPWORDS'), ('I', 'ARTICLE\n",
      "-----------------------------------------------\n",
      "('S&L', 'ORG'), ('lawyers', 'PERSON'), ('appellate', 'LAW'), ('court', 'FAC'), ('ruling', 'EVENT'), ('cases', 'EVENT'), ('Sunbelt', 'PRODUCT'), ('Dallas', 'LOC'), ('Valley Ranch', 'WORK_OF_ART'), ('Cowboys', 'ORG')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 89/100 [04:52<01:10,  6.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('$', 'MONEY')] [('239', 'CARDINAL')] [('million', 'QUANTITY')] [('by', 'VERB')] [('charging', 'VERB')] [('fees', 'PRODUCT')] [('for', 'PREP')] [('commercial', 'NORP')] [('airline', 'PRODUCT')] [('- landing rights', 'FAC')] [('at', 'PREP')] [('New York ', 'GPE')] [(',', 'STOPWORD')] [('s', 'STOPWORD')] [('LaGuardia', 'LOC')] [('and', 'CONJUNCTION')] [('John F. Kennedy International Airports , O'Hare International Airport in Chicago and National Airport in Washington .', 'GPE')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 90/100 [05:04<01:20,  8.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Australia', 'GPE'), ('Shandong Stock - holding Company , Ltd.', 'ORG')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 91/100 [05:06<00:54,  6.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('industry', 'GPE')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 92/100 [05:07<00:37,  4.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('97,963', 'QUAN'), ('employed people', 'NORP'), ('and', 'STOPWORDS'), ('registered capital', 'MONEY'), ('of private enterprises', 'FAC'), ('is more than 3.08 billion yuan', 'MONEY'), ('.', 'STOPWORDS'), ('respectively', 'STOPWORDS'), ('10 % to 20 % higher', 'QUAN'), ('than that of the same period of the previous year .', 'DATE')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 93/100 [05:15<00:39,  5.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Israel', 'GPE')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 94/100 [05:15<00:24,  4.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Hertz', 'ORG'), ('Avis', 'ORG')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 95/100 [05:17<00:17,  3.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Chen', 'PERSON'), ('Shui - bian', 'PERSON')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 96/100 [05:19<00:11,  2.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('official', 'NORP'), ('actions', 'EVENT'), ('aimed', 'VERB'), ('at', 'ADV'), ('takeovers', 'PRODUCT'), (',', 'STOPWORDS'), ('then', 'ADV'), ('by', 'PREPOSITION'), ('the', 'DET'), ('tax', 'MONEY'), ('-', 'PUNCTUATION'), ('writing', 'VERB'), ('House', 'ORG'), ('Ways', 'NORP'), ('and', 'CONJUNCTION'), ('Means', 'NORP'), ('Committee', 'ORG'), (',', 'STOPWORDS'), ('rather', 'ADV'), ('than', 'PREPOSITION'), ('the', 'DET'), ('Transportation', 'FAC'), ('Department', 'FAC'), ('.', 'PUNCTUATION')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 97/100 [05:31<00:16,  5.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Arthur', 'PERSON'), ('Sulzberger', 'PERSON')] </output>"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 98/100 [05:33<00:08,  4.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('everybody', 'NORP'), ('table', 'FAC'), ('with', 'STOPWORDS'), ('the', 'STOPWORDS'), ('North', 'GPE'), ('Koreans', 'GPE'), ('is', 'VERB'), ('not', 'ADV'), ('only', 'ADV'), ('that', 'STOPWORDS'), ('they', 'PRONOUN'), ('have', 'VERB'), ('a', 'DET'), ('stake', 'NORP'), ('in', 'PREPOSITION'), ('the', 'STOPWORDS'), ('outcome', 'WORK_OF_ART'), ('as', 'ADV'), ('well', 'ADV'), ('but', 'CONJUNCTION'), ('uh', 'STOPWORDS'), ('in', 'PREPOSITION'), ('dealing', 'VERB'), ('with', 'PREPOSITION'), ('North', 'GPE'), ('Korea', 'GPE'), ('diplomacy', 'WORK"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [05:45<00:06,  6.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [()]. Returned [('everybody', 'NORP'), ('table', 'FAC'), ('with', 'STOPWORDS'), ('the', 'STOPWORDS'), ('North', 'GPE'), ('Koreans', 'GPE'), ('is', 'VERB'), ('not', 'ADV'), ('only', 'ADV'), ('that', 'STOPWORDS'), ('they', 'PRONOUN'), ('have', 'VERB'), ('a', 'DET'), ('stake', 'NORP'), ('in', 'PREPOSITION'), ('the', 'STOPWORDS'), ('outcome', 'WORK_OF_ART'), ('as', 'ADV'), ('well', 'ADV'), ('but', 'CONJUNCTION'), ('uh', 'STOPWORDS'), ('in', 'PREPOSITION'), ('dealing', 'VERB'), ('with', 'PREPOSITION'), ('North', 'GPE'), ('Korea', 'GPE'), ('diplomacy', 'WORK\n",
      "-----------------------------------------------\n",
      "('Saturday', 'TIME')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [05:46<00:00,  3.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./ner/saves/datasets/ontonote5_test_1403.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Pacific', 'GPE'), ('Care Health Systems', 'ORG'), ('Inc.', 'PRODUCT')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:02<04:03,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('China', 'GPE'), ('France', 'GPE')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [00:04<03:19,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ozone', 'GPE')] [('air', 'FAC')] [('conditioner', 'PRODUCT')] [('Styrofoam', 'PRODUCT')] [('pound', 'QUANTITY')] [('year', 'TIME')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [00:07<04:29,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('We', 'NORP')] [('are', 'VERB')] [('currently', 'ADV')] [('re-evaluating', 'VERB')] [('our', 'PRON')] [('positions' , 'PRODUCT')] [(',', 'STOPWORDS')] [('we', 'NORP')] [('want', 'VERB')] [('to', 'ADV')] [('stop', 'VERB')] [('the', 'PRON')] [('bloodshed' , 'PRODUCT')] [(',', 'STOPWORDS')] [('on', 'PREP')] [('both', 'CARDINAL')] [('sides' , 'GPE')] [('and', 'CONJUNCTION')] [('so', 'ADV')] [('our', 'PRON')] [('offer' , 'PRODUCT')] [(',', 'STOP"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [00:20<10:49,  6.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Shanghai', 'GPE'), ('Southeast Asia', 'GPE')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [00:22<07:55,  5.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Finnish', 'GPE'), ('government', 'ORG'), ('1 million US dollars', 'MONEY')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/100 [00:25<06:29,  4.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Apache', 'FAC'), ('helicopter pilot', 'PERSON'), ('Michelle', 'PERSON'), ('POWs', 'ORG')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/100 [00:27<05:29,  3.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Kamyao', 'PERSON'), ('Foreign Ministry', 'FAC')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/100 [00:29<04:34,  2.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Babylonian', 'GPE'), ('Jewish', 'NORP'), ('working - class people', 'PERSON'), ('drab', 'QUANTITY'), ('Soviet - style buildings', 'FAC'), ('AnaMor Towers', 'PRODUCT'), ('Anna and Morris Snezak', 'PERSON'), ('lobbies and hallways', 'LOC')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9/100 [00:35<05:59,  3.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Iraq', 'GPE')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/100 [00:36<04:38,  3.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('wax', 'PRODUCT')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 11/100 [00:37<03:44,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('work', 'WORK_OF_ART'), ('this', 'NORP')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 12/100 [00:39<03:24,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Homeland', 'GPE'), ('Security', 'ORG'), ('Secretary', 'PERSON')] [('Iraqi', 'NORP'), ('lawyer', 'PRODUCT')] [('IES', 'FAC')] [('United', 'GPE'), ('States', 'GPE')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 13/100 [00:44<04:32,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Looking', 'TIME'), ('back', 'TIME'), ('at', 'WORK_OF_ART'), ('my', 'NORP'), ('life', 'GPE'), (',', 'STOPWORDS'), (\"'ve\", 'VERB')]\n",
      "### ASSISTANT : <start_output> [('Looking', 'TIME'), ('back', 'TIME'), ('at', 'WORK_OF_ART'), ('my', 'NORP'), ('life', 'GPE'), (',', 'STOPWORDS'), (\"'ve\", 'VERB')]\n",
      "### ASSISTANT : <start_output> [('Looking', 'TIME'), ('back', 'TIME'), ('at', 'WORK_OF_ART'), ('my', 'NORP'), ('life', 'GPE'), (',', 'STOPWORDS'), (\"'ve\", 'VERB')]\n",
      "### ASSISTANT : <start_output> [('Looking', 'TIME'), ('back', 'TIME'), ('at"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 14/100 [00:56<08:25,  5.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('S&amp;Ls', 'ORG')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 15/100 [00:58<06:27,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Wetten', 'GPE')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 16/100 [00:59<05:00,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('GA', 'ORG'), ('St.', 'LOC')] </end_output>"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 17/100 [01:01<04:07,  2.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('court', 'ORG'), ('justices', 'PERSON')] </end_output>"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 18/100 [01:02<03:33,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Jackie', 'PERSON')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 19/100 [01:04<02:57,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Guangdong', 'GPE'), ('western lettuce', 'PRODUCT'), ('western celery', 'PRODUCT'), ('western cauliflower', 'PRODUCT'), ('Californian perch', 'ANIMAL'), ('whitish pomfret', 'ANIMAL'), ('Dutch tulips', 'PLANT')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20/100 [01:08<03:55,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('vast', 'CARDINAL'), ('majority', 'ORDINAL'), ('these', 'STOPWORDS'), (20, 'NUMBER'), (',', 'STOPWORDS'), ('of', 'STOPWORDS'), ('upper', 'STOPWORDS'), ('-', 'STOPWORDS'), ('class', 'STOPWORDS'), ('citizens', 'STOPWORDS'), ('in', 'STOPWORDS'), ('China', 'GPE'), (',', 'STOPWORDS'), ('the', 'STOPWORDS'), ('proportion', 'STOPWORDS'), ('of', 'STOPWORDS'), ('their', 'PRONOUN'), ('income', 'WORK_OF_ART'), ('that', 'STOPWORDS'), ('comes', 'VERB'), (from, 'PREPOSITION'), ('fully', 'ADJECTIVE'), ('declared', 'VERB'), ('earnings', 'PRODUCT'), ('is', 'VERB'), ('a', 'DETER"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 21/100 [01:21<07:48,  5.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [()]. Returned [('vast', 'CARDINAL'), ('majority', 'ORDINAL'), ('these', 'STOPWORDS'), (20, 'NUMBER'), (',', 'STOPWORDS'), ('of', 'STOPWORDS'), ('upper', 'STOPWORDS'), ('-', 'STOPWORDS'), ('class', 'STOPWORDS'), ('citizens', 'STOPWORDS'), ('in', 'STOPWORDS'), ('China', 'GPE'), (',', 'STOPWORDS'), ('the', 'STOPWORDS'), ('proportion', 'STOPWORDS'), ('of', 'STOPWORDS'), ('their', 'PRONOUN'), ('income', 'WORK_OF_ART'), ('that', 'STOPWORDS'), ('comes', 'VERB'), (from, 'PREPOSITION'), ('fully', 'ADJECTIVE'), ('declared', 'VERB'), ('earnings', 'PRODUCT'), ('is', 'VERB'), ('a', 'DETER\n",
      "-----------------------------------------------\n",
      "('Janet', 'PERSON'), ('Strawberry', 'PRODUCT')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 22/100 [01:23<06:06,  4.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('cable', 'PRODUCT'), ('television', 'PRODUCT')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 23/100 [01:24<04:42,  3.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('George', 'PERSON'), ('Bush', 'PERSON')] </end_output>"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 24/100 [01:26<03:56,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('French', 'GPE'), ('Foreign Minister Hubert Vedrine', 'PERSON'), ('said Sunday that relieving the pressure on Belgrade\\'s devastated economy is the first step towards supporting the new President Vojislav Kostunica and reintegrating Yugoslavia into a democratic Europe .', 'O')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 25/100 [01:31<04:40,  3.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Chinese', 'NORP')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 26/100 [01:33<03:42,  3.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Mr.', 'NORP'), ('Mitchell', 'PERSON')] [('Budget Director Darman' , 'ORG')] [('who pushed for a capital - gains cut to be added to the measure' , 'EVENT')] [('Mr. Darman chose to bypass the Maine Democrat and deal with other lawmakers earlier this year during a dispute over drug funding in the fiscal 1989 supplemental spending bill .', 'TIME')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 27/100 [01:39<04:49,  3.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('production', 'WORK_OF_ART'), ('internal', 'ORDINAL'), ('combustion', 'NORP'), ('engines' , 'PRODUCT')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 28/100 [01:42<04:24,  3.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('December', 'DATE')] [('last', 'ORDINAL')] [('the', 'STOPWORDS')] [('total', 'QUANTITY')] [('number', 'NUMBER')] [('of', 'PREPOSITION')] [('enterprises', 'FAC')] [('in', 'PREPOSITION')] [('bonded', 'LOC')] [('area', 'GPE')] [('was', 'VERB')] [(1, 'CARDINAL')] [(600, 'ORDINAL')] [('of', 'PREPOSITION')] [('which', 'PRONOUN')] [('260', 'CARDINAL')] [('were', 'VERB')] [('foreign', 'NORP')] [('-', '-')] [('invested', 'VERB')] [('enterprises', 'FAC')] [(1.2, '"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 29/100 [01:54<07:18,  6.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Pontiac', 'GPE')] [('Camaro', 'PRODUCT')] [('Firebird', 'PRODUCT')] [('GM', 'ORG')] [('Fiero', 'PRODUCT')] </end_output>\n",
      "### USER : <start_input> The 1982 Pontiac Firefly was a subcompact car produced by General Motors's Pontiac division for the 1982 through 1986 model years . It replaced the Chevrolet Vega and was itself replaced by the Geo Metro in 1987 . <end_input>\n",
      "### ASSISTANT : <start_output> [('Pontiac', 'GPE')] [('Firefly', 'PRODUCT')] </end_output>"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 30/100 [02:05<08:49,  7.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Israel', 'GPE')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 31/100 [02:06<06:32,  5.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Guangzhou', 'GPE')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 32/100 [02:08<05:03,  4.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('DPP', 'ORG')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 33/100 [02:09<03:59,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Ramallah', 'GPE')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 34/100 [02:11<03:18,  3.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('coalmines', 'FAC')] [('construction', 'FAC')] [('others' , 'OTHERS')] [('jobs' , 'OTHERS')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 35/100 [02:15<03:35,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Wang', 'PERSON'), ('Shin', 'PERSON')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 36/100 [02:17<03:03,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('CIA', 'ORG'), ('Pentagon', 'FAC')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 37/100 [02:18<02:28,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Shanghai', 'GPE'), ('this year\\'s value of exports could exceed 14.5 billion US dollars ', 'DATE')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 38/100 [02:21<02:36,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Chinese', 'GPE'), ('American Chamber of Commerce', 'ORG')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 39/100 [02:23<02:28,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Louis Libby', 'PERSON'), ('Dick Cheney', 'ORG')] </end_output>"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 40/100 [02:25<02:25,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('He', 'PERSON'), ('sat', 'VERB'), ('out', 'VERB'), ('1', 'CARDINAL'), ('term', 'WORK_OF_ART'), ('after', 'PREP'), ('losing', 'VERB'), ('a', 'DET'), ('U.S.', 'ORG'), ('Senate', 'PRODUCT'), ('race', 'NOUN'), ('in', 'INFINITIVE'), ('the', 'DET'), ('1960s', 'DATE'), (',', 'PUNCTUATION'), ('but', 'CONJ'), ('for', 'PREP'), ('24', 'CARDINAL'), ('terms', 'NOUN'), (',', 'PUNCTUATION'), ('Yates', 'PERSON'), ('represented', 'VERB'), ('Chicago\\'s', 'DET'), ('northern', 'ADJ'), ('lake', 'WORK_OF_ART'), ('front', '"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 41/100 [02:40<06:08,  6.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [()]. Returned [('He', 'PERSON'), ('sat', 'VERB'), ('out', 'VERB'), ('1', 'CARDINAL'), ('term', 'WORK_OF_ART'), ('after', 'PREP'), ('losing', 'VERB'), ('a', 'DET'), ('U.S.', 'ORG'), ('Senate', 'PRODUCT'), ('race', 'NOUN'), ('in', 'INFINITIVE'), ('the', 'DET'), ('1960s', 'DATE'), (',', 'PUNCTUATION'), ('but', 'CONJ'), ('for', 'PREP'), ('24', 'CARDINAL'), ('terms', 'NOUN'), (',', 'PUNCTUATION'), ('Yates', 'PERSON'), ('represented', 'VERB'), ('Chicago\\'s', 'DET'), ('northern', 'ADJ'), ('lake', 'WORK_OF_ART'), ('front', '\n",
      "-----------------------------------------------\n",
      "('over', 'TIME'), ('period', 'TIME'), ('they', 'PERSON')] </stop_output>"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 42/100 [02:42<04:48,  4.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Guangzhou', 'GPE')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 43/100 [02:43<03:32,  3.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('August', 'DATE'), ('Yemen', 'GPE')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 44/100 [02:45<02:55,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Pennzoil', 'ORG'), ('Texaco', 'ORG')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 45/100 [02:47<02:36,  2.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('potato', 'QUANTITY'), ('chocolate', 'PRODUCT')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 46/100 [02:49<02:21,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('It', 'ORDINAL'), ('such', 'STOPWORDS'), ('a', 'STOPWORDS'), ('beautiful', 'STOPWORDS'), ('and', 'STOPWORDS'), ('historic', 'STOPWORDS'), ('location', 'LOC'), (',', 'STOPWORDS'), ('but', 'STOPWORDS'), ('they', 'PERSON'), ('are', 'VERB'), ('just', 'ADV'), ('going', 'VERB'), ('to', 'STOPWORDS'), ('stick', 'VERB'), ('up', 'VERB'), ('a', 'STOPWORDS'), ('bridge', 'FAC'), (',', 'STOPWORDS'), ('and', 'STOPWORDS'), ('they', 'PERSON'), ('are', 'VERB'), ('even', 'ADV'), ('talking', 'VERB'), ('about', 'VERB'), ('having', 'VERB'), ('a', 'STOPWORDS'), ('rotating', 'VERB'), ('rest"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 47/100 [03:04<05:31,  6.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [()]. Returned [('It', 'ORDINAL'), ('such', 'STOPWORDS'), ('a', 'STOPWORDS'), ('beautiful', 'STOPWORDS'), ('and', 'STOPWORDS'), ('historic', 'STOPWORDS'), ('location', 'LOC'), (',', 'STOPWORDS'), ('but', 'STOPWORDS'), ('they', 'PERSON'), ('are', 'VERB'), ('just', 'ADV'), ('going', 'VERB'), ('to', 'STOPWORDS'), ('stick', 'VERB'), ('up', 'VERB'), ('a', 'STOPWORDS'), ('bridge', 'FAC'), (',', 'STOPWORDS'), ('and', 'STOPWORDS'), ('they', 'PERSON'), ('are', 'VERB'), ('even', 'ADV'), ('talking', 'VERB'), ('about', 'VERB'), ('having', 'VERB'), ('a', 'STOPWORDS'), ('rotating', 'VERB'), ('rest\n",
      "-----------------------------------------------\n",
      "('Friday', 'DATE'), ('New York', 'GPE')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 48/100 [03:06<04:17,  4.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Guangxu', 'PERSON'), ('Qing dynasty', 'ORG')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 49/100 [03:08<03:32,  4.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Mr.', 'PERSON'), ('Louis', 'PERSON')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50/100 [03:09<02:42,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('one', 'CARDINAL'), ('thing', 'ORDINAL')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 51/100 [03:11<02:22,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('North', 'GPE')] </end_output>"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 52/100 [03:13<01:59,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('do', 'VERB'), ('n\\'t', 'STOPWORD'), ('feel', 'VERB'), ('financially', 'ADV'), ('secure', 'NOUN'), ('.', '.')] [('one - fourth', 'NUMERAL'), ('do', 'VERB'), ('n\\'t', 'STOPWORD'), ('feel', 'VERB'), ('that', 'CONJ'), ('they', 'PRONOUN'), ('have', 'VERB'), ('made', 'NOUN'), ('it', 'PRONOUN')] [('40 %', 'NUMERAL'), ('.', '.')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 53/100 [03:23<03:43,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Rumsfeld', 'PERSON'), ('those you are calling traitors have been chosen by the Iraqi people as their leaders by democratic means and free elections , something that did not take place during your rule over the country .', 'O')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 54/100 [03:28<03:39,  4.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Many', 'NORP'), ('others', 'NORP'), ('at', 'TIME'), ('the', 'STOPWORDS'), ('same', 'NORP'), ('time', 'TIME'), ('in', 'PREPOSITION'), ('life', 'GPE'), ('have', 'VERB'), ('opted', 'VERB'), ('to', 'PREPOSITION'), ('take', 'VERB'), ('early', 'ADJECTIVE'), ('retirement', 'PRODUCT'), ('and', 'CONJUNCTION'), ('find', 'VERB'), ('a', 'ARTICLE'), ('guru', 'PERSON'), ('in', 'PREPOSITION'), ('India', 'GPE'), (',', ',') ,('work', 'VERB'), ('as', 'PREPOSITION'), ('a', 'ARTICLE'), ('volunteer', 'PRODUCT'), ('or', 'CONJUNCTION'), ('do', 'VERB'), ('whatever', 'ADJECTIVE"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 55/100 [03:43<05:57,  7.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [()]. Returned [('Many', 'NORP'), ('others', 'NORP'), ('at', 'TIME'), ('the', 'STOPWORDS'), ('same', 'NORP'), ('time', 'TIME'), ('in', 'PREPOSITION'), ('life', 'GPE'), ('have', 'VERB'), ('opted', 'VERB'), ('to', 'PREPOSITION'), ('take', 'VERB'), ('early', 'ADJECTIVE'), ('retirement', 'PRODUCT'), ('and', 'CONJUNCTION'), ('find', 'VERB'), ('a', 'ARTICLE'), ('guru', 'PERSON'), ('in', 'PREPOSITION'), ('India', 'GPE'), (',', ',') ,('work', 'VERB'), ('as', 'PREPOSITION'), ('a', 'ARTICLE'), ('volunteer', 'PRODUCT'), ('or', 'CONJUNCTION'), ('do', 'VERB'), ('whatever', 'ADJECTIVE\n",
      "-----------------------------------------------\n",
      "('CNN', 'ORG')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 56/100 [03:45<04:23,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The', 'ORDINAL'), ('next', 'TIME'), ('stage', 'NORP'), (\"'s\", 'GPE'), ('to', 'CARDINAL'), ('get', 'VERB'), ('beyond', 'WORK_OF_ART'), ('the', 'PERSON'), ('opinion', 'LAW'), ('leaders', 'MONEY'), (',', 'PUNCTUATION'), (\"'s\", 'GPE'), ('who', 'CARDINAL'), ('use', 'VERB'), ('us', 'PRODUCT'), ('as', 'PREPOSITION'), ('a', 'ORDINAL'), ('point', 'WORK_OF_ART'), ('of', 'PREPOSITION'), (\"'s\", 'GPE'), ('reference', 'NORP'), (',', 'PUNCTUATION'), ('to', 'CARDINAL'), ('become', 'VERB'), ('a', 'ORDINAL'), ('point', 'WORK_OF_"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 57/100 [04:00<06:14,  8.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [()]. Returned [('The', 'ORDINAL'), ('next', 'TIME'), ('stage', 'NORP'), (\"'s\", 'GPE'), ('to', 'CARDINAL'), ('get', 'VERB'), ('beyond', 'WORK_OF_ART'), ('the', 'PERSON'), ('opinion', 'LAW'), ('leaders', 'MONEY'), (',', 'PUNCTUATION'), (\"'s\", 'GPE'), ('who', 'CARDINAL'), ('use', 'VERB'), ('us', 'PRODUCT'), ('as', 'PREPOSITION'), ('a', 'ORDINAL'), ('point', 'WORK_OF_ART'), ('of', 'PREPOSITION'), (\"'s\", 'GPE'), ('reference', 'NORP'), (',', 'PUNCTUATION'), ('to', 'CARDINAL'), ('become', 'VERB'), ('a', 'ORDINAL'), ('point', 'WORK_OF_\n",
      "-----------------------------------------------\n",
      "('missiles', 'PRODUCT')] [('Thomson', 'ORG')] [('British Aerospace', 'ORG')] [('Aerospatiale S.A.', 'FAC')] [('France ', 'GPE')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 58/100 [04:04<05:16,  7.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('$', 'MONEY')] [('Bush', 'PERSON')] [('Gramm-Rudman budget law', 'LAW')] [('16 billion of automatic , across - the - board cuts in government spending to comply with the Gramm - Rudman budget law .', 'DATE')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 59/100 [04:10<04:48,  7.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Chinese', 'GPE'), ('society', 'ORG'), ('80 %', 'QUANTITY'), ('poor people', 'PERSON'), ('20 %', 'QUANTITY'), ('wealthy', 'WORK_OF_ART'), ('.', 'STOPWORD')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 60/100 [04:15<04:12,  6.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Tuesday', 'DATE'), ('October', 'DATE'), ('1989', 'DATE')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 61/100 [04:18<03:22,  5.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Mr.', 'PERSON'), ('Friedman', 'PERSON')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 62/100 [04:20<02:41,  4.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('mergers', 'ORG'), ('policy - type loss subsidies', 'MONEY')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 63/100 [04:22<02:18,  3.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Freddie', 'ORG')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 64/100 [04:24<01:50,  3.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Taiwan', 'GPE'), ('Ministry', 'ORG'), ('Economic', 'ORG'), ('Affairs', 'ORG'), ('National', 'ORG'), ('Science', 'ORG'), ('Council', 'ORG'), ('Institutes', 'ORG'), ('biochip', 'PRODUCT')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 65/100 [04:29<02:08,  3.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Add', 'VERB'), ('to', 'PREP'), ('this', 'DET'), ('the', 'DET'), ('fact', 'NOUN'), ('that', 'CONJ'), ('the', 'DET'), ('threshold', 'NORP'), ('.', '.')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 66/100 [04:34<02:21,  4.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('John', 'PERSON'), ('Lampe', 'PERSON')] [('director', 'WORK_OF_ART'), ('of', 'STOPWORDS'), ('advertising', 'PRODUCT'), ('at', 'STOPWORDS'), ('PaineWebber', 'ORG'), ('Inc.', 'STOPWORDS'), ('.', 'STOPWORDS')] [('a', 'STOPWORDS'), ('Saatchi', 'PERSON'), ('&', 'STOPWORDS'), ('Advertising', 'PRODUCT'), ('client', 'WORK_OF_ART'), (' , ', 'STOPWORDS'), (' a ', 'STOPWORDS'), (' Saatchi & ', 'STOPWORDS')] [('Saatchi', 'PERSON'), ('&', 'STOPWORDS'), ('Advertising', 'PRODUCT'), ('client', 'WORK_OF_ART'), ('.', 'STOPWORDS')] [('John', 'PERSON'), ('Lampe', 'PER"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 67/100 [04:48<03:59,  7.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('National', 'ORG'), ('Foreign', 'ORG'), ('Exchange', 'FAC')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 68/100 [04:51<03:05,  5.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Zibo', 'GPE'), ('City', 'ORG')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 69/100 [04:52<02:15,  4.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Last', 'ORDINAL'), ('year', 'DATE')] [('exports', 'QUANTITY'), ('of', 'PREP'), ('primary', 'PRODUCTS'), ('to', 'TO'), ('Japan', 'GPE'), ('were', 'VERB'), ('8', 'CARDINAL'), ('billion', 'MONEY'), ('US', 'LANGUAGE'), ('dollars', 'MONEY')] [('10.9', 'PERCENT'), ('%', '%'), ('higher', 'ADJP'), ('than', 'THAN'), ('that', 'PRONOUN'), ('of', 'PREP'), ('the', 'DET'), ('previous', 'ORDINAL')] [('year', 'DATE')], [('imports', 'QUANTITY'), ('of', 'PREP'), ('primary', 'PRODUCTS'), ('from', 'FROM'), ('Japan', 'GPE'), ('were', 'VERB"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 70/100 [05:07<03:50,  7.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('despite', 'CARDINAL'), ('all', 'ORDINAL'), ('the', 'STOPWORDS'), ('media', 'PRODUCT'), ('prattle', 'WORK_OF_ART'), ('about', 'VERB'), ('comedy', 'WORK_OF_ART'), ('and', 'CONJUNCTION'), ('politics', 'ORG'), ('not', 'ADV'), ('mixing', 'VERB'), (',', 'STOPWORDS'), ('they', 'PERSON'), ('are', 'VERB'), ('similar', 'WORK_OF_ART'), ('in', 'PREPOSITION'), ('one', 'ORDINAL'), ('respect', 'NOUN'), ('both', 'CARDINAL'), ('can', 'VERB'), ('serve', 'VERB'), (',', 'STOPWORDS'), ('as', 'CONJUNCTION'), ('mechanisms', 'WORK_OF_ART'), ('for', 'PREPOSITION'), ('easing', 'NO"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 71/100 [05:22<04:47,  9.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [()]. Returned [('despite', 'CARDINAL'), ('all', 'ORDINAL'), ('the', 'STOPWORDS'), ('media', 'PRODUCT'), ('prattle', 'WORK_OF_ART'), ('about', 'VERB'), ('comedy', 'WORK_OF_ART'), ('and', 'CONJUNCTION'), ('politics', 'ORG'), ('not', 'ADV'), ('mixing', 'VERB'), (',', 'STOPWORDS'), ('they', 'PERSON'), ('are', 'VERB'), ('similar', 'WORK_OF_ART'), ('in', 'PREPOSITION'), ('one', 'ORDINAL'), ('respect', 'NOUN'), ('both', 'CARDINAL'), ('can', 'VERB'), ('serve', 'VERB'), (',', 'STOPWORDS'), ('as', 'CONJUNCTION'), ('mechanisms', 'WORK_OF_ART'), ('for', 'PREPOSITION'), ('easing', 'NO\n",
      "-----------------------------------------------\n",
      "('North', 'GPE'), ('Korea', 'GPE')] </end_output>"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 72/100 [05:25<03:32,  7.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('dancer', 'PERSON')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 73/100 [05:26<02:35,  5.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Clinton', 'PERSON')] </end_output>"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 74/100 [05:28<01:56,  4.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('International', 'GPE'), ('business', 'ORG'), ('loans', 'PRODUCT')] </end_output>"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 75/100 [05:30<01:34,  3.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Ideal', 'ORG'), ('Basic Industries Inc.', 'ORG')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 76/100 [05:31<01:15,  3.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Minister', 'PERSON'), ('China\\'s Mechanical Industry Ministry', 'FAC')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 77/100 [05:34<01:08,  2.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('China', 'GPE')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 78/100 [05:35<00:55,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('middle', 'ORDINAL'), ('age', 'CARDINAL')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 79/100 [05:38<00:50,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Shanghai', 'GPE')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 80/100 [05:39<00:42,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('China', 'GPE')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 81/100 [05:41<00:36,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('California', 'GPE'), ('utility companies', 'ORG')] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 82/100 [05:42<00:34,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The', 'ORDINAL'), ('games', 'NORP'), ('Bron"
     ]
    }
   ],
   "source": [
    "# ToDo \n",
    "from llm.LLMModel import *\n",
    "from ner.llm_ner.prompt_techniques.pt_abstract import PromptTechnique\n",
    "from ner.llm_ner.prompt_techniques.pt_discussion import PT_OutputList\n",
    "from ner.llm_ner.prompt_techniques.pt_gpt_ner import PT_GPT_NER\n",
    "from ner.llm_ner.prompt_techniques.pt_wrapper import PT_Wrapper\n",
    "from ner.llm_ner.prompt_techniques.pt_multi_pt import PT_2Time_Tagger\n",
    "from ner.llm_ner.few_shots_techniques import *\n",
    "from ner.llm_ner.prompts import *\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "model = MistralAI()\n",
    "plus_plus = True\n",
    "pts = [\n",
    "   #  PT_GPT_NER, \n",
    "       PT_OutputList, \n",
    "      #  PT_Wrapper, \n",
    "       PT_2Time_Tagger,\n",
    "      #  PT_Filing\n",
    "       ]\n",
    "results, results_df = model.classical_test_ontonote5(pts = pts, fsts = [FST_NoShots], nb_few_shots=[0], nb_run_by_test=3, plus_plus= plus_plus, test_size = 100)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_mean</th>\n",
       "      <th>f1_conf_inter</th>\n",
       "      <th>model</th>\n",
       "      <th>noshots</th>\n",
       "      <th>prompt_technique</th>\n",
       "      <th>few_shot_tecnique</th>\n",
       "      <th>nb_few_shots</th>\n",
       "      <th>precision</th>\n",
       "      <th>plus_plus</th>\n",
       "      <th>verifier</th>\n",
       "      <th>len_data_train</th>\n",
       "      <th>len_data_test</th>\n",
       "      <th>nb_test_run</th>\n",
       "      <th>confidence_interval</th>\n",
       "      <th>distribution_used</th>\n",
       "      <th>precision_mean</th>\n",
       "      <th>precision_conf_inter</th>\n",
       "      <th>recall_mean</th>\n",
       "      <th>recall_conf_inter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.256</td>\n",
       "      <td>(nan, nan)</td>\n",
       "      <td>mistral-7b-v0.1</td>\n",
       "      <td>False</td>\n",
       "      <td>multi_prompt-get-entities-tagger</td>\n",
       "      <td>sentence</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>1383</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>Student</td>\n",
       "      <td>0.268</td>\n",
       "      <td>(nan, nan)</td>\n",
       "      <td>0.27</td>\n",
       "      <td>(nan, nan)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.245</td>\n",
       "      <td>(nan, nan)</td>\n",
       "      <td>mistral-7b-v0.1</td>\n",
       "      <td>False</td>\n",
       "      <td>filing</td>\n",
       "      <td>sentence</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>1383</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>Student</td>\n",
       "      <td>0.339</td>\n",
       "      <td>(nan, nan)</td>\n",
       "      <td>0.20</td>\n",
       "      <td>(nan, nan)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f1_mean f1_conf_inter            model  noshots  \\\n",
       "0    0.256    (nan, nan)  mistral-7b-v0.1    False   \n",
       "1    0.245    (nan, nan)  mistral-7b-v0.1    False   \n",
       "\n",
       "                   prompt_technique few_shot_tecnique  nb_few_shots  \\\n",
       "0  multi_prompt-get-entities-tagger          sentence             3   \n",
       "1                            filing          sentence             3   \n",
       "\n",
       "   precision  plus_plus verifier  len_data_train  len_data_test  nb_test_run  \\\n",
       "0      False      False     None            1383             20            1   \n",
       "1      False      False     None            1383             20            1   \n",
       "\n",
       "   confidence_interval distribution_used  precision_mean precision_conf_inter  \\\n",
       "0                 0.95           Student           0.268           (nan, nan)   \n",
       "1                 0.95           Student           0.339           (nan, nan)   \n",
       "\n",
       "   recall_mean recall_conf_inter  \n",
       "0         0.27        (nan, nan)  \n",
       "1         0.20        (nan, nan)  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./ner/saves/datasets/ontonote5_test_1403.pkl\n",
      "<ner.Datasets.OntoNotes5Dataset.OntoNote5Dataset object at 0x7f0608554490>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<ner.Datasets.OntoNotes5Dataset.OntoNote5Dataset at 0x7f0600b5bd00>,\n",
       " <ner.Datasets.OntoNotes5Dataset.OntoNote5Dataset at 0x7f0603a8a8f0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ontonote_get_test_cleaned_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

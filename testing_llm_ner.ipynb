{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with random\n",
      "      and discussion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|‚ñç         | 2/50 [00:00<00:04, 11.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### SYSTEM : The task is to extract named entites in a sentence.\n",
      "    A named entity refers to a specific, named object, concept, location, person, organization, or other entities that have a proper name. Named entities are typically unique and distinguishable entities that can be explicitly named or referred to in text. \n",
      "    The goal of named entity extraction is to identify and classify these entities within a given text.\n",
      "    We are working with 18 types of entities of the OntoNote5 dataset that are listed below with their description :\n",
      "        \"CARDINAL\": \"Numerals that do not fall under another type.\",\n",
      "        \"ORDINAL\": \"Words or expressions indicating order.\",\n",
      "        \"WORK_OF_ART\": \"Titles of creative works.\",\n",
      "        \"PERSON\": \"Names of people, including fictional and real characters.\",\n",
      "        \"LOC\": \"Geographical locations, both physical and political.\",\n",
      "        \"DATE\": \"Temporal expressions indicating dates or periods.\",\n",
      "        \"PERCENT\": \"Percentage values.\",\n",
      "        \"PRODUCT\": \"Names of products or services.\",\n",
      "        \"MONEY\": \"Monetary values, including currency symbols.\",\n",
      "        \"FAC\": \"Named facilities, such as buildings, airports, or highways.\",\n",
      "        \"TIME\": \"Temporal expressions indicating times of the day.\",\n",
      "        \"ORG\": \"Names of organizations, institutions, or companies.\",\n",
      "        \"QUANTITY\": \"Measurements or counts, including units.\",\n",
      "        \"LANGUAGE\": \"Names of languages.\",\n",
      "        \"GPE\": \"Geopolitical entities, such as countries, cities, or states.\",\n",
      "        \"LAW\": \"Legal references, including laws and legal concepts.\",\n",
      "        \"NORP\": \"Nationalities, religious, or political groups.\",\n",
      "        \"EVENT\": \"Named occurrences or incidents.\n",
      "### USER : I want you to extract all the named entities in the text and tag them with one of the tag of the OntoNote5 dataset.\n",
      "### ASSISTANT : What is the format of the output ?\n",
      "### USER : You have to output a python list of tuples. In each tuple, you have a the named entity and its own tag. For exemple, with the sentence \"Japan is a country\" as input, you would answer \"[('Japan', 'GPE')]\". \n",
      "### ASSISTANT : Can you provide me examples ?  \n",
      "### USER : There are examples : \n",
      "### INPUT : <start_input> In its severest test , the $ 60 billion of portfolio insurance in effect in the 1987 crash did n't work , as stock buyers disappeared and stock and futures prices became disconnected . <end_input>\n",
      "### OUTPUT : <start_output> [['$ 60 billion', 'MONEY'], ['1987', 'DATE']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> Today investigators say the pilot had confirmed with the control tower moments before taking off he had turned onto the correct runway but pilots behind him say he turned onto the wrong runway . <end_input>\n",
      "### OUTPUT : <start_output> [['Today', 'DATE']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> It is not only for , this kind of sudden road cave - in , it also includes , for instance , security incidents , ah , in our society , as well as natural disasters , ah , and including public health incidents . <end_input>\n",
      "### OUTPUT : <start_output> [] <end_output>\n",
      "\n",
      "### INPUT : <start_input> I have n't really delved into Barrie 's psyche from the biographical end , it 's Peter and Wendy as an extraordinary piece of writing that has always fascinated me . <end_input>\n",
      "### OUTPUT : <start_output> [['Barrie', 'PERSON'], ['Peter and Wendy', 'WORK_OF_ART']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> The industry is `` seeing a softening somewhat in volume and certainly in price in petrochemicals , '' Glenn Cox , president of Phillips Petroleum Co. , said in an interview . <end_input>\n",
      "### OUTPUT : <start_output> [['Glenn Cox', 'PERSON'], ['Phillips Petroleum Co.', 'ORG']] <end_output>\n",
      "\n",
      "### ASSISTANT : I will extract all the named entities in the text that has one of the 18 tags of the OntoNote5 dataset and output a python list of tuples containing the named entitiy and its own tag. Now provide me the sentence.\n",
      "### INPUT : <start_input> Committee member of the CCP Central Politburo , and Secretary of the Shanghai Municipal Party Committee , Bangguo Wu met with Brown this afternoon and introduced the progress and development prospects of reforms and opening up in Shanghai . <end_input>\n",
      "### OUTPUT : <start_output> [\n",
      "### SYSTEM : The task is to extract named entites in a sentence.\n",
      "    A named entity refers to a specific, named object, concept, location, person, organization, or other entities that have a proper name. Named entities are typically unique and distinguishable entities that can be explicitly named or referred to in text. \n",
      "    The goal of named entity extraction is to identify and classify these entities within a given text.\n",
      "    We are working with 18 types of entities of the OntoNote5 dataset that are listed below with their description :\n",
      "        \"CARDINAL\": \"Numerals that do not fall under another type.\",\n",
      "        \"ORDINAL\": \"Words or expressions indicating order.\",\n",
      "        \"WORK_OF_ART\": \"Titles of creative works.\",\n",
      "        \"PERSON\": \"Names of people, including fictional and real characters.\",\n",
      "        \"LOC\": \"Geographical locations, both physical and political.\",\n",
      "        \"DATE\": \"Temporal expressions indicating dates or periods.\",\n",
      "        \"PERCENT\": \"Percentage values.\",\n",
      "        \"PRODUCT\": \"Names of products or services.\",\n",
      "        \"MONEY\": \"Monetary values, including currency symbols.\",\n",
      "        \"FAC\": \"Named facilities, such as buildings, airports, or highways.\",\n",
      "        \"TIME\": \"Temporal expressions indicating times of the day.\",\n",
      "        \"ORG\": \"Names of organizations, institutions, or companies.\",\n",
      "        \"QUANTITY\": \"Measurements or counts, including units.\",\n",
      "        \"LANGUAGE\": \"Names of languages.\",\n",
      "        \"GPE\": \"Geopolitical entities, such as countries, cities, or states.\",\n",
      "        \"LAW\": \"Legal references, including laws and legal concepts.\",\n",
      "        \"NORP\": \"Nationalities, religious, or political groups.\",\n",
      "        \"EVENT\": \"Named occurrences or incidents.\n",
      "### USER : I want you to extract all the named entities in the text and tag them with one of the tag of the OntoNote5 dataset.\n",
      "### ASSISTANT : What is the format of the output ?\n",
      "### USER : You have to output a python list of tuples. In each tuple, you have a the named entity and its own tag. For exemple, with the sentence \"Japan is a country\" as input, you would answer \"[('Japan', 'GPE')]\". \n",
      "### ASSISTANT : Can you provide me examples ?  \n",
      "### USER : There are examples : \n",
      "### INPUT : <start_input> Its watchers are , on the whole , a disloyal group of channel - zapping `` grazers '' and news junkies , who spend an average of just 26 minutes a day watching CNN , according to audience research . <end_input>\n",
      "### OUTPUT : <start_output> [['just 26 minutes', 'TIME'], ['CNN', 'ORG']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> `` I would continue to look for a stable crude market , at least in futures '' trading , said William Hinton , an energy futures broker with Stotler & Co . <end_input>\n",
      "### OUTPUT : <start_output> [['William Hinton', 'PERSON'], ['Stotler & Co', 'ORG']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> For this is Arab land and its people are Arab , and the Zionists are the ones who occupied the land and came to us from all over the world with your help , yours , and that of the old imperial powers . <end_input>\n",
      "### OUTPUT : <start_output> [['Arab', 'NORP'], ['Arab', 'NORP'], ['Zionists', 'NORP']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> Last year , its foreign exchange income was up to more than 2.1 billion US dollars , and in the first half of this year exports again had new growth . <end_input>\n",
      "### OUTPUT : <start_output> [['Last year', 'DATE'], ['more than 2.1 billion US dollars', 'MONEY'], ['the first half of this year', 'DATE']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> Shortly before the visit , Mr. Boesky and Drexel representives had met with Financial Corp. officials and had signed a letter of intent to acquire the 51 % stake in the company . <end_input>\n",
      "### OUTPUT : <start_output> [['Boesky', 'PERSON'], ['Drexel', 'ORG'], ['Financial Corp.', 'ORG'], ['51 %', 'PERCENT']] <end_output>\n",
      "\n",
      "### ASSISTANT : I will extract all the named entities in the text that has one of the 18 tags of the OntoNote5 dataset and output a python list of tuples containing the named entitiy and its own tag. Now provide me the sentence.\n",
      "### INPUT : <start_input> But Mrs. Hills , speaking at a breakfast meeting of the American Chamber of Commerce in Japan on Saturday , stressed that the objective `` is not to get definitive action by spring or summer , it is rather to have a blueprint for action . '' <end_input>\n",
      "### OUTPUT : <start_output> [\n",
      "### SYSTEM : The task is to extract named entites in a sentence.\n",
      "    A named entity refers to a specific, named object, concept, location, person, organization, or other entities that have a proper name. Named entities are typically unique and distinguishable entities that can be explicitly named or referred to in text. \n",
      "    The goal of named entity extraction is to identify and classify these entities within a given text.\n",
      "    We are working with 18 types of entities of the OntoNote5 dataset that are listed below with their description :\n",
      "        \"CARDINAL\": \"Numerals that do not fall under another type.\",\n",
      "        \"ORDINAL\": \"Words or expressions indicating order.\",\n",
      "        \"WORK_OF_ART\": \"Titles of creative works.\",\n",
      "        \"PERSON\": \"Names of people, including fictional and real characters.\",\n",
      "        \"LOC\": \"Geographical locations, both physical and political.\",\n",
      "        \"DATE\": \"Temporal expressions indicating dates or periods.\",\n",
      "        \"PERCENT\": \"Percentage values.\",\n",
      "        \"PRODUCT\": \"Names of products or services.\",\n",
      "        \"MONEY\": \"Monetary values, including currency symbols.\",\n",
      "        \"FAC\": \"Named facilities, such as buildings, airports, or highways.\",\n",
      "        \"TIME\": \"Temporal expressions indicating times of the day.\",\n",
      "        \"ORG\": \"Names of organizations, institutions, or companies.\",\n",
      "        \"QUANTITY\": \"Measurements or counts, including units.\",\n",
      "        \"LANGUAGE\": \"Names of languages.\",\n",
      "        \"GPE\": \"Geopolitical entities, such as countries, cities, or states.\",\n",
      "        \"LAW\": \"Legal references, including laws and legal concepts.\",\n",
      "        \"NORP\": \"Nationalities, religious, or political groups.\",\n",
      "        \"EVENT\": \"Named occurrences or incidents.\n",
      "### USER : I want you to extract all the named entities in the text and tag them with one of the tag of the OntoNote5 dataset.\n",
      "### ASSISTANT : What is the format of the output ?\n",
      "### USER : You have to output a python list of tuples. In each tuple, you have a the named entity and its own tag. For exemple, with the sentence \"Japan is a country\" as input, you would answer \"[('Japan', 'GPE')]\". \n",
      "### ASSISTANT : Can you provide me examples ?  \n",
      "### USER : There are examples : \n",
      "### INPUT : <start_input> In a November 28 press release , the Mainland Affairs Council -LRB- MAC -RRB- , the government body in charge of cross-strait affairs , diplomatically stated that it would observe and implement the suggestions of the Advisory Group if and when they become official government policy . <end_input>\n",
      "### OUTPUT : <start_output> [['November 28', 'DATE'], ['the Mainland Affairs Council', 'ORG'], ['MAC', 'ORG'], ['the Advisory Group', 'ORG']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> We 're dealing with a Muslim Arab civilization right now that 's that 's in decline , that 's heading in the wrong direction in ways that are dangerous for them and I believe dangerous for the stability of the world /. <end_input>\n",
      "### OUTPUT : <start_output> [['Muslim Arab', 'NORP']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> Which by the way I believe you could have a separate bilateral face to face negotiation with the United States and also continue the efforts with the six party talks because it is the South Koreans and the Japanese that are providing financial and fuel incentives /. <end_input>\n",
      "### OUTPUT : <start_output> [['the United States', 'GPE'], ['six', 'CARDINAL'], ['the South Koreans', 'NORP'], ['Japanese', 'NORP']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> So the next day I got up at 7:00 and ran over to chat for an hour ; that guy was nice , did n't embarrass me , so after an hour it ended happily . <end_input>\n",
      "### OUTPUT : <start_output> [['7:00', 'TIME'], ['an hour', 'TIME'], ['an hour', 'TIME']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> Export credits , international financing leaseholds , compensation trades with foreign exchange repayment methods , overseas institution 's and individual 's foreign exchange deposits -LRB- excluding foreign exchange deposits in banks approved for offshore operations -RRB- , project financing , financing under trade projects over 90 days and other forms of foreign exchange loans will all be treated and managed as international commercial loans . <end_input>\n",
      "### OUTPUT : <start_output> [['over 90 days', 'DATE']] <end_output>\n",
      "\n",
      "### ASSISTANT : I will extract all the named entities in the text that has one of the 18 tags of the OntoNote5 dataset and output a python list of tuples containing the named entitiy and its own tag. Now provide me the sentence.\n",
      "### INPUT : <start_input> These two kinds of networks , says H.D. Yeh - who served as TBAD 's president for two terms - were instrumental in creating the \" Taiwanese economic miracle . \" <end_input>\n",
      "### OUTPUT : <start_output> [\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|‚ñä         | 4/50 [00:00<00:04, 10.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### SYSTEM : The task is to extract named entites in a sentence.\n",
      "    A named entity refers to a specific, named object, concept, location, person, organization, or other entities that have a proper name. Named entities are typically unique and distinguishable entities that can be explicitly named or referred to in text. \n",
      "    The goal of named entity extraction is to identify and classify these entities within a given text.\n",
      "    We are working with 18 types of entities of the OntoNote5 dataset that are listed below with their description :\n",
      "        \"CARDINAL\": \"Numerals that do not fall under another type.\",\n",
      "        \"ORDINAL\": \"Words or expressions indicating order.\",\n",
      "        \"WORK_OF_ART\": \"Titles of creative works.\",\n",
      "        \"PERSON\": \"Names of people, including fictional and real characters.\",\n",
      "        \"LOC\": \"Geographical locations, both physical and political.\",\n",
      "        \"DATE\": \"Temporal expressions indicating dates or periods.\",\n",
      "        \"PERCENT\": \"Percentage values.\",\n",
      "        \"PRODUCT\": \"Names of products or services.\",\n",
      "        \"MONEY\": \"Monetary values, including currency symbols.\",\n",
      "        \"FAC\": \"Named facilities, such as buildings, airports, or highways.\",\n",
      "        \"TIME\": \"Temporal expressions indicating times of the day.\",\n",
      "        \"ORG\": \"Names of organizations, institutions, or companies.\",\n",
      "        \"QUANTITY\": \"Measurements or counts, including units.\",\n",
      "        \"LANGUAGE\": \"Names of languages.\",\n",
      "        \"GPE\": \"Geopolitical entities, such as countries, cities, or states.\",\n",
      "        \"LAW\": \"Legal references, including laws and legal concepts.\",\n",
      "        \"NORP\": \"Nationalities, religious, or political groups.\",\n",
      "        \"EVENT\": \"Named occurrences or incidents.\n",
      "### USER : I want you to extract all the named entities in the text and tag them with one of the tag of the OntoNote5 dataset.\n",
      "### ASSISTANT : What is the format of the output ?\n",
      "### USER : You have to output a python list of tuples. In each tuple, you have a the named entity and its own tag. For exemple, with the sentence \"Japan is a country\" as input, you would answer \"[('Japan', 'GPE')]\". \n",
      "### ASSISTANT : Can you provide me examples ?  \n",
      "### USER : There are examples : \n",
      "### INPUT : <start_input> However , there is more to this matter , the whole world has to share the various negative effects caused by the US excessive energy consumption : global warming , and wars caused by oil , etc. <end_input>\n",
      "### OUTPUT : <start_output> [['US', 'GPE']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> In recent years cancer , sudden death and suicide have become all too common during middle age , which shows that the psychological problems of the middle - aged should not be overlooked . <end_input>\n",
      "### OUTPUT : <start_output> [] <end_output>\n",
      "\n",
      "### INPUT : <start_input> Yes , I think as we build this kind , er , of public , this kind of emergency mechanism for public incidents , ah , has been the , most difficult to resolve , an actual problem that has been the most difficult to resolve among administrative management reforms in various countries . <end_input>\n",
      "### OUTPUT : <start_output> [] <end_output>\n",
      "\n",
      "### INPUT : <start_input> With us from the Bush administration the third ranking official at the state department Ambassador Nicholas Burns The former Assistant Secretary of Defense Ashton Carter of Harvard University 's Kennedy school of government The man who led the negotiations for the nineteen ninety four nuclear agreement with North Korea Robert Gallucci Dean of the School of Foreign Service at Georgetown University And the former US Ambassador to the United Nations who has visited North Korea five times Governor Bill Richardson of New Mexico /. <end_input>\n",
      "### OUTPUT : <start_output> [['Bush', 'PERSON'], ['third', 'ORDINAL'], ['Nicholas Burns', 'PERSON'], ['Defense', 'ORG'], ['Ashton Carter', 'PERSON'], [\"Harvard University 's\", 'ORG'], ['Kennedy school of government', 'ORG'], ['nineteen ninety four', 'DATE'], ['North Korea', 'GPE'], ['Robert Gallucci', 'PERSON'], ['the School of Foreign Service', 'ORG'], ['Georgetown University', 'ORG'], ['US', 'GPE'], ['the United Nations', 'ORG'], ['North Korea', 'GPE'], ['five', 'CARDINAL'], ['Bill Richardson', 'PERSON'], ['New Mexico', 'GPE']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> A month ago , I was really desperate , I lost my current job , which I was completely unprepared for , and had to find a job within a month to keep myself going . <end_input>\n",
      "### OUTPUT : <start_output> [['A month ago', 'DATE'], ['a month', 'DATE']] <end_output>\n",
      "\n",
      "### ASSISTANT : I will extract all the named entities in the text that has one of the 18 tags of the OntoNote5 dataset and output a python list of tuples containing the named entitiy and its own tag. Now provide me the sentence.\n",
      "### INPUT : <start_input> The number of active drilling rigs in Canada is down 30 % from a year ago , and the number of completed oil wells is `` down more than that , due to the increasing focus on gas exploration , '' said Robert Feick , manager of crude oil with Calgary 's Independent Petroleum Association of Canada , an industry group . <end_input>\n",
      "### OUTPUT : <start_output> [\n",
      "### SYSTEM : The task is to extract named entites in a sentence.\n",
      "    A named entity refers to a specific, named object, concept, location, person, organization, or other entities that have a proper name. Named entities are typically unique and distinguishable entities that can be explicitly named or referred to in text. \n",
      "    The goal of named entity extraction is to identify and classify these entities within a given text.\n",
      "    We are working with 18 types of entities of the OntoNote5 dataset that are listed below with their description :\n",
      "        \"CARDINAL\": \"Numerals that do not fall under another type.\",\n",
      "        \"ORDINAL\": \"Words or expressions indicating order.\",\n",
      "        \"WORK_OF_ART\": \"Titles of creative works.\",\n",
      "        \"PERSON\": \"Names of people, including fictional and real characters.\",\n",
      "        \"LOC\": \"Geographical locations, both physical and political.\",\n",
      "        \"DATE\": \"Temporal expressions indicating dates or periods.\",\n",
      "        \"PERCENT\": \"Percentage values.\",\n",
      "        \"PRODUCT\": \"Names of products or services.\",\n",
      "        \"MONEY\": \"Monetary values, including currency symbols.\",\n",
      "        \"FAC\": \"Named facilities, such as buildings, airports, or highways.\",\n",
      "        \"TIME\": \"Temporal expressions indicating times of the day.\",\n",
      "        \"ORG\": \"Names of organizations, institutions, or companies.\",\n",
      "        \"QUANTITY\": \"Measurements or counts, including units.\",\n",
      "        \"LANGUAGE\": \"Names of languages.\",\n",
      "        \"GPE\": \"Geopolitical entities, such as countries, cities, or states.\",\n",
      "        \"LAW\": \"Legal references, including laws and legal concepts.\",\n",
      "        \"NORP\": \"Nationalities, religious, or political groups.\",\n",
      "        \"EVENT\": \"Named occurrences or incidents.\n",
      "### USER : I want you to extract all the named entities in the text and tag them with one of the tag of the OntoNote5 dataset.\n",
      "### ASSISTANT : What is the format of the output ?\n",
      "### USER : You have to output a python list of tuples. In each tuple, you have a the named entity and its own tag. For exemple, with the sentence \"Japan is a country\" as input, you would answer \"[('Japan', 'GPE')]\". \n",
      "### ASSISTANT : Can you provide me examples ?  \n",
      "### USER : There are examples : \n",
      "### INPUT : <start_input> In China , freedom , human rights , democracy , happiness and all the other most effective benefits that society can offer refer only to 20 % of the people . <end_input>\n",
      "### OUTPUT : <start_output> [['China', 'GPE'], ['20 %', 'PERCENT']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> As we heard from David Gregory , one of Governor Bush 's main themes in these last days of the campaign is getting rid of partisan gridlock in Washington , which was exactly what the President was talking about today -- an attempt to reopen debate on a $ 240 billion tax cut plan , saying the version House Republicans passed is unacceptable , because it is unfair , according to the President , to children and seniors . <end_input>\n",
      "### OUTPUT : <start_output> [['David Gregory', 'PERSON'], ['one', 'CARDINAL'], ['Bush', 'PERSON'], ['these last days', 'DATE'], ['Washington', 'GPE'], ['today', 'DATE'], ['$ 240 billion', 'MONEY'], ['House', 'ORG'], ['Republicans', 'NORP']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> We do have to try to reduce the violee and take a turn back for a period of calmness so that we can move back to a peace process , but even if the violence subsides , Israelis and Palestinians will still have to deal with an open wound -- a scar so long and so deep from these last two weeks , it may be years before there is a real effort at talking peace again . <end_input>\n",
      "### OUTPUT : <start_output> [['Israelis', 'NORP'], ['Palestinians', 'NORP'], ['these last two weeks', 'DATE'], ['years', 'DATE']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> Well , ah , if there is an accident , from the time it occurs until the time all traffic is cleared , it probably takes about half an hour to an hour during peak periods . <end_input>\n",
      "### OUTPUT : <start_output> [['about half an hour to an hour', 'TIME']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> Now kindred spirits on Addison 's town council have barred the town 's fanciest hotel , the Grand Kempinski , from installing three free pool tables in its new lounge . <end_input>\n",
      "### OUTPUT : <start_output> [['Addison', 'GPE'], ['the Grand Kempinski', 'ORG'], ['three', 'CARDINAL']] <end_output>\n",
      "\n",
      "### ASSISTANT : I will extract all the named entities in the text that has one of the 18 tags of the OntoNote5 dataset and output a python list of tuples containing the named entitiy and its own tag. Now provide me the sentence.\n",
      "### INPUT : <start_input> Various improved domestic and foreign varieties of flowers , fruits , trees , grasses , vegetables , fish , poultry , animals , etc. are successively settling down in Lingnan . <end_input>\n",
      "### OUTPUT : <start_output> [\n",
      "### SYSTEM : The task is to extract named entites in a sentence.\n",
      "    A named entity refers to a specific, named object, concept, location, person, organization, or other entities that have a proper name. Named entities are typically unique and distinguishable entities that can be explicitly named or referred to in text. \n",
      "    The goal of named entity extraction is to identify and classify these entities within a given text.\n",
      "    We are working with 18 types of entities of the OntoNote5 dataset that are listed below with their description :\n",
      "        \"CARDINAL\": \"Numerals that do not fall under another type.\",\n",
      "        \"ORDINAL\": \"Words or expressions indicating order.\",\n",
      "        \"WORK_OF_ART\": \"Titles of creative works.\",\n",
      "        \"PERSON\": \"Names of people, including fictional and real characters.\",\n",
      "        \"LOC\": \"Geographical locations, both physical and political.\",\n",
      "        \"DATE\": \"Temporal expressions indicating dates or periods.\",\n",
      "        \"PERCENT\": \"Percentage values.\",\n",
      "        \"PRODUCT\": \"Names of products or services.\",\n",
      "        \"MONEY\": \"Monetary values, including currency symbols.\",\n",
      "        \"FAC\": \"Named facilities, such as buildings, airports, or highways.\",\n",
      "        \"TIME\": \"Temporal expressions indicating times of the day.\",\n",
      "        \"ORG\": \"Names of organizations, institutions, or companies.\",\n",
      "        \"QUANTITY\": \"Measurements or counts, including units.\",\n",
      "        \"LANGUAGE\": \"Names of languages.\",\n",
      "        \"GPE\": \"Geopolitical entities, such as countries, cities, or states.\",\n",
      "        \"LAW\": \"Legal references, including laws and legal concepts.\",\n",
      "        \"NORP\": \"Nationalities, religious, or political groups.\",\n",
      "        \"EVENT\": \"Named occurrences or incidents.\n",
      "### USER : I want you to extract all the named entities in the text and tag them with one of the tag of the OntoNote5 dataset.\n",
      "### ASSISTANT : What is the format of the output ?\n",
      "### USER : You have to output a python list of tuples. In each tuple, you have a the named entity and its own tag. For exemple, with the sentence \"Japan is a country\" as input, you would answer \"[('Japan', 'GPE')]\". \n",
      "### ASSISTANT : Can you provide me examples ?  \n",
      "### USER : There are examples : \n",
      "### INPUT : <start_input> He tells how his father would have Michael join in at late - night hotel room meetings with `` important business people , '' and wondered whether `` something happened '' to Michael at those sessions . <end_input>\n",
      "### OUTPUT : <start_output> [['Michael', 'PERSON'], ['Michael', 'PERSON']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> When your seemingly nice neighbor , seemingly close friend , or a girl whose eyes can speak asks for it in the real world , how many people will answer with a \" no ? \" <end_input>\n",
      "### OUTPUT : <start_output> [] <end_output>\n",
      "\n",
      "### INPUT : <start_input> In the US , the money you pay for a meal at McDonald 's can fill up more than 10 liters of gas , but in Beijing you can get 5 - 6 liters of gas at most . <end_input>\n",
      "### OUTPUT : <start_output> [['US', 'GPE'], ['McDonald', 'ORG'], ['10 liters', 'QUANTITY'], ['Beijing', 'GPE'], ['5 - 6 liters', 'QUANTITY']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> It 's ironic that while their own lives are far more exotic than the fairy tales Wendy tells , it 's those fictions that they want , told by a mother . <end_input>\n",
      "### OUTPUT : <start_output> [['Wendy', 'PERSON']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> In 1984 the EPA notified Gulf Resources , which was a part - owner of the smelter , that it was potentially liable for sharing cleanup costs at the site under the federal Superfund program . <end_input>\n",
      "### OUTPUT : <start_output> [['1984', 'DATE'], ['EPA', 'ORG'], ['Gulf Resources', 'ORG'], ['Superfund', 'ORG']] <end_output>\n",
      "\n",
      "### ASSISTANT : I will extract all the named entities in the text that has one of the 18 tags of the OntoNote5 dataset and output a python list of tuples containing the named entitiy and its own tag. Now provide me the sentence.\n",
      "### INPUT : <start_input> As your editorial rightly pointed out , Samuel Pierce , former HUD secretary , and Lance Wilson , Mr. Pierce 's former aide , `` are currently being held up to scorn for taking the Fifth Amendment . <end_input>\n",
      "### OUTPUT : <start_output> [\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|‚ñà‚ñå        | 8/50 [00:00<00:03, 11.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### SYSTEM : The task is to extract named entites in a sentence.\n",
      "    A named entity refers to a specific, named object, concept, location, person, organization, or other entities that have a proper name. Named entities are typically unique and distinguishable entities that can be explicitly named or referred to in text. \n",
      "    The goal of named entity extraction is to identify and classify these entities within a given text.\n",
      "    We are working with 18 types of entities of the OntoNote5 dataset that are listed below with their description :\n",
      "        \"CARDINAL\": \"Numerals that do not fall under another type.\",\n",
      "        \"ORDINAL\": \"Words or expressions indicating order.\",\n",
      "        \"WORK_OF_ART\": \"Titles of creative works.\",\n",
      "        \"PERSON\": \"Names of people, including fictional and real characters.\",\n",
      "        \"LOC\": \"Geographical locations, both physical and political.\",\n",
      "        \"DATE\": \"Temporal expressions indicating dates or periods.\",\n",
      "        \"PERCENT\": \"Percentage values.\",\n",
      "        \"PRODUCT\": \"Names of products or services.\",\n",
      "        \"MONEY\": \"Monetary values, including currency symbols.\",\n",
      "        \"FAC\": \"Named facilities, such as buildings, airports, or highways.\",\n",
      "        \"TIME\": \"Temporal expressions indicating times of the day.\",\n",
      "        \"ORG\": \"Names of organizations, institutions, or companies.\",\n",
      "        \"QUANTITY\": \"Measurements or counts, including units.\",\n",
      "        \"LANGUAGE\": \"Names of languages.\",\n",
      "        \"GPE\": \"Geopolitical entities, such as countries, cities, or states.\",\n",
      "        \"LAW\": \"Legal references, including laws and legal concepts.\",\n",
      "        \"NORP\": \"Nationalities, religious, or political groups.\",\n",
      "        \"EVENT\": \"Named occurrences or incidents.\n",
      "### USER : I want you to extract all the named entities in the text and tag them with one of the tag of the OntoNote5 dataset.\n",
      "### ASSISTANT : What is the format of the output ?\n",
      "### USER : You have to output a python list of tuples. In each tuple, you have a the named entity and its own tag. For exemple, with the sentence \"Japan is a country\" as input, you would answer \"[('Japan', 'GPE')]\". \n",
      "### ASSISTANT : Can you provide me examples ?  \n",
      "### USER : There are examples : \n",
      "### INPUT : <start_input> And Carl Spielvogel , chief executive officer of Saatchi 's big Backer Spielvogel Bates advertising unit , said he had offered to lead a management buy - out of the company , but was rebuffed by Charles Saatchi . <end_input>\n",
      "### OUTPUT : <start_output> [['Carl Spielvogel', 'PERSON'], ['Saatchi', 'ORG'], ['Backer Spielvogel Bates', 'ORG'], ['Charles Saatchi', 'PERSON']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> The truth is that it 's very clear from the stories today that she could 've asked uh Scooter Libby to call her so that she could hear the timber of his voice earlier /. <end_input>\n",
      "### OUTPUT : <start_output> [['today', 'DATE'], ['Scooter Libby', 'PERSON']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> This wait lasted till 5:30pm , when the neighbor told me in a half - crying tone that there was an accident , and everyone else was intact , except his father , who was in hospital for fractures . <end_input>\n",
      "### OUTPUT : <start_output> [['5:30pm', 'TIME'], ['half', 'CARDINAL']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> The statistics quoted by the `` new '' Census Bureau report -LRB- garnered from 1984 to 1986 -RRB- are out of date , certainly as an average for the Northeast , and possibly for the rest of the country . <end_input>\n",
      "### OUTPUT : <start_output> [['Census Bureau', 'ORG'], ['1984', 'DATE'], ['1986', 'DATE'], ['Northeast', 'LOC']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> California 's utility companies are not able to generate all the power their customers need , so they have turned to outside suppliers and in the face of rising prices the state 's two largest utility firms have sunk more than eight billion dollars in debt . <end_input>\n",
      "### OUTPUT : <start_output> [['California', 'GPE'], ['two', 'CARDINAL'], ['more than eight billion dollars', 'MONEY']] <end_output>\n",
      "\n",
      "### ASSISTANT : I will extract all the named entities in the text that has one of the 18 tags of the OntoNote5 dataset and output a python list of tuples containing the named entitiy and its own tag. Now provide me the sentence.\n",
      "### INPUT : <start_input> The Iraq story which the media has placed on the back burner in recent months is simmering again as voters in that war torn country went to the polls yesterday to vote on a new constitution with the results yet to be counted /. <end_input>\n",
      "### OUTPUT : <start_output> [\n",
      "### SYSTEM : The task is to extract named entites in a sentence.\n",
      "    A named entity refers to a specific, named object, concept, location, person, organization, or other entities that have a proper name. Named entities are typically unique and distinguishable entities that can be explicitly named or referred to in text. \n",
      "    The goal of named entity extraction is to identify and classify these entities within a given text.\n",
      "    We are working with 18 types of entities of the OntoNote5 dataset that are listed below with their description :\n",
      "        \"CARDINAL\": \"Numerals that do not fall under another type.\",\n",
      "        \"ORDINAL\": \"Words or expressions indicating order.\",\n",
      "        \"WORK_OF_ART\": \"Titles of creative works.\",\n",
      "        \"PERSON\": \"Names of people, including fictional and real characters.\",\n",
      "        \"LOC\": \"Geographical locations, both physical and political.\",\n",
      "        \"DATE\": \"Temporal expressions indicating dates or periods.\",\n",
      "        \"PERCENT\": \"Percentage values.\",\n",
      "        \"PRODUCT\": \"Names of products or services.\",\n",
      "        \"MONEY\": \"Monetary values, including currency symbols.\",\n",
      "        \"FAC\": \"Named facilities, such as buildings, airports, or highways.\",\n",
      "        \"TIME\": \"Temporal expressions indicating times of the day.\",\n",
      "        \"ORG\": \"Names of organizations, institutions, or companies.\",\n",
      "        \"QUANTITY\": \"Measurements or counts, including units.\",\n",
      "        \"LANGUAGE\": \"Names of languages.\",\n",
      "        \"GPE\": \"Geopolitical entities, such as countries, cities, or states.\",\n",
      "        \"LAW\": \"Legal references, including laws and legal concepts.\",\n",
      "        \"NORP\": \"Nationalities, religious, or political groups.\",\n",
      "        \"EVENT\": \"Named occurrences or incidents.\n",
      "### USER : I want you to extract all the named entities in the text and tag them with one of the tag of the OntoNote5 dataset.\n",
      "### ASSISTANT : What is the format of the output ?\n",
      "### USER : You have to output a python list of tuples. In each tuple, you have a the named entity and its own tag. For exemple, with the sentence \"Japan is a country\" as input, you would answer \"[('Japan', 'GPE')]\". \n",
      "### ASSISTANT : Can you provide me examples ?  \n",
      "### USER : There are examples : \n",
      "### INPUT : <start_input> In particular , more terminals , such as , this cable television , ah , , this digital television , ah , and mobile phone SMS , are applied in e-government . <end_input>\n",
      "### OUTPUT : <start_output> [] <end_output>\n",
      "\n",
      "### INPUT : <start_input> French Foreign Minister Hubert Vedrine said Sunday that relieving the pressure on Belgrade 's devastated economy is the first step towards supporting the new President Vojislav Kostunica and reintegrating Yugoslavia into a democratic Europe . <end_input>\n",
      "### OUTPUT : <start_output> [['French', 'NORP'], ['Foreign', 'ORG'], ['Hubert Vedrine', 'PERSON'], ['Sunday', 'DATE'], ['Belgrade', 'GPE'], ['first', 'ORDINAL'], ['Vojislav Kostunica', 'PERSON'], ['Yugoslavia', 'GPE'], ['Europe', 'GPE']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> Businessmen from outside , smelling profits , have set up gaudy storefronts and neon signs , hoping to trade on Tanshui 's mystique to sell coffee , seafood , antiques , and snack foods . <end_input>\n",
      "### OUTPUT : <start_output> [['Tanshui', 'GPE']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> The 1987 crash brought the Reagan administration and Democratic lawmakers to the table for the first budget summit , resulting in a two - year plan to reduce the deficit by more than $ 76 billion -- even though the deficit actually rose by nearly $ 12 billion during that period . <end_input>\n",
      "### OUTPUT : <start_output> [['1987', 'DATE'], ['Reagan', 'PERSON'], ['Democratic', 'NORP'], ['first', 'ORDINAL'], ['two - year', 'DATE'], ['more than $ 76 billion', 'MONEY'], ['$ 12 billion', 'MONEY']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> I think if we are seriously attacked or threatened , that missile which was a test was geared to the United States or to our allies we have allied responsibilities with South Korea or Japan /. /. <end_input>\n",
      "### OUTPUT : <start_output> [['the United States', 'GPE'], ['South Korea', 'GPE'], ['Japan', 'GPE']] <end_output>\n",
      "\n",
      "### ASSISTANT : I will extract all the named entities in the text that has one of the 18 tags of the OntoNote5 dataset and output a python list of tuples containing the named entitiy and its own tag. Now provide me the sentence.\n",
      "### INPUT : <start_input> Tu , who has lived his whole life in the old neighborhood , has watched from his doorstep as old shops have refurbished themselves in modern style , and modern shops have adopted the look of the old . <end_input>\n",
      "### OUTPUT : <start_output> [\n",
      "### SYSTEM : The task is to extract named entites in a sentence.\n",
      "    A named entity refers to a specific, named object, concept, location, person, organization, or other entities that have a proper name. Named entities are typically unique and distinguishable entities that can be explicitly named or referred to in text. \n",
      "    The goal of named entity extraction is to identify and classify these entities within a given text.\n",
      "    We are working with 18 types of entities of the OntoNote5 dataset that are listed below with their description :\n",
      "        \"CARDINAL\": \"Numerals that do not fall under another type.\",\n",
      "        \"ORDINAL\": \"Words or expressions indicating order.\",\n",
      "        \"WORK_OF_ART\": \"Titles of creative works.\",\n",
      "        \"PERSON\": \"Names of people, including fictional and real characters.\",\n",
      "        \"LOC\": \"Geographical locations, both physical and political.\",\n",
      "        \"DATE\": \"Temporal expressions indicating dates or periods.\",\n",
      "        \"PERCENT\": \"Percentage values.\",\n",
      "        \"PRODUCT\": \"Names of products or services.\",\n",
      "        \"MONEY\": \"Monetary values, including currency symbols.\",\n",
      "        \"FAC\": \"Named facilities, such as buildings, airports, or highways.\",\n",
      "        \"TIME\": \"Temporal expressions indicating times of the day.\",\n",
      "        \"ORG\": \"Names of organizations, institutions, or companies.\",\n",
      "        \"QUANTITY\": \"Measurements or counts, including units.\",\n",
      "        \"LANGUAGE\": \"Names of languages.\",\n",
      "        \"GPE\": \"Geopolitical entities, such as countries, cities, or states.\",\n",
      "        \"LAW\": \"Legal references, including laws and legal concepts.\",\n",
      "        \"NORP\": \"Nationalities, religious, or political groups.\",\n",
      "        \"EVENT\": \"Named occurrences or incidents.\n",
      "### USER : I want you to extract all the named entities in the text and tag them with one of the tag of the OntoNote5 dataset.\n",
      "### ASSISTANT : What is the format of the output ?\n",
      "### USER : You have to output a python list of tuples. In each tuple, you have a the named entity and its own tag. For exemple, with the sentence \"Japan is a country\" as input, you would answer \"[('Japan', 'GPE')]\". \n",
      "### ASSISTANT : Can you provide me examples ?  \n",
      "### USER : There are examples : \n",
      "### INPUT : <start_input> `` There have been many preposterous reasons advanced to support a capital - gains tax cut , '' Sen. Mitchell said during his television appearance , `` but I suggest that is perhaps more than any of the others . <end_input>\n",
      "### OUTPUT : <start_output> [['Mitchell', 'PERSON']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> Happy couples and jilted lovers line the river , displaying their joy or sadness in their postures : two people 's shadows are melted together by the darkened river behind , while others stand alone on the riverbank like statues . <end_input>\n",
      "### OUTPUT : <start_output> [['two', 'CARDINAL']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> Apart from the enterovirus chip , which is already at the testing stage , the ITRI 's Molecular Biomedical Technology Division is also conducting research and development on biochip applications and technology . <end_input>\n",
      "### OUTPUT : <start_output> [[\"the ITRI 's Molecular Biomedical Technology Division\", 'ORG']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> These poor people , who struggle just to pay for the necessities of life , their children 's education , old age , illness and death , also have to pay income tax . <end_input>\n",
      "### OUTPUT : <start_output> [] <end_output>\n",
      "\n",
      "### INPUT : <start_input> Financial Corp. said it agreed to buy the bonds after a representative of Ivan F. Boesky Corp. visited it in November 1983 and said Financial Corp. could improve its financial condition by purchasing the bonds . <end_input>\n",
      "### OUTPUT : <start_output> [['Financial Corp.', 'ORG'], ['Ivan F. Boesky Corp.', 'ORG'], ['November 1983', 'DATE'], ['Financial Corp.', 'ORG']] <end_output>\n",
      "\n",
      "### ASSISTANT : I will extract all the named entities in the text that has one of the 18 tags of the OntoNote5 dataset and output a python list of tuples containing the named entitiy and its own tag. Now provide me the sentence.\n",
      "### INPUT : <start_input> Um you know um Judy 's always been a pioneer and an agent of change you know um and uh has been at the forefront of a lot of stories /. <end_input>\n",
      "### OUTPUT : <start_output> [\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|‚ñà‚ñà        | 10/50 [00:00<00:03, 11.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### SYSTEM : The task is to extract named entites in a sentence.\n",
      "    A named entity refers to a specific, named object, concept, location, person, organization, or other entities that have a proper name. Named entities are typically unique and distinguishable entities that can be explicitly named or referred to in text. \n",
      "    The goal of named entity extraction is to identify and classify these entities within a given text.\n",
      "    We are working with 18 types of entities of the OntoNote5 dataset that are listed below with their description :\n",
      "        \"CARDINAL\": \"Numerals that do not fall under another type.\",\n",
      "        \"ORDINAL\": \"Words or expressions indicating order.\",\n",
      "        \"WORK_OF_ART\": \"Titles of creative works.\",\n",
      "        \"PERSON\": \"Names of people, including fictional and real characters.\",\n",
      "        \"LOC\": \"Geographical locations, both physical and political.\",\n",
      "        \"DATE\": \"Temporal expressions indicating dates or periods.\",\n",
      "        \"PERCENT\": \"Percentage values.\",\n",
      "        \"PRODUCT\": \"Names of products or services.\",\n",
      "        \"MONEY\": \"Monetary values, including currency symbols.\",\n",
      "        \"FAC\": \"Named facilities, such as buildings, airports, or highways.\",\n",
      "        \"TIME\": \"Temporal expressions indicating times of the day.\",\n",
      "        \"ORG\": \"Names of organizations, institutions, or companies.\",\n",
      "        \"QUANTITY\": \"Measurements or counts, including units.\",\n",
      "        \"LANGUAGE\": \"Names of languages.\",\n",
      "        \"GPE\": \"Geopolitical entities, such as countries, cities, or states.\",\n",
      "        \"LAW\": \"Legal references, including laws and legal concepts.\",\n",
      "        \"NORP\": \"Nationalities, religious, or political groups.\",\n",
      "        \"EVENT\": \"Named occurrences or incidents.\n",
      "### USER : I want you to extract all the named entities in the text and tag them with one of the tag of the OntoNote5 dataset.\n",
      "### ASSISTANT : What is the format of the output ?\n",
      "### USER : You have to output a python list of tuples. In each tuple, you have a the named entity and its own tag. For exemple, with the sentence \"Japan is a country\" as input, you would answer \"[('Japan', 'GPE')]\". \n",
      "### ASSISTANT : Can you provide me examples ?  \n",
      "### USER : There are examples : \n",
      "### INPUT : <start_input> Rumsfeld began the conversation by saying Rumsfeld : I came to meet you to negotiate the situation in Iraq ; we have made contact with some of your followers inside and outside Iraq , they have advised us to listen to you . <end_input>\n",
      "### OUTPUT : <start_output> [['Rumsfeld', 'PERSON'], ['Rumsfeld', 'PERSON'], ['Iraq', 'GPE'], ['Iraq', 'GPE']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> Since 1991 when Shenzhen established the first standing talent market , such \" all - weather \" talent exchange organizations have rapidly spread in the Zhujiang Delta and all cities within the province . <end_input>\n",
      "### OUTPUT : <start_output> [['Since 1991', 'DATE'], ['Shenzhen', 'GPE'], ['first', 'ORDINAL'], ['the Zhujiang Delta', 'LOC']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> This is another thing that the Indians were glad to hear him say , and he also said that both India and Russia suffer from the same sort of terrorism , as he put it , referring of course to the separatist militancies in Chechnya and Russia and in Jammu and Kashmir . <end_input>\n",
      "### OUTPUT : <start_output> [['Indians', 'NORP'], ['India', 'GPE'], ['Russia', 'GPE'], ['Chechnya', 'GPE'], ['Russia', 'GPE'], ['Jammu', 'GPE'], ['Kashmir', 'GPE']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> And if China wants to eliminate unreported income , to date there is no sign of that , and there is no compelling evidence to explain when China might eliminate unreported income . <end_input>\n",
      "### OUTPUT : <start_output> [['China', 'GPE'], ['China', 'GPE']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> Rated single - A - 1 by Moody 's Investors Service Inc. and single - A by Standard & Poor 's Corp. , the non-callable issue will be sold through underwriters led by Merrill Lynch Capital Markets . <end_input>\n",
      "### OUTPUT : <start_output> [['1', 'CARDINAL'], [\"Moody 's Investors Service Inc.\", 'ORG'], [\"Standard & Poor 's Corp.\", 'ORG'], ['Merrill Lynch Capital Markets', 'ORG']] <end_output>\n",
      "\n",
      "### ASSISTANT : I will extract all the named entities in the text that has one of the 18 tags of the OntoNote5 dataset and output a python list of tuples containing the named entitiy and its own tag. Now provide me the sentence.\n",
      "### INPUT : <start_input> Invoking the Taiwanese business battle cry of \" victory to those who strive the hardest , \" 20,000 - 30,000 Taiwan expats in Dongguan have in little more than a decade turned a county of banana and lichee plantations into a big city with exports behind only Shenzhen 's and Shanghai 's . <end_input>\n",
      "### OUTPUT : <start_output> [\n",
      "### SYSTEM : The task is to extract named entites in a sentence.\n",
      "    A named entity refers to a specific, named object, concept, location, person, organization, or other entities that have a proper name. Named entities are typically unique and distinguishable entities that can be explicitly named or referred to in text. \n",
      "    The goal of named entity extraction is to identify and classify these entities within a given text.\n",
      "    We are working with 18 types of entities of the OntoNote5 dataset that are listed below with their description :\n",
      "        \"CARDINAL\": \"Numerals that do not fall under another type.\",\n",
      "        \"ORDINAL\": \"Words or expressions indicating order.\",\n",
      "        \"WORK_OF_ART\": \"Titles of creative works.\",\n",
      "        \"PERSON\": \"Names of people, including fictional and real characters.\",\n",
      "        \"LOC\": \"Geographical locations, both physical and political.\",\n",
      "        \"DATE\": \"Temporal expressions indicating dates or periods.\",\n",
      "        \"PERCENT\": \"Percentage values.\",\n",
      "        \"PRODUCT\": \"Names of products or services.\",\n",
      "        \"MONEY\": \"Monetary values, including currency symbols.\",\n",
      "        \"FAC\": \"Named facilities, such as buildings, airports, or highways.\",\n",
      "        \"TIME\": \"Temporal expressions indicating times of the day.\",\n",
      "        \"ORG\": \"Names of organizations, institutions, or companies.\",\n",
      "        \"QUANTITY\": \"Measurements or counts, including units.\",\n",
      "        \"LANGUAGE\": \"Names of languages.\",\n",
      "        \"GPE\": \"Geopolitical entities, such as countries, cities, or states.\",\n",
      "        \"LAW\": \"Legal references, including laws and legal concepts.\",\n",
      "        \"NORP\": \"Nationalities, religious, or political groups.\",\n",
      "        \"EVENT\": \"Named occurrences or incidents.\n",
      "### USER : I want you to extract all the named entities in the text and tag them with one of the tag of the OntoNote5 dataset.\n",
      "### ASSISTANT : What is the format of the output ?\n",
      "### USER : You have to output a python list of tuples. In each tuple, you have a the named entity and its own tag. For exemple, with the sentence \"Japan is a country\" as input, you would answer \"[('Japan', 'GPE')]\". \n",
      "### ASSISTANT : Can you provide me examples ?  \n",
      "### USER : There are examples : \n",
      "### INPUT : <start_input> Weatherford International Inc. said it canceled plans for a preferred - stock swap but may resume payment of dividends on the stock , and added that it expects to publicly offer about 10 million common shares . <end_input>\n",
      "### OUTPUT : <start_output> [['Weatherford International Inc.', 'ORG'], ['about 10 million', 'CARDINAL']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> Diplomats and analysts have commented that a joint investigation into the attack may in fact strengthen ties between the world super power and the poor , but strategic Arab state . <end_input>\n",
      "### OUTPUT : <start_output> [['Arab', 'NORP']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> I appreciate your candor and your capacity to build a knowledge base with each contributor adding to the thread that moves me in a sonambulant noiseless rush toward the truth . <end_input>\n",
      "### OUTPUT : <start_output> [] <end_output>\n",
      "\n",
      "### INPUT : <start_input> For instance , natural gas currently produced along the Gulf Coast is selling on the spot market for around $ 1.47 a thousand cubic feet , down 13 % from $ 1.69 a thousand cubic feet a year ago . <end_input>\n",
      "### OUTPUT : <start_output> [['the Gulf Coast', 'LOC'], ['around $ 1.47', 'MONEY'], ['a thousand cubic feet', 'QUANTITY'], ['13 %', 'PERCENT'], ['1.69', 'MONEY'], ['a thousand cubic feet', 'QUANTITY'], ['a year ago', 'DATE']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> The White House Office of Management and Budget , whose calculations determine whether the Gramm - Rudman targets are met , estimated that the House - passed deficit - reduction measure would cut the fiscal 1990 shortfall by $ 6.2 billion , almost half of the Congressional Budget Office 's estimate of $ 11.0 billion . <end_input>\n",
      "### OUTPUT : <start_output> [['The White House Office of Management and Budget', 'ORG'], ['Gramm - Rudman', 'LAW'], ['House', 'ORG'], ['fiscal 1990', 'DATE'], ['$ 6.2 billion', 'MONEY'], ['almost half', 'CARDINAL'], [\"the Congressional Budget Office 's\", 'ORG'], ['$ 11.0 billion', 'MONEY']] <end_output>\n",
      "\n",
      "### ASSISTANT : I will extract all the named entities in the text that has one of the 18 tags of the OntoNote5 dataset and output a python list of tuples containing the named entitiy and its own tag. Now provide me the sentence.\n",
      "### INPUT : <start_input> Additionally , the annual added value of light industry was 885.5 billion yuan , 11.5 % higher than that of last year ; the added value of heavy industry was 1.1621 trillion yuan , a 10.4 % growth . <end_input>\n",
      "### OUTPUT : <start_output> [\n",
      "### SYSTEM : The task is to extract named entites in a sentence.\n",
      "    A named entity refers to a specific, named object, concept, location, person, organization, or other entities that have a proper name. Named entities are typically unique and distinguishable entities that can be explicitly named or referred to in text. \n",
      "    The goal of named entity extraction is to identify and classify these entities within a given text.\n",
      "    We are working with 18 types of entities of the OntoNote5 dataset that are listed below with their description :\n",
      "        \"CARDINAL\": \"Numerals that do not fall under another type.\",\n",
      "        \"ORDINAL\": \"Words or expressions indicating order.\",\n",
      "        \"WORK_OF_ART\": \"Titles of creative works.\",\n",
      "        \"PERSON\": \"Names of people, including fictional and real characters.\",\n",
      "        \"LOC\": \"Geographical locations, both physical and political.\",\n",
      "        \"DATE\": \"Temporal expressions indicating dates or periods.\",\n",
      "        \"PERCENT\": \"Percentage values.\",\n",
      "        \"PRODUCT\": \"Names of products or services.\",\n",
      "        \"MONEY\": \"Monetary values, including currency symbols.\",\n",
      "        \"FAC\": \"Named facilities, such as buildings, airports, or highways.\",\n",
      "        \"TIME\": \"Temporal expressions indicating times of the day.\",\n",
      "        \"ORG\": \"Names of organizations, institutions, or companies.\",\n",
      "        \"QUANTITY\": \"Measurements or counts, including units.\",\n",
      "        \"LANGUAGE\": \"Names of languages.\",\n",
      "        \"GPE\": \"Geopolitical entities, such as countries, cities, or states.\",\n",
      "        \"LAW\": \"Legal references, including laws and legal concepts.\",\n",
      "        \"NORP\": \"Nationalities, religious, or political groups.\",\n",
      "        \"EVENT\": \"Named occurrences or incidents.\n",
      "### USER : I want you to extract all the named entities in the text and tag them with one of the tag of the OntoNote5 dataset.\n",
      "### ASSISTANT : What is the format of the output ?\n",
      "### USER : You have to output a python list of tuples. In each tuple, you have a the named entity and its own tag. For exemple, with the sentence \"Japan is a country\" as input, you would answer \"[('Japan', 'GPE')]\". \n",
      "### ASSISTANT : Can you provide me examples ?  \n",
      "### USER : There are examples : \n",
      "### INPUT : <start_input> People do n't know that when I was young I had dreadful protruding teeth , but now not only do my teeth no longer show , but the lines of my face have also softened . <end_input>\n",
      "### OUTPUT : <start_output> [] <end_output>\n",
      "\n",
      "### INPUT : <start_input> although the Bush administration 's rhetoric about Kim Jong - Il and his regime has sometimes seemed ferocious North Korea 's leaders seem to have concluded that the Bush North Korea policy consists mainly of empty words and that oft repeated warning need not be taken terribly seriously /. <end_input>\n",
      "### OUTPUT : <start_output> [['Bush', 'PERSON'], ['Kim Jong - Il', 'PERSON'], [\"North Korea 's\", 'GPE'], ['Bush', 'PERSON'], ['North Korea', 'GPE']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> He said that to be a fearless champion of social justice , as is expected of a journalist , the most important thing , apart from energy and vitality , is modesty . <end_input>\n",
      "### OUTPUT : <start_output> [] <end_output>\n",
      "\n",
      "### INPUT : <start_input> And that is the whole notion of the use of and abuse of confidential sources the protections that reporters do or do n't have and the propensity of uh the United States government to have more secrecy not less /. <end_input>\n",
      "### OUTPUT : <start_output> [['United States', 'GPE']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> We do have to try to reduce the violee and take a turn back for a period of calmness so that we can move back to a peace process , but even if the violence subsides , Israelis and Palestinians will still have to deal with an open wound -- a scar so long and so deep from these last two weeks , it may be years before there is a real effort at talking peace again . <end_input>\n",
      "### OUTPUT : <start_output> [['Israelis', 'NORP'], ['Palestinians', 'NORP'], ['these last two weeks', 'DATE'], ['years', 'DATE']] <end_output>\n",
      "\n",
      "### ASSISTANT : I will extract all the named entities in the text that has one of the 18 tags of the OntoNote5 dataset and output a python list of tuples containing the named entitiy and its own tag. Now provide me the sentence.\n",
      "### INPUT : <start_input> Renaissance , which manages about $ 1.8 billion , drew stiff criticism from many clients earlier this year because it pulled entirely out of stocks at the beginning of the year and thus missed a strong rally . <end_input>\n",
      "### OUTPUT : <start_output> [\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|‚ñà‚ñà‚ñä       | 14/50 [00:01<00:03, 11.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### SYSTEM : The task is to extract named entites in a sentence.\n",
      "    A named entity refers to a specific, named object, concept, location, person, organization, or other entities that have a proper name. Named entities are typically unique and distinguishable entities that can be explicitly named or referred to in text. \n",
      "    The goal of named entity extraction is to identify and classify these entities within a given text.\n",
      "    We are working with 18 types of entities of the OntoNote5 dataset that are listed below with their description :\n",
      "        \"CARDINAL\": \"Numerals that do not fall under another type.\",\n",
      "        \"ORDINAL\": \"Words or expressions indicating order.\",\n",
      "        \"WORK_OF_ART\": \"Titles of creative works.\",\n",
      "        \"PERSON\": \"Names of people, including fictional and real characters.\",\n",
      "        \"LOC\": \"Geographical locations, both physical and political.\",\n",
      "        \"DATE\": \"Temporal expressions indicating dates or periods.\",\n",
      "        \"PERCENT\": \"Percentage values.\",\n",
      "        \"PRODUCT\": \"Names of products or services.\",\n",
      "        \"MONEY\": \"Monetary values, including currency symbols.\",\n",
      "        \"FAC\": \"Named facilities, such as buildings, airports, or highways.\",\n",
      "        \"TIME\": \"Temporal expressions indicating times of the day.\",\n",
      "        \"ORG\": \"Names of organizations, institutions, or companies.\",\n",
      "        \"QUANTITY\": \"Measurements or counts, including units.\",\n",
      "        \"LANGUAGE\": \"Names of languages.\",\n",
      "        \"GPE\": \"Geopolitical entities, such as countries, cities, or states.\",\n",
      "        \"LAW\": \"Legal references, including laws and legal concepts.\",\n",
      "        \"NORP\": \"Nationalities, religious, or political groups.\",\n",
      "        \"EVENT\": \"Named occurrences or incidents.\n",
      "### USER : I want you to extract all the named entities in the text and tag them with one of the tag of the OntoNote5 dataset.\n",
      "### ASSISTANT : What is the format of the output ?\n",
      "### USER : You have to output a python list of tuples. In each tuple, you have a the named entity and its own tag. For exemple, with the sentence \"Japan is a country\" as input, you would answer \"[('Japan', 'GPE')]\". \n",
      "### ASSISTANT : Can you provide me examples ?  \n",
      "### USER : There are examples : \n",
      "### INPUT : <start_input> He sat out 1 term after losing a U.S Senate race in the 1960s , but for 24 terms , Yates represented Chicago 's northern lake front and northern suburbs . <end_input>\n",
      "### OUTPUT : <start_output> [['1', 'CARDINAL'], ['U.S Senate', 'ORG'], ['the 1960s', 'DATE'], ['24', 'CARDINAL'], ['Yates', 'PERSON'], ['Chicago', 'GPE']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> If you want to know what Gao Xingjian is all about , as a thinker and as an artist , our international book critic Christopher Meryl says Gao 's masterpiece is an ideal starting point . <end_input>\n",
      "### OUTPUT : <start_output> [['Gao Xingjian', 'PERSON'], ['Christopher Meryl', 'PERSON'], ['Gao', 'PERSON']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> In particular , more terminals , such as , this cable television , ah , , this digital television , ah , and mobile phone SMS , are applied in e-government . <end_input>\n",
      "### OUTPUT : <start_output> [] <end_output>\n",
      "\n",
      "### INPUT : <start_input> -LRB- Jackson was Geller 's best man in 2001 when he and his wife renewed his vows , the same year Geller is said to have been reactivated as a psychic spy . -RRB- <end_input>\n",
      "### OUTPUT : <start_output> [['Jackson', 'PERSON'], ['Geller', 'PERSON'], ['2001', 'DATE'], ['the same year', 'DATE'], ['Geller', 'PERSON']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> `` It seems to me that a story like this breaks just before every important Cocom meeting , '' said a Washington lobbyist for a number of U.S. computer companies . <end_input>\n",
      "### OUTPUT : <start_output> [['Cocom', 'ORG'], ['Washington', 'GPE'], ['U.S.', 'GPE']] <end_output>\n",
      "\n",
      "### ASSISTANT : I will extract all the named entities in the text that has one of the 18 tags of the OntoNote5 dataset and output a python list of tuples containing the named entitiy and its own tag. Now provide me the sentence.\n",
      "### INPUT : <start_input> If the dollar stays weak , he says , that will add to inflationary pressures in the U.S. and make it hard for the Federal Reserve Board to ease interest rates very much . <end_input>\n",
      "### OUTPUT : <start_output> [\n",
      "### SYSTEM : The task is to extract named entites in a sentence.\n",
      "    A named entity refers to a specific, named object, concept, location, person, organization, or other entities that have a proper name. Named entities are typically unique and distinguishable entities that can be explicitly named or referred to in text. \n",
      "    The goal of named entity extraction is to identify and classify these entities within a given text.\n",
      "    We are working with 18 types of entities of the OntoNote5 dataset that are listed below with their description :\n",
      "        \"CARDINAL\": \"Numerals that do not fall under another type.\",\n",
      "        \"ORDINAL\": \"Words or expressions indicating order.\",\n",
      "        \"WORK_OF_ART\": \"Titles of creative works.\",\n",
      "        \"PERSON\": \"Names of people, including fictional and real characters.\",\n",
      "        \"LOC\": \"Geographical locations, both physical and political.\",\n",
      "        \"DATE\": \"Temporal expressions indicating dates or periods.\",\n",
      "        \"PERCENT\": \"Percentage values.\",\n",
      "        \"PRODUCT\": \"Names of products or services.\",\n",
      "        \"MONEY\": \"Monetary values, including currency symbols.\",\n",
      "        \"FAC\": \"Named facilities, such as buildings, airports, or highways.\",\n",
      "        \"TIME\": \"Temporal expressions indicating times of the day.\",\n",
      "        \"ORG\": \"Names of organizations, institutions, or companies.\",\n",
      "        \"QUANTITY\": \"Measurements or counts, including units.\",\n",
      "        \"LANGUAGE\": \"Names of languages.\",\n",
      "        \"GPE\": \"Geopolitical entities, such as countries, cities, or states.\",\n",
      "        \"LAW\": \"Legal references, including laws and legal concepts.\",\n",
      "        \"NORP\": \"Nationalities, religious, or political groups.\",\n",
      "        \"EVENT\": \"Named occurrences or incidents.\n",
      "### USER : I want you to extract all the named entities in the text and tag them with one of the tag of the OntoNote5 dataset.\n",
      "### ASSISTANT : What is the format of the output ?\n",
      "### USER : You have to output a python list of tuples. In each tuple, you have a the named entity and its own tag. For exemple, with the sentence \"Japan is a country\" as input, you would answer \"[('Japan', 'GPE')]\". \n",
      "### ASSISTANT : Can you provide me examples ?  \n",
      "### USER : There are examples : \n",
      "### INPUT : <start_input> Developing at this rate , in the next ten years , not including graduates from higher education institutes , Guangdong 's talent gap is conservatively estimated to surpass 1 million . <end_input>\n",
      "### OUTPUT : <start_output> [['the next ten years', 'DATE'], ['Guangdong', 'GPE'], ['1 million', 'CARDINAL']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> `` The capability of existing fields to deliver oil is dropping , '' and oil exploration activity is also down dramatically , as many producers shift their emphasis to natural gas , said Ronald Watkins , vice president for government and industry relations with Interprovincial 's parent , Interhome Energy Inc . <end_input>\n",
      "### OUTPUT : <start_output> [['Ronald Watkins', 'PERSON'], ['Interprovincial', 'ORG'], ['Interhome Energy Inc', 'ORG']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> Through more than ten years ' market development , China has now become the world 's main down manufacturing country and down products export country , annually exporting nearly 30,000 tons of down and over 20 million down products , with earned foreign exchange reaching 820 million US dollars , including down clothing export values accounting for more than 50 % of total industry export values . <end_input>\n",
      "### OUTPUT : <start_output> [[\"more than ten years '\", 'DATE'], ['China', 'GPE'], ['nearly 30,000 tons', 'QUANTITY'], ['over 20 million', 'CARDINAL'], ['820 million US dollars', 'MONEY'], ['more than 50 %', 'PERCENT']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> But always , in years past , they have bucked the trend and have been able to pick up a fifth vote to eke out a number of major victories in civil rights and liberties cases . <end_input>\n",
      "### OUTPUT : <start_output> [['years past', 'DATE'], ['fifth', 'ORDINAL']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> From January to November of this year , the Shanghai 's total foreign trade export volume for the year reached 22.02 billion US dollars , increasing by 73 % compared with 1993 . <end_input>\n",
      "### OUTPUT : <start_output> [['January to November of this year', 'DATE'], ['Shanghai', 'GPE'], ['the year', 'DATE'], ['22.02 billion US dollars', 'MONEY'], ['73 %', 'PERCENT'], ['1993', 'DATE']] <end_output>\n",
      "\n",
      "### ASSISTANT : I will extract all the named entities in the text that has one of the 18 tags of the OntoNote5 dataset and output a python list of tuples containing the named entitiy and its own tag. Now provide me the sentence.\n",
      "### INPUT : <start_input> Developments such as the sequencing of the human genome and the rapid development of genetic engineering have spawned biotechnology industries like bioinformatics , biomaterials and pharmaceutical engineering , which have emerged as the rising stars of 21st - century industry . <end_input>\n",
      "### OUTPUT : <start_output> [\n",
      "### SYSTEM : The task is to extract named entites in a sentence.\n",
      "    A named entity refers to a specific, named object, concept, location, person, organization, or other entities that have a proper name. Named entities are typically unique and distinguishable entities that can be explicitly named or referred to in text. \n",
      "    The goal of named entity extraction is to identify and classify these entities within a given text.\n",
      "    We are working with 18 types of entities of the OntoNote5 dataset that are listed below with their description :\n",
      "        \"CARDINAL\": \"Numerals that do not fall under another type.\",\n",
      "        \"ORDINAL\": \"Words or expressions indicating order.\",\n",
      "        \"WORK_OF_ART\": \"Titles of creative works.\",\n",
      "        \"PERSON\": \"Names of people, including fictional and real characters.\",\n",
      "        \"LOC\": \"Geographical locations, both physical and political.\",\n",
      "        \"DATE\": \"Temporal expressions indicating dates or periods.\",\n",
      "        \"PERCENT\": \"Percentage values.\",\n",
      "        \"PRODUCT\": \"Names of products or services.\",\n",
      "        \"MONEY\": \"Monetary values, including currency symbols.\",\n",
      "        \"FAC\": \"Named facilities, such as buildings, airports, or highways.\",\n",
      "        \"TIME\": \"Temporal expressions indicating times of the day.\",\n",
      "        \"ORG\": \"Names of organizations, institutions, or companies.\",\n",
      "        \"QUANTITY\": \"Measurements or counts, including units.\",\n",
      "        \"LANGUAGE\": \"Names of languages.\",\n",
      "        \"GPE\": \"Geopolitical entities, such as countries, cities, or states.\",\n",
      "        \"LAW\": \"Legal references, including laws and legal concepts.\",\n",
      "        \"NORP\": \"Nationalities, religious, or political groups.\",\n",
      "        \"EVENT\": \"Named occurrences or incidents.\n",
      "### USER : I want you to extract all the named entities in the text and tag them with one of the tag of the OntoNote5 dataset.\n",
      "### ASSISTANT : What is the format of the output ?\n",
      "### USER : You have to output a python list of tuples. In each tuple, you have a the named entity and its own tag. For exemple, with the sentence \"Japan is a country\" as input, you would answer \"[('Japan', 'GPE')]\". \n",
      "### ASSISTANT : Can you provide me examples ?  \n",
      "### USER : There are examples : \n",
      "### INPUT : <start_input> Thus some people have set their sights on the biochip market , and believe that following Taiwan 's success in the semiconductor field , the island could go on to be a major center for contract manufacture of biochips . <end_input>\n",
      "### OUTPUT : <start_output> [['Taiwan', 'GPE']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> I suspect he is a brilliant cover or red - herring used as a shield by very powerful forces , responsible for God - knows - what at his now - abandoned ranch . <end_input>\n",
      "### OUTPUT : <start_output> [] <end_output>\n",
      "\n",
      "### INPUT : <start_input> Additionally , the company said it filed with the Securities and Exchange Commission for the proposed offering of 10 million shares of common stock , expected to be offered in November . <end_input>\n",
      "### OUTPUT : <start_output> [['the Securities and Exchange Commission', 'ORG'], ['10 million', 'CARDINAL'], ['November', 'DATE']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> And according to economics minister Lin Hsin - yi , the government recognizes that the \" go slow \" policy needs to be relaxed , and will give a more thorough accounting of this before the end of the year . <end_input>\n",
      "### OUTPUT : <start_output> [['Lin Hsin - yi', 'PERSON'], ['the end of the year', 'DATE']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> As the 1992 economic integration approaches , Europe 's cultural curators have taken to the ramparts against American `` cultural imperialism , '' threatening to impose quotas against such pop invaders as `` Dallas , '' `` Miami Vice '' and `` L.A. Law . '' <end_input>\n",
      "### OUTPUT : <start_output> [['1992', 'DATE'], ['Europe', 'LOC'], ['American', 'NORP'], ['Dallas', 'WORK_OF_ART'], ['Miami Vice', 'WORK_OF_ART'], ['L.A. Law', 'WORK_OF_ART']] <end_output>\n",
      "\n",
      "### ASSISTANT : I will extract all the named entities in the text that has one of the 18 tags of the OntoNote5 dataset and output a python list of tuples containing the named entitiy and its own tag. Now provide me the sentence.\n",
      "### INPUT : <start_input> Results of the Tuesday , October 10 , 1989 , auction of short - term U.S. government bills , sold at a discount from face value in units of $ 10,000 to $ 1 million : <end_input>\n",
      "### OUTPUT : <start_output> [\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|‚ñà‚ñà‚ñà‚ñè      | 16/50 [00:01<00:02, 11.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### SYSTEM : The task is to extract named entites in a sentence.\n",
      "    A named entity refers to a specific, named object, concept, location, person, organization, or other entities that have a proper name. Named entities are typically unique and distinguishable entities that can be explicitly named or referred to in text. \n",
      "    The goal of named entity extraction is to identify and classify these entities within a given text.\n",
      "    We are working with 18 types of entities of the OntoNote5 dataset that are listed below with their description :\n",
      "        \"CARDINAL\": \"Numerals that do not fall under another type.\",\n",
      "        \"ORDINAL\": \"Words or expressions indicating order.\",\n",
      "        \"WORK_OF_ART\": \"Titles of creative works.\",\n",
      "        \"PERSON\": \"Names of people, including fictional and real characters.\",\n",
      "        \"LOC\": \"Geographical locations, both physical and political.\",\n",
      "        \"DATE\": \"Temporal expressions indicating dates or periods.\",\n",
      "        \"PERCENT\": \"Percentage values.\",\n",
      "        \"PRODUCT\": \"Names of products or services.\",\n",
      "        \"MONEY\": \"Monetary values, including currency symbols.\",\n",
      "        \"FAC\": \"Named facilities, such as buildings, airports, or highways.\",\n",
      "        \"TIME\": \"Temporal expressions indicating times of the day.\",\n",
      "        \"ORG\": \"Names of organizations, institutions, or companies.\",\n",
      "        \"QUANTITY\": \"Measurements or counts, including units.\",\n",
      "        \"LANGUAGE\": \"Names of languages.\",\n",
      "        \"GPE\": \"Geopolitical entities, such as countries, cities, or states.\",\n",
      "        \"LAW\": \"Legal references, including laws and legal concepts.\",\n",
      "        \"NORP\": \"Nationalities, religious, or political groups.\",\n",
      "        \"EVENT\": \"Named occurrences or incidents.\n",
      "### USER : I want you to extract all the named entities in the text and tag them with one of the tag of the OntoNote5 dataset.\n",
      "### ASSISTANT : What is the format of the output ?\n",
      "### USER : You have to output a python list of tuples. In each tuple, you have a the named entity and its own tag. For exemple, with the sentence \"Japan is a country\" as input, you would answer \"[('Japan', 'GPE')]\". \n",
      "### ASSISTANT : Can you provide me examples ?  \n",
      "### USER : There are examples : \n",
      "### INPUT : <start_input> Professor Zhou , actually for such a large scale city as Beijing that has more than 14 million people , ah , for such a big city , a suddenly occurring public emergency like this should be said to be relatively common . <end_input>\n",
      "### OUTPUT : <start_output> [['Zhou', 'PERSON'], ['Beijing', 'GPE'], ['more than 14 million', 'CARDINAL']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> The reason they are picking that particular day is it allows , Brian , enough time for the aggrieved party , the losing party to file within 10 days a contest of the certification and that still allows enough time for the contest to be litigated through the courts primarily the circuit court and back to the Supreme Court if necessary and still meet the December 12 deadline for the Electoral College vote here . <end_input>\n",
      "### OUTPUT : <start_output> [['Brian', 'PERSON'], ['10 days', 'DATE'], ['the Supreme Court', 'ORG'], ['December 12', 'DATE'], ['Electoral College', 'ORG']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> We know that currently , many ministries and commissions , as well as people 's governments at the provincial level , along with those at municipal and district levels , have set up emergency contingency plans for public emergencies , but many of them have not been put to the test . <end_input>\n",
      "### OUTPUT : <start_output> [] <end_output>\n",
      "\n",
      "### INPUT : <start_input> The nation 's largest short - selling operation is Feshbach Brothers , Palo Alto , Calif. , which said last May that its short positions had shown losses of 10 % for the year up to that point . <end_input>\n",
      "### OUTPUT : <start_output> [['Feshbach Brothers', 'ORG'], ['Palo Alto', 'GPE'], ['Calif.', 'GPE'], ['last May', 'DATE'], ['10 %', 'PERCENT'], ['the year', 'DATE']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> At home , President Vojislav Kostunica says that he intends to promote democracy and free speech , but Kostunica just might have second thoughts , once a theater group that roasted his predecessor over the coals starts turning him on a spit . <end_input>\n",
      "### OUTPUT : <start_output> [['Vojislav Kostunica', 'PERSON'], ['Kostunica', 'PERSON'], ['second', 'ORDINAL']] <end_output>\n",
      "\n",
      "### ASSISTANT : I will extract all the named entities in the text that has one of the 18 tags of the OntoNote5 dataset and output a python list of tuples containing the named entitiy and its own tag. Now provide me the sentence.\n",
      "### INPUT : <start_input> The officials said that reports from the scene , including one from an Army officer working in Aden Harbor , suggested that a small rubber craft that was helping the Cole dock came alongside the destroyer and caused the blast . <end_input>\n",
      "### OUTPUT : <start_output> [\n",
      "### SYSTEM : The task is to extract named entites in a sentence.\n",
      "    A named entity refers to a specific, named object, concept, location, person, organization, or other entities that have a proper name. Named entities are typically unique and distinguishable entities that can be explicitly named or referred to in text. \n",
      "    The goal of named entity extraction is to identify and classify these entities within a given text.\n",
      "    We are working with 18 types of entities of the OntoNote5 dataset that are listed below with their description :\n",
      "        \"CARDINAL\": \"Numerals that do not fall under another type.\",\n",
      "        \"ORDINAL\": \"Words or expressions indicating order.\",\n",
      "        \"WORK_OF_ART\": \"Titles of creative works.\",\n",
      "        \"PERSON\": \"Names of people, including fictional and real characters.\",\n",
      "        \"LOC\": \"Geographical locations, both physical and political.\",\n",
      "        \"DATE\": \"Temporal expressions indicating dates or periods.\",\n",
      "        \"PERCENT\": \"Percentage values.\",\n",
      "        \"PRODUCT\": \"Names of products or services.\",\n",
      "        \"MONEY\": \"Monetary values, including currency symbols.\",\n",
      "        \"FAC\": \"Named facilities, such as buildings, airports, or highways.\",\n",
      "        \"TIME\": \"Temporal expressions indicating times of the day.\",\n",
      "        \"ORG\": \"Names of organizations, institutions, or companies.\",\n",
      "        \"QUANTITY\": \"Measurements or counts, including units.\",\n",
      "        \"LANGUAGE\": \"Names of languages.\",\n",
      "        \"GPE\": \"Geopolitical entities, such as countries, cities, or states.\",\n",
      "        \"LAW\": \"Legal references, including laws and legal concepts.\",\n",
      "        \"NORP\": \"Nationalities, religious, or political groups.\",\n",
      "        \"EVENT\": \"Named occurrences or incidents.\n",
      "### USER : I want you to extract all the named entities in the text and tag them with one of the tag of the OntoNote5 dataset.\n",
      "### ASSISTANT : What is the format of the output ?\n",
      "### USER : You have to output a python list of tuples. In each tuple, you have a the named entity and its own tag. For exemple, with the sentence \"Japan is a country\" as input, you would answer \"[('Japan', 'GPE')]\". \n",
      "### ASSISTANT : Can you provide me examples ?  \n",
      "### USER : There are examples : \n",
      "### INPUT : <start_input> Today investigators say the pilot had confirmed with the control tower moments before taking off he had turned onto the correct runway but pilots behind him say he turned onto the wrong runway . <end_input>\n",
      "### OUTPUT : <start_output> [['Today', 'DATE']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> CALTEX and Caterpillar from the US , Japan 's Itochu , South Korea 's Daewoo and the New World Consortium from Hong Kong had been successively entering the zone to invest and open business . <end_input>\n",
      "### OUTPUT : <start_output> [['CALTEX', 'ORG'], ['Caterpillar', 'ORG'], ['US', 'GPE'], ['Japan', 'GPE'], ['Itochu', 'ORG'], [\"South Korea 's\", 'GPE'], ['Daewoo', 'ORG'], ['the New World Consortium', 'ORG'], ['Hong Kong', 'GPE']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> One annual co-production , the three - hour - long `` Eurovision Song Contest , '' featuring soft - rock songs from each of 20 European countries , has been described as the world 's most boring TV show . <end_input>\n",
      "### OUTPUT : <start_output> [['One', 'CARDINAL'], ['annual', 'DATE'], ['three - hour', 'TIME'], ['Eurovision Song Contest', 'WORK_OF_ART'], ['20', 'CARDINAL'], ['European', 'NORP']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> Last year , its foreign exchange income was up to more than 2.1 billion US dollars , and in the first half of this year exports again had new growth . <end_input>\n",
      "### OUTPUT : <start_output> [['Last year', 'DATE'], ['more than 2.1 billion US dollars', 'MONEY'], ['the first half of this year', 'DATE']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> but first Judy Miller and the New York Times finally go public on the front page this morning with their nearly six thousand word account of the CIA leak investigation /. <end_input>\n",
      "### OUTPUT : <start_output> [['first', 'ORDINAL'], ['Judy Miller', 'PERSON'], ['the New York Times', 'ORG'], ['this morning', 'TIME'], ['nearly six thousand', 'CARDINAL'], ['CIA', 'ORG']] <end_output>\n",
      "\n",
      "### ASSISTANT : I will extract all the named entities in the text that has one of the 18 tags of the OntoNote5 dataset and output a python list of tuples containing the named entitiy and its own tag. Now provide me the sentence.\n",
      "### INPUT : <start_input> For enterprises whose assets do not offset debt and that are on the verge of bankruptcy , measures can be adopted for reorganization such as reorganizing enterprise management levels , changing methods of enterprise assets operation , and guiding the enterprise organization of structural adjustment , etc . <end_input>\n",
      "### OUTPUT : <start_output> [\n",
      "### SYSTEM : The task is to extract named entites in a sentence.\n",
      "    A named entity refers to a specific, named object, concept, location, person, organization, or other entities that have a proper name. Named entities are typically unique and distinguishable entities that can be explicitly named or referred to in text. \n",
      "    The goal of named entity extraction is to identify and classify these entities within a given text.\n",
      "    We are working with 18 types of entities of the OntoNote5 dataset that are listed below with their description :\n",
      "        \"CARDINAL\": \"Numerals that do not fall under another type.\",\n",
      "        \"ORDINAL\": \"Words or expressions indicating order.\",\n",
      "        \"WORK_OF_ART\": \"Titles of creative works.\",\n",
      "        \"PERSON\": \"Names of people, including fictional and real characters.\",\n",
      "        \"LOC\": \"Geographical locations, both physical and political.\",\n",
      "        \"DATE\": \"Temporal expressions indicating dates or periods.\",\n",
      "        \"PERCENT\": \"Percentage values.\",\n",
      "        \"PRODUCT\": \"Names of products or services.\",\n",
      "        \"MONEY\": \"Monetary values, including currency symbols.\",\n",
      "        \"FAC\": \"Named facilities, such as buildings, airports, or highways.\",\n",
      "        \"TIME\": \"Temporal expressions indicating times of the day.\",\n",
      "        \"ORG\": \"Names of organizations, institutions, or companies.\",\n",
      "        \"QUANTITY\": \"Measurements or counts, including units.\",\n",
      "        \"LANGUAGE\": \"Names of languages.\",\n",
      "        \"GPE\": \"Geopolitical entities, such as countries, cities, or states.\",\n",
      "        \"LAW\": \"Legal references, including laws and legal concepts.\",\n",
      "        \"NORP\": \"Nationalities, religious, or political groups.\",\n",
      "        \"EVENT\": \"Named occurrences or incidents.\n",
      "### USER : I want you to extract all the named entities in the text and tag them with one of the tag of the OntoNote5 dataset.\n",
      "### ASSISTANT : What is the format of the output ?\n",
      "### USER : You have to output a python list of tuples. In each tuple, you have a the named entity and its own tag. For exemple, with the sentence \"Japan is a country\" as input, you would answer \"[('Japan', 'GPE')]\". \n",
      "### ASSISTANT : Can you provide me examples ?  \n",
      "### USER : There are examples : \n",
      "### INPUT : <start_input> Instead of meeting us on common ground , instead of working with the White House or congressional Democrats , the Republican leadership closed its doors to compromise -- literally closed the doors to compromise . <end_input>\n",
      "### OUTPUT : <start_output> [['the White House', 'ORG'], ['Democrats', 'NORP'], ['Republican', 'NORP']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> Mr. Spielvogel had said that Prudential - Bache was prepared to finance either a management buy - out and restructuring , or a buy - out of Backer Spielvogel alone , led by him . <end_input>\n",
      "### OUTPUT : <start_output> [['Spielvogel', 'PERSON'], ['Prudential - Bache', 'ORG'], ['Backer Spielvogel', 'ORG']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> The company said Salomon Brothers Inc. and Howard , Weil , Labouisse , Friedrichs Inc. , underwriters for the offering , were granted an option to buy as much as an additional 1.5 million shares to cover over - allotments . <end_input>\n",
      "### OUTPUT : <start_output> [['Salomon Brothers Inc.', 'ORG'], ['Howard , Weil , Labouisse , Friedrichs Inc.', 'ORG'], ['as much as an additional 1.5 million', 'CARDINAL']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> Our production relations are no different from the production relations in Marx 's \" Das Kapital , \" constantly reproducing a proletariat who can only rely on selling its labor to make a living . <end_input>\n",
      "### OUTPUT : <start_output> [['Marx', 'PERSON'], ['Das Kapital', 'WORK_OF_ART']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> Nicky and Allison also have cerebral palsy , and their visit to Nickelodeon coincides with the network 's debut of `` Pelswick , '' an animated series about a 13 - year - old boy in a wheelchair . <end_input>\n",
      "### OUTPUT : <start_output> [['Nicky', 'PERSON'], ['Allison', 'PERSON'], ['Nickelodeon', 'ORG'], ['Pelswick', 'WORK_OF_ART'], ['13 - year - old', 'DATE']] <end_output>\n",
      "\n",
      "### ASSISTANT : I will extract all the named entities in the text that has one of the 18 tags of the OntoNote5 dataset and output a python list of tuples containing the named entitiy and its own tag. Now provide me the sentence.\n",
      "### INPUT : <start_input> Interprovincial , Canada 's biggest oil pipeline operator and a major transporter of crude to the U.S. , said revised industry forecasts indicate that Canadian oil output will total about 1.64 million barrels a day by 1991 , 8 % lower than a previous estimate . <end_input>\n",
      "### OUTPUT : <start_output> [\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 20/50 [00:01<00:02, 11.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### SYSTEM : The task is to extract named entites in a sentence.\n",
      "    A named entity refers to a specific, named object, concept, location, person, organization, or other entities that have a proper name. Named entities are typically unique and distinguishable entities that can be explicitly named or referred to in text. \n",
      "    The goal of named entity extraction is to identify and classify these entities within a given text.\n",
      "    We are working with 18 types of entities of the OntoNote5 dataset that are listed below with their description :\n",
      "        \"CARDINAL\": \"Numerals that do not fall under another type.\",\n",
      "        \"ORDINAL\": \"Words or expressions indicating order.\",\n",
      "        \"WORK_OF_ART\": \"Titles of creative works.\",\n",
      "        \"PERSON\": \"Names of people, including fictional and real characters.\",\n",
      "        \"LOC\": \"Geographical locations, both physical and political.\",\n",
      "        \"DATE\": \"Temporal expressions indicating dates or periods.\",\n",
      "        \"PERCENT\": \"Percentage values.\",\n",
      "        \"PRODUCT\": \"Names of products or services.\",\n",
      "        \"MONEY\": \"Monetary values, including currency symbols.\",\n",
      "        \"FAC\": \"Named facilities, such as buildings, airports, or highways.\",\n",
      "        \"TIME\": \"Temporal expressions indicating times of the day.\",\n",
      "        \"ORG\": \"Names of organizations, institutions, or companies.\",\n",
      "        \"QUANTITY\": \"Measurements or counts, including units.\",\n",
      "        \"LANGUAGE\": \"Names of languages.\",\n",
      "        \"GPE\": \"Geopolitical entities, such as countries, cities, or states.\",\n",
      "        \"LAW\": \"Legal references, including laws and legal concepts.\",\n",
      "        \"NORP\": \"Nationalities, religious, or political groups.\",\n",
      "        \"EVENT\": \"Named occurrences or incidents.\n",
      "### USER : I want you to extract all the named entities in the text and tag them with one of the tag of the OntoNote5 dataset.\n",
      "### ASSISTANT : What is the format of the output ?\n",
      "### USER : You have to output a python list of tuples. In each tuple, you have a the named entity and its own tag. For exemple, with the sentence \"Japan is a country\" as input, you would answer \"[('Japan', 'GPE')]\". \n",
      "### ASSISTANT : Can you provide me examples ?  \n",
      "### USER : There are examples : \n",
      "### INPUT : <start_input> The enterovirus detection biochip developed by DR. Chip Biotechnology takes only six hours to give hospitals the answer to whether a sample contains enterovirus , and if it is the deadly strain Entero 71 . <end_input>\n",
      "### OUTPUT : <start_output> [['DR. Chip Biotechnology', 'ORG'], ['only six hours', 'TIME']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> Weatherford suspended its preferred - dividend payment in October 1985 and said it has n't any plans to catch up on dividends in arrears about $ 6 million , but will do so some time in the future . <end_input>\n",
      "### OUTPUT : <start_output> [['Weatherford', 'ORG'], ['October 1985', 'DATE'], ['about $ 6 million', 'MONEY']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> On Yemeni TV today the country 's President expressed his heart - felt condolences to those who were killed and injured , but denied that the explosion on board the cole was caused by terrorists , although , admits Mohammed Al - Qadhi , editor of the Yemen Observer newspaper in the capital Sana , anti-American sentiment has been running high in Yemen because of events in the Middle East . <end_input>\n",
      "### OUTPUT : <start_output> [['Yemeni', 'NORP'], ['today', 'DATE'], ['cole', 'PRODUCT'], ['Mohammed Al - Qadhi', 'PERSON'], ['Yemen Observer', 'ORG'], ['Sana', 'GPE'], ['anti-American', 'NORP'], ['Yemen', 'GPE'], ['the Middle East', 'LOC']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> 4 . That the Journal defends `` the sleaze , fraud , waste , embezzlement , influence - peddling and abuse of the public that took place while Mr. Pierce was secretary of HUD , '' etc. and so forth . <end_input>\n",
      "### OUTPUT : <start_output> [['4', 'CARDINAL'], ['Journal', 'ORG'], ['Pierce', 'PERSON'], ['HUD', 'ORG']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> As the 1992 economic integration approaches , Europe 's cultural curators have taken to the ramparts against American `` cultural imperialism , '' threatening to impose quotas against such pop invaders as `` Dallas , '' `` Miami Vice '' and `` L.A. Law . '' <end_input>\n",
      "### OUTPUT : <start_output> [['1992', 'DATE'], ['Europe', 'LOC'], ['American', 'NORP'], ['Dallas', 'WORK_OF_ART'], ['Miami Vice', 'WORK_OF_ART'], ['L.A. Law', 'WORK_OF_ART']] <end_output>\n",
      "\n",
      "### ASSISTANT : I will extract all the named entities in the text that has one of the 18 tags of the OntoNote5 dataset and output a python list of tuples containing the named entitiy and its own tag. Now provide me the sentence.\n",
      "### INPUT : <start_input> With this in mind , Peck has developed nylon - based biochips which have been called \" the poor man 's biochip , \" since they cost a third less than glass chips . <end_input>\n",
      "### OUTPUT : <start_output> [\n",
      "### SYSTEM : The task is to extract named entites in a sentence.\n",
      "    A named entity refers to a specific, named object, concept, location, person, organization, or other entities that have a proper name. Named entities are typically unique and distinguishable entities that can be explicitly named or referred to in text. \n",
      "    The goal of named entity extraction is to identify and classify these entities within a given text.\n",
      "    We are working with 18 types of entities of the OntoNote5 dataset that are listed below with their description :\n",
      "        \"CARDINAL\": \"Numerals that do not fall under another type.\",\n",
      "        \"ORDINAL\": \"Words or expressions indicating order.\",\n",
      "        \"WORK_OF_ART\": \"Titles of creative works.\",\n",
      "        \"PERSON\": \"Names of people, including fictional and real characters.\",\n",
      "        \"LOC\": \"Geographical locations, both physical and political.\",\n",
      "        \"DATE\": \"Temporal expressions indicating dates or periods.\",\n",
      "        \"PERCENT\": \"Percentage values.\",\n",
      "        \"PRODUCT\": \"Names of products or services.\",\n",
      "        \"MONEY\": \"Monetary values, including currency symbols.\",\n",
      "        \"FAC\": \"Named facilities, such as buildings, airports, or highways.\",\n",
      "        \"TIME\": \"Temporal expressions indicating times of the day.\",\n",
      "        \"ORG\": \"Names of organizations, institutions, or companies.\",\n",
      "        \"QUANTITY\": \"Measurements or counts, including units.\",\n",
      "        \"LANGUAGE\": \"Names of languages.\",\n",
      "        \"GPE\": \"Geopolitical entities, such as countries, cities, or states.\",\n",
      "        \"LAW\": \"Legal references, including laws and legal concepts.\",\n",
      "        \"NORP\": \"Nationalities, religious, or political groups.\",\n",
      "        \"EVENT\": \"Named occurrences or incidents.\n",
      "### USER : I want you to extract all the named entities in the text and tag them with one of the tag of the OntoNote5 dataset.\n",
      "### ASSISTANT : What is the format of the output ?\n",
      "### USER : You have to output a python list of tuples. In each tuple, you have a the named entity and its own tag. For exemple, with the sentence \"Japan is a country\" as input, you would answer \"[('Japan', 'GPE')]\". \n",
      "### ASSISTANT : Can you provide me examples ?  \n",
      "### USER : There are examples : \n",
      "### INPUT : <start_input> `` Refining margins were so good in the third quarter of last year and generally not very good this year , '' said William Randol , a securities analyst at First Boston Corp . <end_input>\n",
      "### OUTPUT : <start_output> [['the third quarter of last year', 'DATE'], ['this year', 'DATE'], ['William Randol', 'PERSON'], ['First Boston Corp', 'ORG']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> 80 types of \" Dragon 's head merchandise \" such as clothing , textile products , vessels , steel , electronic computers , household electrical appliances , containers , etc. have developed quickly and account for more than half of the entire city 's export volume . <end_input>\n",
      "### OUTPUT : <start_output> [['80', 'CARDINAL']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> The good news is even though at any given point in time that there are these people out there perpetrating these crimes we are getting better at catching them and better at catching them sooner So that instead of waiting until they 've committed twelve crimes or instead of having twelve murders take place before we catch somebody now we may catch them after the first or second murder /. <end_input>\n",
      "### OUTPUT : <start_output> [['twelve', 'CARDINAL'], ['twelve', 'CARDINAL'], ['first', 'ORDINAL'], ['second', 'ORDINAL']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> We have not given up on this quest to come to the end of these negotiations and put the North Koreans back into a place where they can no longer be a threat to their neighbors or to the United States /. <end_input>\n",
      "### OUTPUT : <start_output> [['the North Koreans', 'NORP'], ['the United States', 'GPE']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> Unseasonably hot , dry weather across large portions of the Great Plains and in wheat - growing areas in Washington and Oregon is threatening to reduce the yield from this season 's winter wheat crop , said Conrad Leslie , a futures analyst and head of Leslie Analytical in Chicago . <end_input>\n",
      "### OUTPUT : <start_output> [['the Great Plains', 'LOC'], ['Washington', 'GPE'], ['Oregon', 'GPE'], ['season', 'DATE'], ['winter', 'DATE'], ['Conrad Leslie', 'PERSON'], ['Leslie Analytical', 'ORG'], ['Chicago', 'GPE']] <end_output>\n",
      "\n",
      "### ASSISTANT : I will extract all the named entities in the text that has one of the 18 tags of the OntoNote5 dataset and output a python list of tuples containing the named entitiy and its own tag. Now provide me the sentence.\n",
      "### INPUT : <start_input> Farmers who work in the city are generally a young workforce in their prime , while this is the period in which their children attend primary or junior high school . <end_input>\n",
      "### OUTPUT : <start_output> [\n",
      "### SYSTEM : The task is to extract named entites in a sentence.\n",
      "    A named entity refers to a specific, named object, concept, location, person, organization, or other entities that have a proper name. Named entities are typically unique and distinguishable entities that can be explicitly named or referred to in text. \n",
      "    The goal of named entity extraction is to identify and classify these entities within a given text.\n",
      "    We are working with 18 types of entities of the OntoNote5 dataset that are listed below with their description :\n",
      "        \"CARDINAL\": \"Numerals that do not fall under another type.\",\n",
      "        \"ORDINAL\": \"Words or expressions indicating order.\",\n",
      "        \"WORK_OF_ART\": \"Titles of creative works.\",\n",
      "        \"PERSON\": \"Names of people, including fictional and real characters.\",\n",
      "        \"LOC\": \"Geographical locations, both physical and political.\",\n",
      "        \"DATE\": \"Temporal expressions indicating dates or periods.\",\n",
      "        \"PERCENT\": \"Percentage values.\",\n",
      "        \"PRODUCT\": \"Names of products or services.\",\n",
      "        \"MONEY\": \"Monetary values, including currency symbols.\",\n",
      "        \"FAC\": \"Named facilities, such as buildings, airports, or highways.\",\n",
      "        \"TIME\": \"Temporal expressions indicating times of the day.\",\n",
      "        \"ORG\": \"Names of organizations, institutions, or companies.\",\n",
      "        \"QUANTITY\": \"Measurements or counts, including units.\",\n",
      "        \"LANGUAGE\": \"Names of languages.\",\n",
      "        \"GPE\": \"Geopolitical entities, such as countries, cities, or states.\",\n",
      "        \"LAW\": \"Legal references, including laws and legal concepts.\",\n",
      "        \"NORP\": \"Nationalities, religious, or political groups.\",\n",
      "        \"EVENT\": \"Named occurrences or incidents.\n",
      "### USER : I want you to extract all the named entities in the text and tag them with one of the tag of the OntoNote5 dataset.\n",
      "### ASSISTANT : What is the format of the output ?\n",
      "### USER : You have to output a python list of tuples. In each tuple, you have a the named entity and its own tag. For exemple, with the sentence \"Japan is a country\" as input, you would answer \"[('Japan', 'GPE')]\". \n",
      "### ASSISTANT : Can you provide me examples ?  \n",
      "### USER : There are examples : \n",
      "### INPUT : <start_input> My point is if it 's just going to be a face to face meeting that serves as a precursor that also deals with this frozen assets issue which has directly hit the North Korean regime cause it controls the foreign expenditures of Kim Jong - Il and you deal with this light water reactor especially now after we 've promised it to Iran and economic incentives to Iran I think the timing is right for this new stage of direct negotiation /. <end_input>\n",
      "### OUTPUT : <start_output> [['North Korean', 'NORP'], ['Kim Jong - Il', 'PERSON'], ['Iran', 'GPE'], ['Iran', 'GPE']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> By the end of the first quarter of this year , the registered capital of Guangzhou 's privately owned enterprises is 3.08 billion yuan , 24.97 % higher than that of the end of last year . <end_input>\n",
      "### OUTPUT : <start_output> [['the end of the first quarter of this year', 'DATE'], ['Guangzhou', 'GPE'], ['3.08 billion yuan', 'MONEY'], ['24.97 %', 'PERCENT'], ['the end of last year', 'DATE']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> On November 24 the New Party , which had already pulled out of the Advisory Group , published an article in the press signed by leading members such as Yu Mu - ming and Chen Kui - miao , in which they called on the government to take the constitution as its starting point for breaking the \" one China \" deadlock . <end_input>\n",
      "### OUTPUT : <start_output> [['November 24', 'DATE'], ['the New Party', 'ORG'], ['the Advisory Group', 'ORG'], ['Yu Mu - ming', 'PERSON'], ['Chen Kui - miao', 'PERSON'], ['one', 'CARDINAL'], ['China', 'GPE']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> Laiwu City has established a detoxification production base to carry out nursery detoxification on traditional products such as shallot , ginger and garlic , and after detoxification , the output of shallot , ginger and garlic has increased more than doubled . <end_input>\n",
      "### OUTPUT : <start_output> [['Laiwu City', 'GPE']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> Taiwan Genome Sciences -LRB- TGS -RRB- , which was set up in November 1999 as a joint venture by the Uni-President Enterprises Group , Yuen Foong Yu and Tuntex Groups , only entered the biotechnology fray in April of this year . <end_input>\n",
      "### OUTPUT : <start_output> [['Taiwan Genome Sciences', 'ORG'], ['TGS', 'ORG'], ['November 1999', 'DATE'], ['the Uni-President Enterprises Group', 'ORG'], ['Yuen Foong Yu', 'PERSON'], ['Tuntex Groups', 'ORG'], ['April of this year', 'DATE']] <end_output>\n",
      "\n",
      "### ASSISTANT : I will extract all the named entities in the text that has one of the 18 tags of the OntoNote5 dataset and output a python list of tuples containing the named entitiy and its own tag. Now provide me the sentence.\n",
      "### INPUT : <start_input> but he also said their instructions say that if they hear of any abuse they are to follow local laws , which usually requires them to inform the police ASAP . <end_input>\n",
      "### OUTPUT : <start_output> [\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 22/50 [00:01<00:02, 11.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### SYSTEM : The task is to extract named entites in a sentence.\n",
      "    A named entity refers to a specific, named object, concept, location, person, organization, or other entities that have a proper name. Named entities are typically unique and distinguishable entities that can be explicitly named or referred to in text. \n",
      "    The goal of named entity extraction is to identify and classify these entities within a given text.\n",
      "    We are working with 18 types of entities of the OntoNote5 dataset that are listed below with their description :\n",
      "        \"CARDINAL\": \"Numerals that do not fall under another type.\",\n",
      "        \"ORDINAL\": \"Words or expressions indicating order.\",\n",
      "        \"WORK_OF_ART\": \"Titles of creative works.\",\n",
      "        \"PERSON\": \"Names of people, including fictional and real characters.\",\n",
      "        \"LOC\": \"Geographical locations, both physical and political.\",\n",
      "        \"DATE\": \"Temporal expressions indicating dates or periods.\",\n",
      "        \"PERCENT\": \"Percentage values.\",\n",
      "        \"PRODUCT\": \"Names of products or services.\",\n",
      "        \"MONEY\": \"Monetary values, including currency symbols.\",\n",
      "        \"FAC\": \"Named facilities, such as buildings, airports, or highways.\",\n",
      "        \"TIME\": \"Temporal expressions indicating times of the day.\",\n",
      "        \"ORG\": \"Names of organizations, institutions, or companies.\",\n",
      "        \"QUANTITY\": \"Measurements or counts, including units.\",\n",
      "        \"LANGUAGE\": \"Names of languages.\",\n",
      "        \"GPE\": \"Geopolitical entities, such as countries, cities, or states.\",\n",
      "        \"LAW\": \"Legal references, including laws and legal concepts.\",\n",
      "        \"NORP\": \"Nationalities, religious, or political groups.\",\n",
      "        \"EVENT\": \"Named occurrences or incidents.\n",
      "### USER : I want you to extract all the named entities in the text and tag them with one of the tag of the OntoNote5 dataset.\n",
      "### ASSISTANT : What is the format of the output ?\n",
      "### USER : You have to output a python list of tuples. In each tuple, you have a the named entity and its own tag. For exemple, with the sentence \"Japan is a country\" as input, you would answer \"[('Japan', 'GPE')]\". \n",
      "### ASSISTANT : Can you provide me examples ?  \n",
      "### USER : There are examples : \n",
      "### INPUT : <start_input> News Now 's Susan Yakie spoke with our New Delhi correspondent Jim Teeple about the Russian leader 's visit and his comments about the situation in the disputed Kashmir region . <end_input>\n",
      "### OUTPUT : <start_output> [[\"News Now 's\", 'ORG'], ['Susan Yakie', 'PERSON'], ['New Delhi', 'GPE'], ['Jim Teeple', 'PERSON'], ['Russian', 'NORP'], ['Kashmir', 'GPE']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> The thrifts ' lawyers claim that the suits , numbering 700 to 1,000 in Texas alone , should be dismissed as moot because neither the S&Ls nor the extinct Federal Savings and Loan Insurance Corp. has the money to pay judgments . <end_input>\n",
      "### OUTPUT : <start_output> [['700 to 1,000', 'CARDINAL'], ['Texas', 'GPE'], ['Federal Savings and Loan Insurance Corp.', 'ORG']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> Regarding this , my standpoint is : because the socialism underpinned by planned economy , public ownership and the people 's democratic dictatorship is indeed a really \" fresh \" systemic thing for China in the mid and late 20th century -- without a model or sufficient experience or theories to refer to , no matter how scientific its kernel is , it is hard not to have certain superficial and local problems . <end_input>\n",
      "### OUTPUT : <start_output> [['China', 'GPE'], ['the mid and late 20th century', 'DATE']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> In a new report , the Secretary General says democratization has now taken root as a universal norm and that the United Nations should strengthen its commitment to assisting nations that are moving toward democracy . <end_input>\n",
      "### OUTPUT : <start_output> [['the United Nations', 'ORG']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> For instance , the Finnish government has allocated 1 million US dollars as a subsidy for the preliminary work of the Tumen River Development ; Sweden has put forth funding to do feasibility studies on the linking of the Chinese and Mongolian railways and the construction of a new Northeast Asian continental bridge . <end_input>\n",
      "### OUTPUT : <start_output> [['Finnish', 'NORP'], ['1 million US dollars', 'MONEY'], ['the Tumen River Development', 'GPE'], ['Sweden', 'GPE'], ['Chinese', 'NORP'], ['Mongolian', 'NORP'], ['Northeast Asian', 'NORP']] <end_output>\n",
      "\n",
      "### ASSISTANT : I will extract all the named entities in the text that has one of the 18 tags of the OntoNote5 dataset and output a python list of tuples containing the named entitiy and its own tag. Now provide me the sentence.\n",
      "### INPUT : <start_input> Since Qingdao Beer and Shandong Huaneng succeeded in respectively issuing H - shares and N - shares in Hong Kong and the US , last year , 5 more share - holding companies , such as Shandong 's Chenmin Paper Manufacturing Group , Jinan 's Qingqi Group , Yantai 's Zhangyu Group , Xinhua 's Pharmacy Group and Lutai 's Textile Group , etc. also entered the market issuing foreign capital shares , altogether attracting 265 million US dollars of foreign capital . <end_input>\n",
      "### OUTPUT : <start_output> [\n",
      "### SYSTEM : The task is to extract named entites in a sentence.\n",
      "    A named entity refers to a specific, named object, concept, location, person, organization, or other entities that have a proper name. Named entities are typically unique and distinguishable entities that can be explicitly named or referred to in text. \n",
      "    The goal of named entity extraction is to identify and classify these entities within a given text.\n",
      "    We are working with 18 types of entities of the OntoNote5 dataset that are listed below with their description :\n",
      "        \"CARDINAL\": \"Numerals that do not fall under another type.\",\n",
      "        \"ORDINAL\": \"Words or expressions indicating order.\",\n",
      "        \"WORK_OF_ART\": \"Titles of creative works.\",\n",
      "        \"PERSON\": \"Names of people, including fictional and real characters.\",\n",
      "        \"LOC\": \"Geographical locations, both physical and political.\",\n",
      "        \"DATE\": \"Temporal expressions indicating dates or periods.\",\n",
      "        \"PERCENT\": \"Percentage values.\",\n",
      "        \"PRODUCT\": \"Names of products or services.\",\n",
      "        \"MONEY\": \"Monetary values, including currency symbols.\",\n",
      "        \"FAC\": \"Named facilities, such as buildings, airports, or highways.\",\n",
      "        \"TIME\": \"Temporal expressions indicating times of the day.\",\n",
      "        \"ORG\": \"Names of organizations, institutions, or companies.\",\n",
      "        \"QUANTITY\": \"Measurements or counts, including units.\",\n",
      "        \"LANGUAGE\": \"Names of languages.\",\n",
      "        \"GPE\": \"Geopolitical entities, such as countries, cities, or states.\",\n",
      "        \"LAW\": \"Legal references, including laws and legal concepts.\",\n",
      "        \"NORP\": \"Nationalities, religious, or political groups.\",\n",
      "        \"EVENT\": \"Named occurrences or incidents.\n",
      "### USER : I want you to extract all the named entities in the text and tag them with one of the tag of the OntoNote5 dataset.\n",
      "### ASSISTANT : What is the format of the output ?\n",
      "### USER : You have to output a python list of tuples. In each tuple, you have a the named entity and its own tag. For exemple, with the sentence \"Japan is a country\" as input, you would answer \"[('Japan', 'GPE')]\". \n",
      "### ASSISTANT : Can you provide me examples ?  \n",
      "### USER : There are examples : \n",
      "### INPUT : <start_input> Of course , many children of poor people are able to get rich , but this came about because the parents struggled harder , tightening their belts and \" skimping on food and clothing \" for themselves . <end_input>\n",
      "### OUTPUT : <start_output> [] <end_output>\n",
      "\n",
      "### INPUT : <start_input> When your seemingly nice neighbor , seemingly close friend , or a girl whose eyes can speak asks for it in the real world , how many people will answer with a \" no ? \" <end_input>\n",
      "### OUTPUT : <start_output> [] <end_output>\n",
      "\n",
      "### INPUT : <start_input> While the situation of peasant workers in the city has repeatedly put society into question , the phenomenon of left - behind children in rural areas has gradually entered the view of the public . <end_input>\n",
      "### OUTPUT : <start_output> [] <end_output>\n",
      "\n",
      "### INPUT : <start_input> Also missing from the Senate bill is the House 's repeal of a law , called Section 89 , that compels companies to give rank - and - file workers comparable health benefits to top paid executives . <end_input>\n",
      "### OUTPUT : <start_output> [['Senate', 'ORG'], ['House', 'ORG'], ['Section 89', 'LAW']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> Truly , the foundation of disabled sports in China is not very strong , popularization is not yet widespread , and compared with some developed countries , still has a large gap . <end_input>\n",
      "### OUTPUT : <start_output> [['China', 'GPE']] <end_output>\n",
      "\n",
      "### ASSISTANT : I will extract all the named entities in the text that has one of the 18 tags of the OntoNote5 dataset and output a python list of tuples containing the named entitiy and its own tag. Now provide me the sentence.\n",
      "### INPUT : <start_input> I always thought the best compliment you could get as a journalist is when you told the Lebanese something they did n't know because you were moving around so much /. <end_input>\n",
      "### OUTPUT : <start_output> [\n",
      "### SYSTEM : The task is to extract named entites in a sentence.\n",
      "    A named entity refers to a specific, named object, concept, location, person, organization, or other entities that have a proper name. Named entities are typically unique and distinguishable entities that can be explicitly named or referred to in text. \n",
      "    The goal of named entity extraction is to identify and classify these entities within a given text.\n",
      "    We are working with 18 types of entities of the OntoNote5 dataset that are listed below with their description :\n",
      "        \"CARDINAL\": \"Numerals that do not fall under another type.\",\n",
      "        \"ORDINAL\": \"Words or expressions indicating order.\",\n",
      "        \"WORK_OF_ART\": \"Titles of creative works.\",\n",
      "        \"PERSON\": \"Names of people, including fictional and real characters.\",\n",
      "        \"LOC\": \"Geographical locations, both physical and political.\",\n",
      "        \"DATE\": \"Temporal expressions indicating dates or periods.\",\n",
      "        \"PERCENT\": \"Percentage values.\",\n",
      "        \"PRODUCT\": \"Names of products or services.\",\n",
      "        \"MONEY\": \"Monetary values, including currency symbols.\",\n",
      "        \"FAC\": \"Named facilities, such as buildings, airports, or highways.\",\n",
      "        \"TIME\": \"Temporal expressions indicating times of the day.\",\n",
      "        \"ORG\": \"Names of organizations, institutions, or companies.\",\n",
      "        \"QUANTITY\": \"Measurements or counts, including units.\",\n",
      "        \"LANGUAGE\": \"Names of languages.\",\n",
      "        \"GPE\": \"Geopolitical entities, such as countries, cities, or states.\",\n",
      "        \"LAW\": \"Legal references, including laws and legal concepts.\",\n",
      "        \"NORP\": \"Nationalities, religious, or political groups.\",\n",
      "        \"EVENT\": \"Named occurrences or incidents.\n",
      "### USER : I want you to extract all the named entities in the text and tag them with one of the tag of the OntoNote5 dataset.\n",
      "### ASSISTANT : What is the format of the output ?\n",
      "### USER : You have to output a python list of tuples. In each tuple, you have a the named entity and its own tag. For exemple, with the sentence \"Japan is a country\" as input, you would answer \"[('Japan', 'GPE')]\". \n",
      "### ASSISTANT : Can you provide me examples ?  \n",
      "### USER : There are examples : \n",
      "### INPUT : <start_input> True , you do not have neither a civilization nor history , but all that can not excuse your thefts and your hatred of Iraq 's civilization and Iraq 's riches . <end_input>\n",
      "### OUTPUT : <start_output> [['Iraq', 'GPE'], ['Iraq', 'GPE']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> Finally , the tarp drops , and it is , of course , a gargantuan , bronze statue of Michael , fists clenched defiantly , his star insignia prominent , yet his face still somehow child - like and unthreatening . <end_input>\n",
      "### OUTPUT : <start_output> [['Michael', 'PERSON']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> They never expected that the luggage carts would in fact make it much easier for customers to find them in sprawling Hong Kong airport and would become an easily recognizable company trademark . <end_input>\n",
      "### OUTPUT : <start_output> [['Hong Kong', 'GPE']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> Therefore , no matter from the perspective of average citizens or from the standpoint of the founder of the new government , we should respect and develop her on the basis of inheritance , innovation and improvement . <end_input>\n",
      "### OUTPUT : <start_output> [] <end_output>\n",
      "\n",
      "### INPUT : <start_input> I did not expect anyone to kill the dancer unless good would come of it , but like the most idiots his aim was correct but the method was wrong . <end_input>\n",
      "### OUTPUT : <start_output> [] <end_output>\n",
      "\n",
      "### ASSISTANT : I will extract all the named entities in the text that has one of the 18 tags of the OntoNote5 dataset and output a python list of tuples containing the named entitiy and its own tag. Now provide me the sentence.\n",
      "### INPUT : <start_input> `` It has n't had any impact on us , nor do we expect it to , '' said a spokeswoman for Miller Brewing Co. , a major client of Backer Spielvogel . <end_input>\n",
      "### OUTPUT : <start_output> [\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 26/50 [00:02<00:01, 12.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### SYSTEM : The task is to extract named entites in a sentence.\n",
      "    A named entity refers to a specific, named object, concept, location, person, organization, or other entities that have a proper name. Named entities are typically unique and distinguishable entities that can be explicitly named or referred to in text. \n",
      "    The goal of named entity extraction is to identify and classify these entities within a given text.\n",
      "    We are working with 18 types of entities of the OntoNote5 dataset that are listed below with their description :\n",
      "        \"CARDINAL\": \"Numerals that do not fall under another type.\",\n",
      "        \"ORDINAL\": \"Words or expressions indicating order.\",\n",
      "        \"WORK_OF_ART\": \"Titles of creative works.\",\n",
      "        \"PERSON\": \"Names of people, including fictional and real characters.\",\n",
      "        \"LOC\": \"Geographical locations, both physical and political.\",\n",
      "        \"DATE\": \"Temporal expressions indicating dates or periods.\",\n",
      "        \"PERCENT\": \"Percentage values.\",\n",
      "        \"PRODUCT\": \"Names of products or services.\",\n",
      "        \"MONEY\": \"Monetary values, including currency symbols.\",\n",
      "        \"FAC\": \"Named facilities, such as buildings, airports, or highways.\",\n",
      "        \"TIME\": \"Temporal expressions indicating times of the day.\",\n",
      "        \"ORG\": \"Names of organizations, institutions, or companies.\",\n",
      "        \"QUANTITY\": \"Measurements or counts, including units.\",\n",
      "        \"LANGUAGE\": \"Names of languages.\",\n",
      "        \"GPE\": \"Geopolitical entities, such as countries, cities, or states.\",\n",
      "        \"LAW\": \"Legal references, including laws and legal concepts.\",\n",
      "        \"NORP\": \"Nationalities, religious, or political groups.\",\n",
      "        \"EVENT\": \"Named occurrences or incidents.\n",
      "### USER : I want you to extract all the named entities in the text and tag them with one of the tag of the OntoNote5 dataset.\n",
      "### ASSISTANT : What is the format of the output ?\n",
      "### USER : You have to output a python list of tuples. In each tuple, you have a the named entity and its own tag. For exemple, with the sentence \"Japan is a country\" as input, you would answer \"[('Japan', 'GPE')]\". \n",
      "### ASSISTANT : Can you provide me examples ?  \n",
      "### USER : There are examples : \n",
      "### INPUT : <start_input> A month ago , I was really desperate , I lost my current job , which I was completely unprepared for , and had to find a job within a month to keep myself going . <end_input>\n",
      "### OUTPUT : <start_output> [['A month ago', 'DATE'], ['a month', 'DATE']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> This should be a motif familiar to anyone acquainted with the literature of mind control and ritual abuse survivors : the father and first controller , passing his child - victim up the social ladder of abuse in return for status , protection and reward . <end_input>\n",
      "### OUTPUT : <start_output> [] <end_output>\n",
      "\n",
      "### INPUT : <start_input> The cream of the British crop , the literary dramas that are shown on U.S. public television as `` Masterpiece Theater , '' make up a relatively small part of British air time . <end_input>\n",
      "### OUTPUT : <start_output> [['British', 'NORP'], ['U.S.', 'GPE'], ['Masterpiece Theater', 'WORK_OF_ART'], ['British', 'NORP']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> I do n't agree with that view because I think it 's more immoral to let North Korea go nuclear than to try to reach a deal with North Korea /. <end_input>\n",
      "### OUTPUT : <start_output> [['North Korea', 'GPE'], ['North Korea', 'GPE']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> Conventional insurance lines such as transportation insurance , property insurance , automobile insurance , etc. are specially offered to foreign funded enterprises such as the Zhengda Company and the Huaxing Aluminum Firm , etc. and new types of insurance such as employer liability insurance , investment insurance , and profit - loss insurance , etc. are also offered at the appropriate time , satisfying the investment needs of foreign businessmen , bringing the insurance rate of the foreign business invested enterprises to more than 90 percent . <end_input>\n",
      "### OUTPUT : <start_output> [['the Zhengda Company', 'ORG'], ['the Huaxing Aluminum Firm', 'ORG'], ['more than 90 percent', 'PERCENT']] <end_output>\n",
      "\n",
      "### ASSISTANT : I will extract all the named entities in the text that has one of the 18 tags of the OntoNote5 dataset and output a python list of tuples containing the named entitiy and its own tag. Now provide me the sentence.\n",
      "### INPUT : <start_input> He said Jews were `` sick with complexes '' ; and he called David Dinkins , Mr. Giuliani 's black opponent , `` a fancy shvartze with a mustache . '' <end_input>\n",
      "### OUTPUT : <start_output> [\n",
      "### SYSTEM : The task is to extract named entites in a sentence.\n",
      "    A named entity refers to a specific, named object, concept, location, person, organization, or other entities that have a proper name. Named entities are typically unique and distinguishable entities that can be explicitly named or referred to in text. \n",
      "    The goal of named entity extraction is to identify and classify these entities within a given text.\n",
      "    We are working with 18 types of entities of the OntoNote5 dataset that are listed below with their description :\n",
      "        \"CARDINAL\": \"Numerals that do not fall under another type.\",\n",
      "        \"ORDINAL\": \"Words or expressions indicating order.\",\n",
      "        \"WORK_OF_ART\": \"Titles of creative works.\",\n",
      "        \"PERSON\": \"Names of people, including fictional and real characters.\",\n",
      "        \"LOC\": \"Geographical locations, both physical and political.\",\n",
      "        \"DATE\": \"Temporal expressions indicating dates or periods.\",\n",
      "        \"PERCENT\": \"Percentage values.\",\n",
      "        \"PRODUCT\": \"Names of products or services.\",\n",
      "        \"MONEY\": \"Monetary values, including currency symbols.\",\n",
      "        \"FAC\": \"Named facilities, such as buildings, airports, or highways.\",\n",
      "        \"TIME\": \"Temporal expressions indicating times of the day.\",\n",
      "        \"ORG\": \"Names of organizations, institutions, or companies.\",\n",
      "        \"QUANTITY\": \"Measurements or counts, including units.\",\n",
      "        \"LANGUAGE\": \"Names of languages.\",\n",
      "        \"GPE\": \"Geopolitical entities, such as countries, cities, or states.\",\n",
      "        \"LAW\": \"Legal references, including laws and legal concepts.\",\n",
      "        \"NORP\": \"Nationalities, religious, or political groups.\",\n",
      "        \"EVENT\": \"Named occurrences or incidents.\n",
      "### USER : I want you to extract all the named entities in the text and tag them with one of the tag of the OntoNote5 dataset.\n",
      "### ASSISTANT : What is the format of the output ?\n",
      "### USER : You have to output a python list of tuples. In each tuple, you have a the named entity and its own tag. For exemple, with the sentence \"Japan is a country\" as input, you would answer \"[('Japan', 'GPE')]\". \n",
      "### ASSISTANT : Can you provide me examples ?  \n",
      "### USER : There are examples : \n",
      "### INPUT : <start_input> However , during the Japanese occupation , as a result of silting , and because the Japanese invested a huge effort in developing the port at Keelung , Tanshui faded in importance , never again to see the likes of its glory days . <end_input>\n",
      "### OUTPUT : <start_output> [['Japanese', 'NORP'], ['Japanese', 'NORP'], ['Keelung', 'GPE'], ['Tanshui', 'GPE']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> I want to give a word of advice to your \" dumb \" president , you must pass it on to him , and it is that he should save what is left of his soldiers . <end_input>\n",
      "### OUTPUT : <start_output> [] <end_output>\n",
      "\n",
      "### INPUT : <start_input> Linpien used to be little more than a brief stop for travelers on their way to the seaside resort of Kenting , but now its residents are wondering if they can turn the town into a destination in its own right . <end_input>\n",
      "### OUTPUT : <start_output> [['Linpien', 'GPE'], ['Kenting', 'GPE']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> 4 . That the Journal defends `` the sleaze , fraud , waste , embezzlement , influence - peddling and abuse of the public that took place while Mr. Pierce was secretary of HUD , '' etc. and so forth . <end_input>\n",
      "### OUTPUT : <start_output> [['4', 'CARDINAL'], ['Journal', 'ORG'], ['Pierce', 'PERSON'], ['HUD', 'ORG']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> He said that the Chinese government has repeatedly stated that the Hong Kong Special Administrative Region 's first legislative assembly and regional organizations will be formed according to the Basic Law and relevant resolutions of the National People 's Congress . <end_input>\n",
      "### OUTPUT : <start_output> [['Chinese', 'NORP'], [\"the Hong Kong Special Administrative Region 's\", 'GPE'], ['first', 'ORDINAL'], ['the Basic Law', 'LAW'], [\"the National People 's Congress\", 'ORG']] <end_output>\n",
      "\n",
      "### ASSISTANT : I will extract all the named entities in the text that has one of the 18 tags of the OntoNote5 dataset and output a python list of tuples containing the named entitiy and its own tag. Now provide me the sentence.\n",
      "### INPUT : <start_input> Yes , many , viewers not in Beijing may not be quite familiar , ah , with this road section we just mentioned , where , ah , the accident occurred . <end_input>\n",
      "### OUTPUT : <start_output> [\n",
      "### SYSTEM : The task is to extract named entites in a sentence.\n",
      "    A named entity refers to a specific, named object, concept, location, person, organization, or other entities that have a proper name. Named entities are typically unique and distinguishable entities that can be explicitly named or referred to in text. \n",
      "    The goal of named entity extraction is to identify and classify these entities within a given text.\n",
      "    We are working with 18 types of entities of the OntoNote5 dataset that are listed below with their description :\n",
      "        \"CARDINAL\": \"Numerals that do not fall under another type.\",\n",
      "        \"ORDINAL\": \"Words or expressions indicating order.\",\n",
      "        \"WORK_OF_ART\": \"Titles of creative works.\",\n",
      "        \"PERSON\": \"Names of people, including fictional and real characters.\",\n",
      "        \"LOC\": \"Geographical locations, both physical and political.\",\n",
      "        \"DATE\": \"Temporal expressions indicating dates or periods.\",\n",
      "        \"PERCENT\": \"Percentage values.\",\n",
      "        \"PRODUCT\": \"Names of products or services.\",\n",
      "        \"MONEY\": \"Monetary values, including currency symbols.\",\n",
      "        \"FAC\": \"Named facilities, such as buildings, airports, or highways.\",\n",
      "        \"TIME\": \"Temporal expressions indicating times of the day.\",\n",
      "        \"ORG\": \"Names of organizations, institutions, or companies.\",\n",
      "        \"QUANTITY\": \"Measurements or counts, including units.\",\n",
      "        \"LANGUAGE\": \"Names of languages.\",\n",
      "        \"GPE\": \"Geopolitical entities, such as countries, cities, or states.\",\n",
      "        \"LAW\": \"Legal references, including laws and legal concepts.\",\n",
      "        \"NORP\": \"Nationalities, religious, or political groups.\",\n",
      "        \"EVENT\": \"Named occurrences or incidents.\n",
      "### USER : I want you to extract all the named entities in the text and tag them with one of the tag of the OntoNote5 dataset.\n",
      "### ASSISTANT : What is the format of the output ?\n",
      "### USER : You have to output a python list of tuples. In each tuple, you have a the named entity and its own tag. For exemple, with the sentence \"Japan is a country\" as input, you would answer \"[('Japan', 'GPE')]\". \n",
      "### ASSISTANT : Can you provide me examples ?  \n",
      "### USER : There are examples : \n",
      "### INPUT : <start_input> Alright I want to turn now to uh President Bush 's uh meeting uh uh photo op some called it with US troops in Iraq whether it was staged how shocking that would be /. <end_input>\n",
      "### OUTPUT : <start_output> [['Bush', 'PERSON'], ['US', 'GPE'], ['Iraq', 'GPE']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> Chang also notes that when people come to forks in the road when they reach middle age , they may look around in all directions and feel at a loss , but they 've got to encourage themselves to keep pressing ahead . <end_input>\n",
      "### OUTPUT : <start_output> [['Chang', 'PERSON']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> \" Because this area is a patents minefield , it 's impossible to create a product which from start to finish does n't infringe on anyone else 's patents , \" says Johnsee Lee . <end_input>\n",
      "### OUTPUT : <start_output> [['Johnsee Lee', 'PERSON']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> There are n't enough people during the last few years who actually went out and talked to the innovators who are doing all of these things who are actually reshaping the world /. <end_input>\n",
      "### OUTPUT : <start_output> [['the last few years', 'DATE']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> American investigators are going to the scene but in Washington at the White House , the Pentagon and the State Department , US officials are already expressing suspicions that today 's explosion was an act of terrorism . <end_input>\n",
      "### OUTPUT : <start_output> [['American', 'NORP'], ['Washington', 'GPE'], ['the White House', 'FAC'], ['Pentagon', 'FAC'], ['the State Department', 'FAC'], ['US', 'GPE'], ['today', 'DATE']] <end_output>\n",
      "\n",
      "### ASSISTANT : I will extract all the named entities in the text that has one of the 18 tags of the OntoNote5 dataset and output a python list of tuples containing the named entitiy and its own tag. Now provide me the sentence.\n",
      "### INPUT : <start_input> We 're all getting , this news in from the speech that the Homeland Security Secretary Tom Ridge is expected to be delivering at the international press club around 1:00 Eastern at the top of the hour . <end_input>\n",
      "### OUTPUT : <start_output> [\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 28/50 [00:02<00:01, 11.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### SYSTEM : The task is to extract named entites in a sentence.\n",
      "    A named entity refers to a specific, named object, concept, location, person, organization, or other entities that have a proper name. Named entities are typically unique and distinguishable entities that can be explicitly named or referred to in text. \n",
      "    The goal of named entity extraction is to identify and classify these entities within a given text.\n",
      "    We are working with 18 types of entities of the OntoNote5 dataset that are listed below with their description :\n",
      "        \"CARDINAL\": \"Numerals that do not fall under another type.\",\n",
      "        \"ORDINAL\": \"Words or expressions indicating order.\",\n",
      "        \"WORK_OF_ART\": \"Titles of creative works.\",\n",
      "        \"PERSON\": \"Names of people, including fictional and real characters.\",\n",
      "        \"LOC\": \"Geographical locations, both physical and political.\",\n",
      "        \"DATE\": \"Temporal expressions indicating dates or periods.\",\n",
      "        \"PERCENT\": \"Percentage values.\",\n",
      "        \"PRODUCT\": \"Names of products or services.\",\n",
      "        \"MONEY\": \"Monetary values, including currency symbols.\",\n",
      "        \"FAC\": \"Named facilities, such as buildings, airports, or highways.\",\n",
      "        \"TIME\": \"Temporal expressions indicating times of the day.\",\n",
      "        \"ORG\": \"Names of organizations, institutions, or companies.\",\n",
      "        \"QUANTITY\": \"Measurements or counts, including units.\",\n",
      "        \"LANGUAGE\": \"Names of languages.\",\n",
      "        \"GPE\": \"Geopolitical entities, such as countries, cities, or states.\",\n",
      "        \"LAW\": \"Legal references, including laws and legal concepts.\",\n",
      "        \"NORP\": \"Nationalities, religious, or political groups.\",\n",
      "        \"EVENT\": \"Named occurrences or incidents.\n",
      "### USER : I want you to extract all the named entities in the text and tag them with one of the tag of the OntoNote5 dataset.\n",
      "### ASSISTANT : What is the format of the output ?\n",
      "### USER : You have to output a python list of tuples. In each tuple, you have a the named entity and its own tag. For exemple, with the sentence \"Japan is a country\" as input, you would answer \"[('Japan', 'GPE')]\". \n",
      "### ASSISTANT : Can you provide me examples ?  \n",
      "### USER : There are examples : \n",
      "### INPUT : <start_input> The franchisees , owners or operators of 1,000 of the 1,900 franchised Arby 's in the U.S. , said : `` We have concluded that continued control of Arby 's by Victor Posner is totally unacceptable to us , because it is extremely likely to cause irreparable damage to the Arby 's system . <end_input>\n",
      "### OUTPUT : <start_output> [['1,000', 'CARDINAL'], ['1,900', 'CARDINAL'], ['Arby', 'ORG'], ['U.S.', 'GPE'], [\"Arby 's\", 'ORG'], ['Victor Posner', 'PERSON'], ['Arby', 'ORG']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> Well , since direction of traffic was carried out on the periphery , the number of vehicles at the section of the accident was significantly less than usual , with road traffic very orderly . <end_input>\n",
      "### OUTPUT : <start_output> [] <end_output>\n",
      "\n",
      "### INPUT : <start_input> I do n't think the Times had any choice though Howie . Because remember as a press reporter back on July twenty - seventh the turmoil in the newsroom has been going on for months about Judy Miller and the way the paper has decided to cover the story and the way they decided to present her as a martyr for the first amendment /. <end_input>\n",
      "### OUTPUT : <start_output> [['Times', 'ORG'], ['Howie', 'PERSON'], ['July twenty - seventh', 'DATE'], ['months', 'DATE'], ['Judy Miller', 'PERSON'], ['the first amendment', 'LAW']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> The most militant opposition to American TV imports has come from French television and movie producers , who have demanded quotas ensuring that a full 60 % of Europe 's TV shows be produced in Europe . <end_input>\n",
      "### OUTPUT : <start_output> [['American', 'NORP'], ['French', 'NORP'], ['a full 60 %', 'PERCENT'], ['Europe', 'LOC'], ['Europe', 'LOC']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> When American saxophonist David Murray recorded his acclaimed afrocentric jazz album , Fo Juke Review in Dakar , he recruited Amidu Berry and DJ Awadi from PBS to show what an edge West African music can really have . <end_input>\n",
      "### OUTPUT : <start_output> [['American', 'NORP'], ['David Murray', 'PERSON'], ['Fo Juke Review', 'WORK_OF_ART'], ['Dakar', 'GPE'], ['Amidu Berry', 'PERSON'], ['DJ Awadi', 'PERSON'], ['PBS', 'ORG'], ['West African', 'NORP']] <end_output>\n",
      "\n",
      "### ASSISTANT : I will extract all the named entities in the text that has one of the 18 tags of the OntoNote5 dataset and output a python list of tuples containing the named entitiy and its own tag. Now provide me the sentence.\n",
      "### INPUT : <start_input> The show will be co-anchored by Bernard Shaw and Catherine Crier , a 34 - year - old former Texas judge and campus beauty queen who has never held a job in television or journalism . <end_input>\n",
      "### OUTPUT : <start_output> [\n",
      "### SYSTEM : The task is to extract named entites in a sentence.\n",
      "    A named entity refers to a specific, named object, concept, location, person, organization, or other entities that have a proper name. Named entities are typically unique and distinguishable entities that can be explicitly named or referred to in text. \n",
      "    The goal of named entity extraction is to identify and classify these entities within a given text.\n",
      "    We are working with 18 types of entities of the OntoNote5 dataset that are listed below with their description :\n",
      "        \"CARDINAL\": \"Numerals that do not fall under another type.\",\n",
      "        \"ORDINAL\": \"Words or expressions indicating order.\",\n",
      "        \"WORK_OF_ART\": \"Titles of creative works.\",\n",
      "        \"PERSON\": \"Names of people, including fictional and real characters.\",\n",
      "        \"LOC\": \"Geographical locations, both physical and political.\",\n",
      "        \"DATE\": \"Temporal expressions indicating dates or periods.\",\n",
      "        \"PERCENT\": \"Percentage values.\",\n",
      "        \"PRODUCT\": \"Names of products or services.\",\n",
      "        \"MONEY\": \"Monetary values, including currency symbols.\",\n",
      "        \"FAC\": \"Named facilities, such as buildings, airports, or highways.\",\n",
      "        \"TIME\": \"Temporal expressions indicating times of the day.\",\n",
      "        \"ORG\": \"Names of organizations, institutions, or companies.\",\n",
      "        \"QUANTITY\": \"Measurements or counts, including units.\",\n",
      "        \"LANGUAGE\": \"Names of languages.\",\n",
      "        \"GPE\": \"Geopolitical entities, such as countries, cities, or states.\",\n",
      "        \"LAW\": \"Legal references, including laws and legal concepts.\",\n",
      "        \"NORP\": \"Nationalities, religious, or political groups.\",\n",
      "        \"EVENT\": \"Named occurrences or incidents.\n",
      "### USER : I want you to extract all the named entities in the text and tag them with one of the tag of the OntoNote5 dataset.\n",
      "### ASSISTANT : What is the format of the output ?\n",
      "### USER : You have to output a python list of tuples. In each tuple, you have a the named entity and its own tag. For exemple, with the sentence \"Japan is a country\" as input, you would answer \"[('Japan', 'GPE')]\". \n",
      "### ASSISTANT : Can you provide me examples ?  \n",
      "### USER : There are examples : \n",
      "### INPUT : <start_input> Rumsfeld : Those you are calling traitors have been chosen by the Iraqi people as their leaders by democratic means and free elections , something that did not take place during your rule over the country . <end_input>\n",
      "### OUTPUT : <start_output> [['Rumsfeld', 'PERSON'], ['Iraqi', 'NORP']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> How president Chen Shui - bian responds to this proposal will determine whether or not the \" one China \" stalemate can be broken , and if there is to be a set timetable for implementing the three direct links . <end_input>\n",
      "### OUTPUT : <start_output> [['Chen Shui - bian', 'PERSON'], ['one', 'CARDINAL'], ['China', 'GPE'], ['three', 'CARDINAL']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> So before they say it is a white man tangle you know it 's because of a white man that this happens and they got to , you know , check around and they say who is the real guilty . <end_input>\n",
      "### OUTPUT : <start_output> [] <end_output>\n",
      "\n",
      "### INPUT : <start_input> The reason they are picking that particular day is it allows , Brian , enough time for the aggrieved party , the losing party to file within 10 days a contest of the certification and that still allows enough time for the contest to be litigated through the courts primarily the circuit court and back to the Supreme Court if necessary and still meet the December 12 deadline for the Electoral College vote here . <end_input>\n",
      "### OUTPUT : <start_output> [['Brian', 'PERSON'], ['10 days', 'DATE'], ['the Supreme Court', 'ORG'], ['December 12', 'DATE'], ['Electoral College', 'ORG']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> Ideal Basic Industries Inc. said its directors reached an agreement in principle calling for HOFI North America Inc. to combine its North American cement holdings with Ideal in a transaction that will leave Ideal 's minority shareholders with 12.8 % of the combined company . <end_input>\n",
      "### OUTPUT : <start_output> [['Ideal Basic Industries Inc.', 'ORG'], ['HOFI North America Inc.', 'ORG'], ['North American', 'NORP'], ['Ideal', 'ORG'], ['Ideal', 'ORG'], ['12.8 %', 'PERCENT']] <end_output>\n",
      "\n",
      "### ASSISTANT : I will extract all the named entities in the text that has one of the 18 tags of the OntoNote5 dataset and output a python list of tuples containing the named entitiy and its own tag. Now provide me the sentence.\n",
      "### INPUT : <start_input> What I was referring to in that quote you had was the number of cases we see day in and day out at the lowest levels , scams and so forth , where considerable amounts of money are being made and lost by relatively small investors . <end_input>\n",
      "### OUTPUT : <start_output> [\n",
      "### SYSTEM : The task is to extract named entites in a sentence.\n",
      "    A named entity refers to a specific, named object, concept, location, person, organization, or other entities that have a proper name. Named entities are typically unique and distinguishable entities that can be explicitly named or referred to in text. \n",
      "    The goal of named entity extraction is to identify and classify these entities within a given text.\n",
      "    We are working with 18 types of entities of the OntoNote5 dataset that are listed below with their description :\n",
      "        \"CARDINAL\": \"Numerals that do not fall under another type.\",\n",
      "        \"ORDINAL\": \"Words or expressions indicating order.\",\n",
      "        \"WORK_OF_ART\": \"Titles of creative works.\",\n",
      "        \"PERSON\": \"Names of people, including fictional and real characters.\",\n",
      "        \"LOC\": \"Geographical locations, both physical and political.\",\n",
      "        \"DATE\": \"Temporal expressions indicating dates or periods.\",\n",
      "        \"PERCENT\": \"Percentage values.\",\n",
      "        \"PRODUCT\": \"Names of products or services.\",\n",
      "        \"MONEY\": \"Monetary values, including currency symbols.\",\n",
      "        \"FAC\": \"Named facilities, such as buildings, airports, or highways.\",\n",
      "        \"TIME\": \"Temporal expressions indicating times of the day.\",\n",
      "        \"ORG\": \"Names of organizations, institutions, or companies.\",\n",
      "        \"QUANTITY\": \"Measurements or counts, including units.\",\n",
      "        \"LANGUAGE\": \"Names of languages.\",\n",
      "        \"GPE\": \"Geopolitical entities, such as countries, cities, or states.\",\n",
      "        \"LAW\": \"Legal references, including laws and legal concepts.\",\n",
      "        \"NORP\": \"Nationalities, religious, or political groups.\",\n",
      "        \"EVENT\": \"Named occurrences or incidents.\n",
      "### USER : I want you to extract all the named entities in the text and tag them with one of the tag of the OntoNote5 dataset.\n",
      "### ASSISTANT : What is the format of the output ?\n",
      "### USER : You have to output a python list of tuples. In each tuple, you have a the named entity and its own tag. For exemple, with the sentence \"Japan is a country\" as input, you would answer \"[('Japan', 'GPE')]\". \n",
      "### ASSISTANT : Can you provide me examples ?  \n",
      "### USER : There are examples : \n",
      "### INPUT : <start_input> As soon as you 're through customs at Hong Kong , you see them : women draped with beauty pageant - like sashes with the Chinese characters for \" Global Travel \" emblazoned across them . <end_input>\n",
      "### OUTPUT : <start_output> [['Hong Kong', 'GPE'], ['Chinese', 'NORP'], ['\" Global Travel \"', 'ORG']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> and %um it 's just been quite interesting although when she was in Rhode Island she was very disruptive , %um down there and really caused Francis a lot of stress <end_input>\n",
      "### OUTPUT : <start_output> [['Rhode Island', 'GPE'], ['Francis', 'PERSON']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> China plans to formulate many new preferential policies to ensure positively , reasonably and effectively utilizing foreign investment and to improve the pattern of opening up to the outside world . <end_input>\n",
      "### OUTPUT : <start_output> [['China', 'GPE']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> \" In addition to enterovirus , we plan to develop chips to detect other infectious diseases such as hepatitis B , hepatitis C and HIV , \" says Wang Shin - hwan . <end_input>\n",
      "### OUTPUT : <start_output> [['Wang Shin - hwan', 'PERSON']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> Line by line Mr. Friedman 's weary cynicism can be amusing , especially when he 's riffing on the Hollywood social scheme -- the way people size each other up , immediately canceling the desperate ones who merely almost made it . <end_input>\n",
      "### OUTPUT : <start_output> [['Friedman', 'PERSON'], ['Hollywood', 'GPE']] <end_output>\n",
      "\n",
      "### ASSISTANT : I will extract all the named entities in the text that has one of the 18 tags of the OntoNote5 dataset and output a python list of tuples containing the named entitiy and its own tag. Now provide me the sentence.\n",
      "### INPUT : <start_input> Growing 11.7 % , but growth rate declined 6 % from that of last year ; the industrial added value of other economic types was 445 billion , a 13.4 % growth , and a 3 % climb from that of last year . <end_input>\n",
      "### OUTPUT : <start_output> [\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 32/50 [00:02<00:01, 11.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### SYSTEM : The task is to extract named entites in a sentence.\n",
      "    A named entity refers to a specific, named object, concept, location, person, organization, or other entities that have a proper name. Named entities are typically unique and distinguishable entities that can be explicitly named or referred to in text. \n",
      "    The goal of named entity extraction is to identify and classify these entities within a given text.\n",
      "    We are working with 18 types of entities of the OntoNote5 dataset that are listed below with their description :\n",
      "        \"CARDINAL\": \"Numerals that do not fall under another type.\",\n",
      "        \"ORDINAL\": \"Words or expressions indicating order.\",\n",
      "        \"WORK_OF_ART\": \"Titles of creative works.\",\n",
      "        \"PERSON\": \"Names of people, including fictional and real characters.\",\n",
      "        \"LOC\": \"Geographical locations, both physical and political.\",\n",
      "        \"DATE\": \"Temporal expressions indicating dates or periods.\",\n",
      "        \"PERCENT\": \"Percentage values.\",\n",
      "        \"PRODUCT\": \"Names of products or services.\",\n",
      "        \"MONEY\": \"Monetary values, including currency symbols.\",\n",
      "        \"FAC\": \"Named facilities, such as buildings, airports, or highways.\",\n",
      "        \"TIME\": \"Temporal expressions indicating times of the day.\",\n",
      "        \"ORG\": \"Names of organizations, institutions, or companies.\",\n",
      "        \"QUANTITY\": \"Measurements or counts, including units.\",\n",
      "        \"LANGUAGE\": \"Names of languages.\",\n",
      "        \"GPE\": \"Geopolitical entities, such as countries, cities, or states.\",\n",
      "        \"LAW\": \"Legal references, including laws and legal concepts.\",\n",
      "        \"NORP\": \"Nationalities, religious, or political groups.\",\n",
      "        \"EVENT\": \"Named occurrences or incidents.\n",
      "### USER : I want you to extract all the named entities in the text and tag them with one of the tag of the OntoNote5 dataset.\n",
      "### ASSISTANT : What is the format of the output ?\n",
      "### USER : You have to output a python list of tuples. In each tuple, you have a the named entity and its own tag. For exemple, with the sentence \"Japan is a country\" as input, you would answer \"[('Japan', 'GPE')]\". \n",
      "### ASSISTANT : Can you provide me examples ?  \n",
      "### USER : There are examples : \n",
      "### INPUT : <start_input> Saddam Hussein : We have had no weapons of mass destruction since 1991 , we were truthful when we spoke with the international inspection mission , we were truthful in our letters to Kofi Annan , you knew these facts but you were looking for any pretext to occupy Iraq and topple its legitimate authority . <end_input>\n",
      "### OUTPUT : <start_output> [['Saddam Hussein', 'PERSON'], ['1991', 'DATE'], ['Kofi Annan', 'PERSON'], ['Iraq', 'GPE']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> -- Raising an additional $ 43 million by increasing existing Federal Communications Commission fees and penalties and establishing new fees for amateur radio operators , ship stations and mobile radio facilities . <end_input>\n",
      "### OUTPUT : <start_output> [['an additional $ 43 million', 'MONEY'], ['Federal Communications Commission', 'ORG']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> As Syms 's `` core business of off - price retailing grows , a small subsidiary that is operationally unrelated becomes a difficult distraction , '' said Marcy Syms , president of the parent , in a statement . <end_input>\n",
      "### OUTPUT : <start_output> [['Syms', 'ORG'], ['Marcy Syms', 'PERSON']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> They have both invested enormous amounts in it , and both regimes would be more vulnerable if the peace process were to fail , because detractors and opponents within each country would have ammunition by which to fire at them . <end_input>\n",
      "### OUTPUT : <start_output> [] <end_output>\n",
      "\n",
      "### INPUT : <start_input> The Islam Diary : A leader of the Shiite death squads in Sadr City , east of Baghdad , acknowledged that the Mahdi Army militia was involved in killing operations of Arab Sunni men after kidnapping them , despite their relatives having paid the blood money demanded by the hostage - takers in return for their being freed . <end_input>\n",
      "### OUTPUT : <start_output> [['The Islam Diary', 'WORK_OF_ART'], ['Shiite', 'NORP'], ['Sadr City', 'GPE'], ['Baghdad', 'GPE'], ['Mahdi Army', 'ORG'], ['Arab', 'NORP'], ['Sunni', 'NORP']] <end_output>\n",
      "\n",
      "### ASSISTANT : I will extract all the named entities in the text that has one of the 18 tags of the OntoNote5 dataset and output a python list of tuples containing the named entitiy and its own tag. Now provide me the sentence.\n",
      "### INPUT : <start_input> Reporter Lee , flying in from California , unsure if his wife was alive , today , identifying his remains , and tonight survivor John Diaz begins the long trip home to California . <end_input>\n",
      "### OUTPUT : <start_output> [\n",
      "### SYSTEM : The task is to extract named entites in a sentence.\n",
      "    A named entity refers to a specific, named object, concept, location, person, organization, or other entities that have a proper name. Named entities are typically unique and distinguishable entities that can be explicitly named or referred to in text. \n",
      "    The goal of named entity extraction is to identify and classify these entities within a given text.\n",
      "    We are working with 18 types of entities of the OntoNote5 dataset that are listed below with their description :\n",
      "        \"CARDINAL\": \"Numerals that do not fall under another type.\",\n",
      "        \"ORDINAL\": \"Words or expressions indicating order.\",\n",
      "        \"WORK_OF_ART\": \"Titles of creative works.\",\n",
      "        \"PERSON\": \"Names of people, including fictional and real characters.\",\n",
      "        \"LOC\": \"Geographical locations, both physical and political.\",\n",
      "        \"DATE\": \"Temporal expressions indicating dates or periods.\",\n",
      "        \"PERCENT\": \"Percentage values.\",\n",
      "        \"PRODUCT\": \"Names of products or services.\",\n",
      "        \"MONEY\": \"Monetary values, including currency symbols.\",\n",
      "        \"FAC\": \"Named facilities, such as buildings, airports, or highways.\",\n",
      "        \"TIME\": \"Temporal expressions indicating times of the day.\",\n",
      "        \"ORG\": \"Names of organizations, institutions, or companies.\",\n",
      "        \"QUANTITY\": \"Measurements or counts, including units.\",\n",
      "        \"LANGUAGE\": \"Names of languages.\",\n",
      "        \"GPE\": \"Geopolitical entities, such as countries, cities, or states.\",\n",
      "        \"LAW\": \"Legal references, including laws and legal concepts.\",\n",
      "        \"NORP\": \"Nationalities, religious, or political groups.\",\n",
      "        \"EVENT\": \"Named occurrences or incidents.\n",
      "### USER : I want you to extract all the named entities in the text and tag them with one of the tag of the OntoNote5 dataset.\n",
      "### ASSISTANT : What is the format of the output ?\n",
      "### USER : You have to output a python list of tuples. In each tuple, you have a the named entity and its own tag. For exemple, with the sentence \"Japan is a country\" as input, you would answer \"[('Japan', 'GPE')]\". \n",
      "### ASSISTANT : Can you provide me examples ?  \n",
      "### USER : There are examples : \n",
      "### INPUT : <start_input> Those lanterns moving through the river are actually the ferry , while those stars flashing in the distance are beams of light that come from the lighthouse every five seconds . <end_input>\n",
      "### OUTPUT : <start_output> [['five', 'CARDINAL']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> In the first quarter of this year , Guangzhou 's private industries , construction industries and traffic and transportation industries have achieved a total output value of 412 million yuan , 22.62 % higher than that of the same period of the previous year . <end_input>\n",
      "### OUTPUT : <start_output> [['the first quarter of this year', 'DATE'], ['Guangzhou', 'GPE'], ['412 million yuan', 'MONEY'], ['22.62 %', 'PERCENT'], ['the same period of the previous year', 'DATE']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> And as a result I would argue that really masked what is actually a fundemental inflection point the flattening of the world that we 're going from a vertical value creation model of command and control to a much more horizontal one of connect and collaborate /. <end_input>\n",
      "### OUTPUT : <start_output> [] <end_output>\n",
      "\n",
      "### INPUT : <start_input> Mr. Burt nonetheless paid the penalty as if he had lost , agreeing to spend a day with West German Foreign Minister Hans - Dietrich Genscher frying and selling their combined weight in potato pancakes . <end_input>\n",
      "### OUTPUT : <start_output> [['Burt', 'PERSON'], ['a day', 'DATE'], ['West German', 'NORP'], ['Hans - Dietrich Genscher', 'PERSON']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> This may not be the case , as the public ' persona ' is merely an ' alter ' personality and he may have many other ' personalities ' which are dark . <end_input>\n",
      "### OUTPUT : <start_output> [] <end_output>\n",
      "\n",
      "### ASSISTANT : I will extract all the named entities in the text that has one of the 18 tags of the OntoNote5 dataset and output a python list of tuples containing the named entitiy and its own tag. Now provide me the sentence.\n",
      "### INPUT : <start_input> By the end of last December , the total number of enterprises in the bonded area was 1,614 , of which 260 were foreign - invested enterprises and the total investment reached 1.2 billion US dollars , with an actual utilized foreign investment of 113 million US dollars . <end_input>\n",
      "### OUTPUT : <start_output> [\n",
      "### SYSTEM : The task is to extract named entites in a sentence.\n",
      "    A named entity refers to a specific, named object, concept, location, person, organization, or other entities that have a proper name. Named entities are typically unique and distinguishable entities that can be explicitly named or referred to in text. \n",
      "    The goal of named entity extraction is to identify and classify these entities within a given text.\n",
      "    We are working with 18 types of entities of the OntoNote5 dataset that are listed below with their description :\n",
      "        \"CARDINAL\": \"Numerals that do not fall under another type.\",\n",
      "        \"ORDINAL\": \"Words or expressions indicating order.\",\n",
      "        \"WORK_OF_ART\": \"Titles of creative works.\",\n",
      "        \"PERSON\": \"Names of people, including fictional and real characters.\",\n",
      "        \"LOC\": \"Geographical locations, both physical and political.\",\n",
      "        \"DATE\": \"Temporal expressions indicating dates or periods.\",\n",
      "        \"PERCENT\": \"Percentage values.\",\n",
      "        \"PRODUCT\": \"Names of products or services.\",\n",
      "        \"MONEY\": \"Monetary values, including currency symbols.\",\n",
      "        \"FAC\": \"Named facilities, such as buildings, airports, or highways.\",\n",
      "        \"TIME\": \"Temporal expressions indicating times of the day.\",\n",
      "        \"ORG\": \"Names of organizations, institutions, or companies.\",\n",
      "        \"QUANTITY\": \"Measurements or counts, including units.\",\n",
      "        \"LANGUAGE\": \"Names of languages.\",\n",
      "        \"GPE\": \"Geopolitical entities, such as countries, cities, or states.\",\n",
      "        \"LAW\": \"Legal references, including laws and legal concepts.\",\n",
      "        \"NORP\": \"Nationalities, religious, or political groups.\",\n",
      "        \"EVENT\": \"Named occurrences or incidents.\n",
      "### USER : I want you to extract all the named entities in the text and tag them with one of the tag of the OntoNote5 dataset.\n",
      "### ASSISTANT : What is the format of the output ?\n",
      "### USER : You have to output a python list of tuples. In each tuple, you have a the named entity and its own tag. For exemple, with the sentence \"Japan is a country\" as input, you would answer \"[('Japan', 'GPE')]\". \n",
      "### ASSISTANT : Can you provide me examples ?  \n",
      "### USER : There are examples : \n",
      "### INPUT : <start_input> When you 're feeling under the weather , all you need to do is buy a diagnostic biochip from the chemist 's shop , put a drop of urine onto it , and you will find out what is wrong with you - a health check will be as easy as a pregnancy test today . <end_input>\n",
      "### OUTPUT : <start_output> [] <end_output>\n",
      "\n",
      "### INPUT : <start_input> One obvious place to attach a capital - gains tax cut , and perhaps other popular items stripped from the deficit - reduction bill , is the legislation to raise the federal borrowing limit . <end_input>\n",
      "### OUTPUT : <start_output> [['One', 'CARDINAL']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> But administration officials privately agree with Mr. Panetta , who said a precipitous drop this week `` is going to force the president and Congress to take a much harder look at fiscal policy . '' <end_input>\n",
      "### OUTPUT : <start_output> [['Panetta', 'PERSON'], ['this week', 'DATE'], ['Congress', 'ORG']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> Not at odds though with what actually the military commanders have been saying which is that the number of really trained Iraqi units you know are far fewer than sometimes suggested by the administration /. <end_input>\n",
      "### OUTPUT : <start_output> [['Iraqi', 'NORP']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> Data provided by the State Taxation Administration show that , starting next year , foreign business investment BOT projects will continue to enjoy preferential taxation , and the scope of their preferential policies will include investment enterprises and individual investors engaged in BOT projects . <end_input>\n",
      "### OUTPUT : <start_output> [['the State Taxation Administration', 'ORG'], ['next year', 'DATE']] <end_output>\n",
      "\n",
      "### ASSISTANT : I will extract all the named entities in the text that has one of the 18 tags of the OntoNote5 dataset and output a python list of tuples containing the named entitiy and its own tag. Now provide me the sentence.\n",
      "### INPUT : <start_input> Officials in the Iraqi Department of Defense said that the two missiles or bomb shells dropped by planes of the multi-national forces on the 13th at 4 O'clock in the morning local time hit a large sized underground bomb shelter and , at least 500 civilians hiding inside were killed , more than half of whom were women and children . <end_input>\n",
      "### OUTPUT : <start_output> [\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 34/50 [00:02<00:01, 11.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### SYSTEM : The task is to extract named entites in a sentence.\n",
      "    A named entity refers to a specific, named object, concept, location, person, organization, or other entities that have a proper name. Named entities are typically unique and distinguishable entities that can be explicitly named or referred to in text. \n",
      "    The goal of named entity extraction is to identify and classify these entities within a given text.\n",
      "    We are working with 18 types of entities of the OntoNote5 dataset that are listed below with their description :\n",
      "        \"CARDINAL\": \"Numerals that do not fall under another type.\",\n",
      "        \"ORDINAL\": \"Words or expressions indicating order.\",\n",
      "        \"WORK_OF_ART\": \"Titles of creative works.\",\n",
      "        \"PERSON\": \"Names of people, including fictional and real characters.\",\n",
      "        \"LOC\": \"Geographical locations, both physical and political.\",\n",
      "        \"DATE\": \"Temporal expressions indicating dates or periods.\",\n",
      "        \"PERCENT\": \"Percentage values.\",\n",
      "        \"PRODUCT\": \"Names of products or services.\",\n",
      "        \"MONEY\": \"Monetary values, including currency symbols.\",\n",
      "        \"FAC\": \"Named facilities, such as buildings, airports, or highways.\",\n",
      "        \"TIME\": \"Temporal expressions indicating times of the day.\",\n",
      "        \"ORG\": \"Names of organizations, institutions, or companies.\",\n",
      "        \"QUANTITY\": \"Measurements or counts, including units.\",\n",
      "        \"LANGUAGE\": \"Names of languages.\",\n",
      "        \"GPE\": \"Geopolitical entities, such as countries, cities, or states.\",\n",
      "        \"LAW\": \"Legal references, including laws and legal concepts.\",\n",
      "        \"NORP\": \"Nationalities, religious, or political groups.\",\n",
      "        \"EVENT\": \"Named occurrences or incidents.\n",
      "### USER : I want you to extract all the named entities in the text and tag them with one of the tag of the OntoNote5 dataset.\n",
      "### ASSISTANT : What is the format of the output ?\n",
      "### USER : You have to output a python list of tuples. In each tuple, you have a the named entity and its own tag. For exemple, with the sentence \"Japan is a country\" as input, you would answer \"[('Japan', 'GPE')]\". \n",
      "### ASSISTANT : Can you provide me examples ?  \n",
      "### USER : There are examples : \n",
      "### INPUT : <start_input> The problem , however , is that GM 's moves are coming at a time when UAW leaders are trying to silence dissidents who charge the union is too passive in the face of GM layoffs . <end_input>\n",
      "### OUTPUT : <start_output> [['GM', 'ORG'], ['UAW', 'ORG'], ['GM', 'ORG']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> According to statistics , during the \" eighth five - year plan \" period , the amount of risk People 's Insurance Co. took up for the import and export trade of Gansu Province reached 771 million yuan , and paid out 13.855 million yuan as indemnity , effectively promoting the development of Gansu Province 's import and export trade . <end_input>\n",
      "### OUTPUT : <start_output> [['eighth', 'ORDINAL'], ['five - year', 'DATE'], [\"People 's Insurance Co.\", 'ORG'], ['Gansu Province', 'GPE'], ['771 million yuan', 'MONEY'], ['13.855 million yuan', 'MONEY'], [\"Gansu Province 's\", 'GPE']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> Mr. Granville says he would n't even think of buying until at least 600 to 700 stocks have hit 52 - week lows ; about 100 stocks hit new lows Friday . <end_input>\n",
      "### OUTPUT : <start_output> [['Granville', 'PERSON'], ['600', 'CARDINAL'], ['700', 'CARDINAL'], ['52 - week', 'DATE'], ['about 100', 'CARDINAL'], ['Friday', 'DATE']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> Companies with which GEC has had talks about a possible joint Ferranti bid include Matra , Britain 's Dowty Group PLC , West Germany 's Daimler - Benz AG , and France 's Dassault group . <end_input>\n",
      "### OUTPUT : <start_output> [['GEC', 'ORG'], ['Ferranti', 'ORG'], ['Matra', 'ORG'], ['Britain', 'GPE'], ['Dowty Group PLC', 'ORG'], [\"West Germany 's\", 'GPE'], ['Daimler - Benz AG', 'ORG'], ['France', 'GPE'], ['Dassault', 'ORG']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> Remember after the Jayson Blair scandal broke we had a seven thousand word story that did not give a full account of what happened . Especially about why is a major institution like the Times ignoring so many red flags /. <end_input>\n",
      "### OUTPUT : <start_output> [['Jayson Blair', 'PERSON'], ['seven thousand word', 'CARDINAL'], ['Times', 'ORG']] <end_output>\n",
      "\n",
      "### ASSISTANT : I will extract all the named entities in the text that has one of the 18 tags of the OntoNote5 dataset and output a python list of tuples containing the named entitiy and its own tag. Now provide me the sentence.\n",
      "### INPUT : <start_input> Now your international readership on the New York Times website has gone down because of this new experiment the Times has where it costs forty nine ninety - five a year for non-subscribers at home to read Times columnists /. <end_input>\n",
      "### OUTPUT : <start_output> [\n",
      "### SYSTEM : The task is to extract named entites in a sentence.\n",
      "    A named entity refers to a specific, named object, concept, location, person, organization, or other entities that have a proper name. Named entities are typically unique and distinguishable entities that can be explicitly named or referred to in text. \n",
      "    The goal of named entity extraction is to identify and classify these entities within a given text.\n",
      "    We are working with 18 types of entities of the OntoNote5 dataset that are listed below with their description :\n",
      "        \"CARDINAL\": \"Numerals that do not fall under another type.\",\n",
      "        \"ORDINAL\": \"Words or expressions indicating order.\",\n",
      "        \"WORK_OF_ART\": \"Titles of creative works.\",\n",
      "        \"PERSON\": \"Names of people, including fictional and real characters.\",\n",
      "        \"LOC\": \"Geographical locations, both physical and political.\",\n",
      "        \"DATE\": \"Temporal expressions indicating dates or periods.\",\n",
      "        \"PERCENT\": \"Percentage values.\",\n",
      "        \"PRODUCT\": \"Names of products or services.\",\n",
      "        \"MONEY\": \"Monetary values, including currency symbols.\",\n",
      "        \"FAC\": \"Named facilities, such as buildings, airports, or highways.\",\n",
      "        \"TIME\": \"Temporal expressions indicating times of the day.\",\n",
      "        \"ORG\": \"Names of organizations, institutions, or companies.\",\n",
      "        \"QUANTITY\": \"Measurements or counts, including units.\",\n",
      "        \"LANGUAGE\": \"Names of languages.\",\n",
      "        \"GPE\": \"Geopolitical entities, such as countries, cities, or states.\",\n",
      "        \"LAW\": \"Legal references, including laws and legal concepts.\",\n",
      "        \"NORP\": \"Nationalities, religious, or political groups.\",\n",
      "        \"EVENT\": \"Named occurrences or incidents.\n",
      "### USER : I want you to extract all the named entities in the text and tag them with one of the tag of the OntoNote5 dataset.\n",
      "### ASSISTANT : What is the format of the output ?\n",
      "### USER : You have to output a python list of tuples. In each tuple, you have a the named entity and its own tag. For exemple, with the sentence \"Japan is a country\" as input, you would answer \"[('Japan', 'GPE')]\". \n",
      "### ASSISTANT : Can you provide me examples ?  \n",
      "### USER : There are examples : \n",
      "### INPUT : <start_input> And one of the things that they find experimentally are what they call anti phased , %uh , states , where if you look at the total intensity uh-huh . of the laser , you get an oscillation which is characterized by one frequency . <end_input>\n",
      "### OUTPUT : <start_output> [['one', 'CARDINAL']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> Sixthly , I ask that you hand me the weapons of mass destruction if you have found them , bring back to life all the martyrs you have killed , and return the integrity of the glorious Iraqi women which you have robbed . <end_input>\n",
      "### OUTPUT : <start_output> [['Sixthly', 'ORDINAL'], ['Iraqi', 'NORP']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> And this involves uh their saying that they contacted Clinton 's office back in August with a detailed list of charges and then quote in subsequent phone calls the President 's people said he did not want to be interviewed /. <end_input>\n",
      "### OUTPUT : <start_output> [['Clinton', 'PERSON'], ['August', 'DATE']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> Mingquan Zhang , vice director of Shandong Province 's Foreign Economy and Trade Committee , said that in 1997 , the quality and level of Shandong 's utilizing foreign capital had further improved . <end_input>\n",
      "### OUTPUT : <start_output> [['Mingquan Zhang', 'PERSON'], [\"Shandong Province 's\", 'GPE'], ['Foreign Economy and Trade Committee', 'ORG'], ['1997', 'DATE'], ['Shandong', 'GPE']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> By sorting out the essence of the above historical background and conceptual relationships , we will have a pretty thorough , comprehensive and systematic knowledge framework about the benign inevitable trends and development guidelines of the future society dependent on the rule of society , so that the associated impression captured may be more concrete . <end_input>\n",
      "### OUTPUT : <start_output> [] <end_output>\n",
      "\n",
      "### ASSISTANT : I will extract all the named entities in the text that has one of the 18 tags of the OntoNote5 dataset and output a python list of tuples containing the named entitiy and its own tag. Now provide me the sentence.\n",
      "### INPUT : <start_input> `` I was buying at the close -LRB- Friday -RRB- and I 'll be buying again because I know we 're getting good value , '' said Frederick A. Moran , president of Moran Asset Management Inc. , Greenwich , Conn . <end_input>\n",
      "### OUTPUT : <start_output> [\n",
      "### SYSTEM : The task is to extract named entites in a sentence.\n",
      "    A named entity refers to a specific, named object, concept, location, person, organization, or other entities that have a proper name. Named entities are typically unique and distinguishable entities that can be explicitly named or referred to in text. \n",
      "    The goal of named entity extraction is to identify and classify these entities within a given text.\n",
      "    We are working with 18 types of entities of the OntoNote5 dataset that are listed below with their description :\n",
      "        \"CARDINAL\": \"Numerals that do not fall under another type.\",\n",
      "        \"ORDINAL\": \"Words or expressions indicating order.\",\n",
      "        \"WORK_OF_ART\": \"Titles of creative works.\",\n",
      "        \"PERSON\": \"Names of people, including fictional and real characters.\",\n",
      "        \"LOC\": \"Geographical locations, both physical and political.\",\n",
      "        \"DATE\": \"Temporal expressions indicating dates or periods.\",\n",
      "        \"PERCENT\": \"Percentage values.\",\n",
      "        \"PRODUCT\": \"Names of products or services.\",\n",
      "        \"MONEY\": \"Monetary values, including currency symbols.\",\n",
      "        \"FAC\": \"Named facilities, such as buildings, airports, or highways.\",\n",
      "        \"TIME\": \"Temporal expressions indicating times of the day.\",\n",
      "        \"ORG\": \"Names of organizations, institutions, or companies.\",\n",
      "        \"QUANTITY\": \"Measurements or counts, including units.\",\n",
      "        \"LANGUAGE\": \"Names of languages.\",\n",
      "        \"GPE\": \"Geopolitical entities, such as countries, cities, or states.\",\n",
      "        \"LAW\": \"Legal references, including laws and legal concepts.\",\n",
      "        \"NORP\": \"Nationalities, religious, or political groups.\",\n",
      "        \"EVENT\": \"Named occurrences or incidents.\n",
      "### USER : I want you to extract all the named entities in the text and tag them with one of the tag of the OntoNote5 dataset.\n",
      "### ASSISTANT : What is the format of the output ?\n",
      "### USER : You have to output a python list of tuples. In each tuple, you have a the named entity and its own tag. For exemple, with the sentence \"Japan is a country\" as input, you would answer \"[('Japan', 'GPE')]\". \n",
      "### ASSISTANT : Can you provide me examples ?  \n",
      "### USER : There are examples : \n",
      "### INPUT : <start_input> We know that in the past , disclosure of information had to be reported to higher authorities , level by level , until the highest authorities had given approval , before information could be disclosed . <end_input>\n",
      "### OUTPUT : <start_output> [] <end_output>\n",
      "\n",
      "### INPUT : <start_input> Bozell Cheil Corp. , as the new agency will be called , will be based in Seoul and is 70 % owned by Samsung and 30 % owned by Bozell . <end_input>\n",
      "### OUTPUT : <start_output> [['Bozell Cheil Corp.', 'ORG'], ['Seoul', 'GPE'], ['70 %', 'PERCENT'], ['Samsung', 'ORG'], ['30 %', 'PERCENT'], ['Bozell', 'ORG']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> In order to satisfy the requirements of the continuously expanding overseas markets , various areas of Guangdong have adjusted to local conditions and selected famous , special and improved varieties , and have built up more than 2,000 agricultural export merchandise production and processing bases . <end_input>\n",
      "### OUTPUT : <start_output> [['Guangdong', 'GPE'], ['more than 2,000', 'CARDINAL']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> Cheney gets a checkup call from Governor Bush and still expects to be released as early as tomorrow , and today , President Clinton cautiously speaks out about the Florida vote fight , saying everyone should , `` let the process play out . '' <end_input>\n",
      "### OUTPUT : <start_output> [['Cheney', 'PERSON'], ['Bush', 'PERSON'], ['tomorrow', 'DATE'], ['today', 'DATE'], ['Clinton', 'PERSON'], ['Florida', 'GPE']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> Official data confirm that in 2004 the total personal income tax for the country amounted to approximately 181 billion , of which 65 % came from the working class , and only 10 % came from the wealthy . <end_input>\n",
      "### OUTPUT : <start_output> [['2004', 'DATE'], ['approximately 181 billion', 'CARDINAL'], ['65 %', 'PERCENT'], ['10 %', 'PERCENT']] <end_output>\n",
      "\n",
      "### ASSISTANT : I will extract all the named entities in the text that has one of the 18 tags of the OntoNote5 dataset and output a python list of tuples containing the named entitiy and its own tag. Now provide me the sentence.\n",
      "### INPUT : <start_input> Saddam Hussein : I know that you are ignorant of history , and I know that your president is no less ignorant but it seems that you have continued to lie to the extent that you now believe yourselves . <end_input>\n",
      "### OUTPUT : <start_output> [\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 38/50 [00:03<00:01, 11.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### SYSTEM : The task is to extract named entites in a sentence.\n",
      "    A named entity refers to a specific, named object, concept, location, person, organization, or other entities that have a proper name. Named entities are typically unique and distinguishable entities that can be explicitly named or referred to in text. \n",
      "    The goal of named entity extraction is to identify and classify these entities within a given text.\n",
      "    We are working with 18 types of entities of the OntoNote5 dataset that are listed below with their description :\n",
      "        \"CARDINAL\": \"Numerals that do not fall under another type.\",\n",
      "        \"ORDINAL\": \"Words or expressions indicating order.\",\n",
      "        \"WORK_OF_ART\": \"Titles of creative works.\",\n",
      "        \"PERSON\": \"Names of people, including fictional and real characters.\",\n",
      "        \"LOC\": \"Geographical locations, both physical and political.\",\n",
      "        \"DATE\": \"Temporal expressions indicating dates or periods.\",\n",
      "        \"PERCENT\": \"Percentage values.\",\n",
      "        \"PRODUCT\": \"Names of products or services.\",\n",
      "        \"MONEY\": \"Monetary values, including currency symbols.\",\n",
      "        \"FAC\": \"Named facilities, such as buildings, airports, or highways.\",\n",
      "        \"TIME\": \"Temporal expressions indicating times of the day.\",\n",
      "        \"ORG\": \"Names of organizations, institutions, or companies.\",\n",
      "        \"QUANTITY\": \"Measurements or counts, including units.\",\n",
      "        \"LANGUAGE\": \"Names of languages.\",\n",
      "        \"GPE\": \"Geopolitical entities, such as countries, cities, or states.\",\n",
      "        \"LAW\": \"Legal references, including laws and legal concepts.\",\n",
      "        \"NORP\": \"Nationalities, religious, or political groups.\",\n",
      "        \"EVENT\": \"Named occurrences or incidents.\n",
      "### USER : I want you to extract all the named entities in the text and tag them with one of the tag of the OntoNote5 dataset.\n",
      "### ASSISTANT : What is the format of the output ?\n",
      "### USER : You have to output a python list of tuples. In each tuple, you have a the named entity and its own tag. For exemple, with the sentence \"Japan is a country\" as input, you would answer \"[('Japan', 'GPE')]\". \n",
      "### ASSISTANT : Can you provide me examples ?  \n",
      "### USER : There are examples : \n",
      "### INPUT : <start_input> China 's population currently stands at 1.26 billion , still the largest in the world , but the paper says that if it were n't for the one child policy that figure would be 300 million higher . <end_input>\n",
      "### OUTPUT : <start_output> [['China', 'GPE'], ['1.26 billion', 'CARDINAL'], ['one', 'CARDINAL'], ['300 million', 'CARDINAL']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> Apart from the material itself being cheaper , the nylon chips use a visible - spectrum colorimetric system to display results , so that they can be read using an ordinary optical scanner , which costs 50 - 70 % less than using a special laser detector . <end_input>\n",
      "### OUTPUT : <start_output> [['50 - 70 %', 'PERCENT']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> This province has currently drafted preferential policies to encourage state - owned enterprises , collective enterprises , privately - operated enterprises , individually - owned science and technology enterprises , foreign funded enterprises and average people from inside and outside the province using various methods to participate in Shaanxi 's small state - owned enterprise reforms . <end_input>\n",
      "### OUTPUT : <start_output> [['Shaanxi', 'GPE']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> It abuts Sanchih Rural Township to the northeast , the Kuantu area of Taipei City to the southeast , and the Taiwan Strait to the northwest ; to the southwest it faces Pali Rural Township over the Tanshui River . <end_input>\n",
      "### OUTPUT : <start_output> [['Sanchih Rural Township', 'GPE'], ['Kuantu', 'LOC'], ['Taipei City', 'GPE'], ['the Taiwan Strait', 'LOC'], ['Pali Rural Township', 'GPE'], ['the Tanshui River', 'LOC']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> We should not entertain any illusions that China 's income tax can in any way regulate income distribution , much less that it can \" take from the rich and give to the poor . \" <end_input>\n",
      "### OUTPUT : <start_output> [['China', 'GPE']] <end_output>\n",
      "\n",
      "### ASSISTANT : I will extract all the named entities in the text that has one of the 18 tags of the OntoNote5 dataset and output a python list of tuples containing the named entitiy and its own tag. Now provide me the sentence.\n",
      "### INPUT : <start_input> Although I was n't attracted to her in that way , I went to see her every day in hospital , and this left a deep impression on her of how considerate Chinese men can be . <end_input>\n",
      "### OUTPUT : <start_output> [\n",
      "### SYSTEM : The task is to extract named entites in a sentence.\n",
      "    A named entity refers to a specific, named object, concept, location, person, organization, or other entities that have a proper name. Named entities are typically unique and distinguishable entities that can be explicitly named or referred to in text. \n",
      "    The goal of named entity extraction is to identify and classify these entities within a given text.\n",
      "    We are working with 18 types of entities of the OntoNote5 dataset that are listed below with their description :\n",
      "        \"CARDINAL\": \"Numerals that do not fall under another type.\",\n",
      "        \"ORDINAL\": \"Words or expressions indicating order.\",\n",
      "        \"WORK_OF_ART\": \"Titles of creative works.\",\n",
      "        \"PERSON\": \"Names of people, including fictional and real characters.\",\n",
      "        \"LOC\": \"Geographical locations, both physical and political.\",\n",
      "        \"DATE\": \"Temporal expressions indicating dates or periods.\",\n",
      "        \"PERCENT\": \"Percentage values.\",\n",
      "        \"PRODUCT\": \"Names of products or services.\",\n",
      "        \"MONEY\": \"Monetary values, including currency symbols.\",\n",
      "        \"FAC\": \"Named facilities, such as buildings, airports, or highways.\",\n",
      "        \"TIME\": \"Temporal expressions indicating times of the day.\",\n",
      "        \"ORG\": \"Names of organizations, institutions, or companies.\",\n",
      "        \"QUANTITY\": \"Measurements or counts, including units.\",\n",
      "        \"LANGUAGE\": \"Names of languages.\",\n",
      "        \"GPE\": \"Geopolitical entities, such as countries, cities, or states.\",\n",
      "        \"LAW\": \"Legal references, including laws and legal concepts.\",\n",
      "        \"NORP\": \"Nationalities, religious, or political groups.\",\n",
      "        \"EVENT\": \"Named occurrences or incidents.\n",
      "### USER : I want you to extract all the named entities in the text and tag them with one of the tag of the OntoNote5 dataset.\n",
      "### ASSISTANT : What is the format of the output ?\n",
      "### USER : You have to output a python list of tuples. In each tuple, you have a the named entity and its own tag. For exemple, with the sentence \"Japan is a country\" as input, you would answer \"[('Japan', 'GPE')]\". \n",
      "### ASSISTANT : Can you provide me examples ?  \n",
      "### USER : There are examples : \n",
      "### INPUT : <start_input> But not much money was spent on the shows , either , a situation that encouraged cheap - to - make talk and game shows , while discouraging expensive - to - produce dramas . <end_input>\n",
      "### OUTPUT : <start_output> [] <end_output>\n",
      "\n",
      "### INPUT : <start_input> Gulf Resources earlier this year proposed a reorganization plan that would make it a unit of a Bermuda concern , potentially exempting it from liability for the smelter 's cleanup costs . <end_input>\n",
      "### OUTPUT : <start_output> [['Gulf Resources', 'ORG'], ['earlier this year', 'DATE'], ['Bermuda', 'GPE']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> And as a result I would argue that really masked what is actually a fundemental inflection point the flattening of the world that we 're going from a vertical value creation model of command and control to a much more horizontal one of connect and collaborate /. <end_input>\n",
      "### OUTPUT : <start_output> [] <end_output>\n",
      "\n",
      "### INPUT : <start_input> It will expand co-operation with developed countries and the widely developing countries , expand fields for opening up to the outside world , and continue experiments utilizing foreign investment in the insurance industry and retail commerce industry . <end_input>\n",
      "### OUTPUT : <start_output> [] <end_output>\n",
      "\n",
      "### INPUT : <start_input> Our production relations are no different from the production relations in Marx 's \" Das Kapital , \" constantly reproducing a proletariat who can only rely on selling its labor to make a living . <end_input>\n",
      "### OUTPUT : <start_output> [['Marx', 'PERSON'], ['Das Kapital', 'WORK_OF_ART']] <end_output>\n",
      "\n",
      "### ASSISTANT : I will extract all the named entities in the text that has one of the 18 tags of the OntoNote5 dataset and output a python list of tuples containing the named entitiy and its own tag. Now provide me the sentence.\n",
      "### INPUT : <start_input> The water used comes from the Chishui river that flows over cinnabar quality soil and selectively uses such locally produced raw materials as sorghum , high quality wheat , etc. and is fermented during the period from the Chinese Dragon Boat Festival to the Double Ninth Festival . <end_input>\n",
      "### OUTPUT : <start_output> [\n",
      "### SYSTEM : The task is to extract named entites in a sentence.\n",
      "    A named entity refers to a specific, named object, concept, location, person, organization, or other entities that have a proper name. Named entities are typically unique and distinguishable entities that can be explicitly named or referred to in text. \n",
      "    The goal of named entity extraction is to identify and classify these entities within a given text.\n",
      "    We are working with 18 types of entities of the OntoNote5 dataset that are listed below with their description :\n",
      "        \"CARDINAL\": \"Numerals that do not fall under another type.\",\n",
      "        \"ORDINAL\": \"Words or expressions indicating order.\",\n",
      "        \"WORK_OF_ART\": \"Titles of creative works.\",\n",
      "        \"PERSON\": \"Names of people, including fictional and real characters.\",\n",
      "        \"LOC\": \"Geographical locations, both physical and political.\",\n",
      "        \"DATE\": \"Temporal expressions indicating dates or periods.\",\n",
      "        \"PERCENT\": \"Percentage values.\",\n",
      "        \"PRODUCT\": \"Names of products or services.\",\n",
      "        \"MONEY\": \"Monetary values, including currency symbols.\",\n",
      "        \"FAC\": \"Named facilities, such as buildings, airports, or highways.\",\n",
      "        \"TIME\": \"Temporal expressions indicating times of the day.\",\n",
      "        \"ORG\": \"Names of organizations, institutions, or companies.\",\n",
      "        \"QUANTITY\": \"Measurements or counts, including units.\",\n",
      "        \"LANGUAGE\": \"Names of languages.\",\n",
      "        \"GPE\": \"Geopolitical entities, such as countries, cities, or states.\",\n",
      "        \"LAW\": \"Legal references, including laws and legal concepts.\",\n",
      "        \"NORP\": \"Nationalities, religious, or political groups.\",\n",
      "        \"EVENT\": \"Named occurrences or incidents.\n",
      "### USER : I want you to extract all the named entities in the text and tag them with one of the tag of the OntoNote5 dataset.\n",
      "### ASSISTANT : What is the format of the output ?\n",
      "### USER : You have to output a python list of tuples. In each tuple, you have a the named entity and its own tag. For exemple, with the sentence \"Japan is a country\" as input, you would answer \"[('Japan', 'GPE')]\". \n",
      "### ASSISTANT : Can you provide me examples ?  \n",
      "### USER : There are examples : \n",
      "### INPUT : <start_input> We have seen some more power techniques perhaps from his Foreign Minister Amre Moussa over the last few weeks , but Amre Moussa today at the Foreign Minister 's meeting was calling simply for the return of East Jerusalem to the Palestinians , in stark contrast to Syrian Foreign Minister Faruq al - Shara who was pulling for a complete cut in diplomatic relations between Israel and the two Arab states that happen . <end_input>\n",
      "### OUTPUT : <start_output> [['Amre Moussa', 'PERSON'], ['the last few weeks', 'DATE'], ['Amre Moussa', 'PERSON'], ['today', 'DATE'], ['East Jerusalem', 'GPE'], ['Palestinians', 'NORP'], ['Syrian', 'NORP'], ['Faruq al - Shara', 'PERSON'], ['Israel', 'GPE'], ['two', 'CARDINAL'], ['Arab', 'NORP']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> Old folk in the South remember when wax apples were \" just something to munch on \" - the kind of fruit that grew freely and that you could help yourself to . <end_input>\n",
      "### OUTPUT : <start_output> [['South', 'LOC']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> Bolar , the subject of a criminal investigation by the FDA and the Inspector General 's office of the Health and Human Services Department , only agreed to recall two strengths of its version of Macrodantin `` as far down as direct customers , mostly wholesalers , '' Mr. Nesbit said . <end_input>\n",
      "### OUTPUT : <start_output> [['Bolar', 'ORG'], ['FDA', 'ORG'], ['the Health and Human Services Department', 'ORG'], ['two', 'CARDINAL'], ['Macrodantin', 'PRODUCT'], ['Nesbit', 'PERSON']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> The situation you mentioned , is it common or is it a rather extreme example , because generally , people will think that grandparents will particularly love and care about their grandchildren ? <end_input>\n",
      "### OUTPUT : <start_output> [] <end_output>\n",
      "\n",
      "### INPUT : <start_input> \" We do n't take much of a break for the Chinese New Year 's holidays , \" says Andrew Yeh , chairman of Dongguan 's Powin Electric , which makes cable for the telecoms industry . <end_input>\n",
      "### OUTPUT : <start_output> [[\"Chinese New Year 's\", 'EVENT'], ['Andrew Yeh', 'PERSON'], ['Dongguan', 'GPE'], ['Powin Electric', 'ORG']] <end_output>\n",
      "\n",
      "### ASSISTANT : I will extract all the named entities in the text that has one of the 18 tags of the OntoNote5 dataset and output a python list of tuples containing the named entitiy and its own tag. Now provide me the sentence.\n",
      "### INPUT : <start_input> In particular , biochips not only can speed the pace of research , but can also replace laboratory animals such as rats and rabbits in many experiments , with tests being carried out directly on human genes on the chip . <end_input>\n",
      "### OUTPUT : <start_output> [\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 40/50 [00:03<00:00, 11.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### SYSTEM : The task is to extract named entites in a sentence.\n",
      "    A named entity refers to a specific, named object, concept, location, person, organization, or other entities that have a proper name. Named entities are typically unique and distinguishable entities that can be explicitly named or referred to in text. \n",
      "    The goal of named entity extraction is to identify and classify these entities within a given text.\n",
      "    We are working with 18 types of entities of the OntoNote5 dataset that are listed below with their description :\n",
      "        \"CARDINAL\": \"Numerals that do not fall under another type.\",\n",
      "        \"ORDINAL\": \"Words or expressions indicating order.\",\n",
      "        \"WORK_OF_ART\": \"Titles of creative works.\",\n",
      "        \"PERSON\": \"Names of people, including fictional and real characters.\",\n",
      "        \"LOC\": \"Geographical locations, both physical and political.\",\n",
      "        \"DATE\": \"Temporal expressions indicating dates or periods.\",\n",
      "        \"PERCENT\": \"Percentage values.\",\n",
      "        \"PRODUCT\": \"Names of products or services.\",\n",
      "        \"MONEY\": \"Monetary values, including currency symbols.\",\n",
      "        \"FAC\": \"Named facilities, such as buildings, airports, or highways.\",\n",
      "        \"TIME\": \"Temporal expressions indicating times of the day.\",\n",
      "        \"ORG\": \"Names of organizations, institutions, or companies.\",\n",
      "        \"QUANTITY\": \"Measurements or counts, including units.\",\n",
      "        \"LANGUAGE\": \"Names of languages.\",\n",
      "        \"GPE\": \"Geopolitical entities, such as countries, cities, or states.\",\n",
      "        \"LAW\": \"Legal references, including laws and legal concepts.\",\n",
      "        \"NORP\": \"Nationalities, religious, or political groups.\",\n",
      "        \"EVENT\": \"Named occurrences or incidents.\n",
      "### USER : I want you to extract all the named entities in the text and tag them with one of the tag of the OntoNote5 dataset.\n",
      "### ASSISTANT : What is the format of the output ?\n",
      "### USER : You have to output a python list of tuples. In each tuple, you have a the named entity and its own tag. For exemple, with the sentence \"Japan is a country\" as input, you would answer \"[('Japan', 'GPE')]\". \n",
      "### ASSISTANT : Can you provide me examples ?  \n",
      "### USER : There are examples : \n",
      "### INPUT : <start_input> `` Last time , we got rewarded for going out and buying stocks when the panic was the worst , '' said John W. Rogers , president of Chicago - based Ariel Capital Management Inc. , which manages $ 1.1 billion of stocks . <end_input>\n",
      "### OUTPUT : <start_output> [['John W. Rogers', 'PERSON'], ['Chicago', 'GPE'], ['Ariel Capital Management Inc.', 'ORG'], ['$ 1.1 billion', 'MONEY']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> There were some fluctuations in growth rates of every quarter of the whole year , but the difference was not significant , which can be regarded as a steady operation . <end_input>\n",
      "### OUTPUT : <start_output> [['the whole year', 'DATE']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> He concluded his remarks by quoting , emotionally and at some length , according to those present , the late Martin Luther King 's famous `` I Have a Dream '' speech from the 1963 March on Washington . <end_input>\n",
      "### OUTPUT : <start_output> [['Martin Luther King', 'PERSON'], ['I Have a Dream', 'WORK_OF_ART'], ['1963', 'DATE'], ['March on Washington', 'EVENT']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> But I am suggesting that they stop requiring Mr. Mason to interrupt his classic shtik with some line about `` caring for other people '' that would sound shmaltzy on the lips of Miss America . <end_input>\n",
      "### OUTPUT : <start_output> [['Mason', 'PERSON'], ['Miss America', 'PERSON']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> It very well could , although , I must say that the Gore campaign has been somewhat disappointed by the number of votes they have not received thus far in the counties that are undertaking the manual recounts , Brian , but a lot of hand counts still must be tallied . <end_input>\n",
      "### OUTPUT : <start_output> [['Gore', 'PERSON'], ['Brian', 'PERSON']] <end_output>\n",
      "\n",
      "### ASSISTANT : I will extract all the named entities in the text that has one of the 18 tags of the OntoNote5 dataset and output a python list of tuples containing the named entitiy and its own tag. Now provide me the sentence.\n",
      "### INPUT : <start_input> It is an insult to China 's family planning policy , has seriously violated the mission and principles of the UN charter , and sets a very bad precedent for the provision of aid to multi-lateral organizations of the UN . <end_input>\n",
      "### OUTPUT : <start_output> [\n",
      "### SYSTEM : The task is to extract named entites in a sentence.\n",
      "    A named entity refers to a specific, named object, concept, location, person, organization, or other entities that have a proper name. Named entities are typically unique and distinguishable entities that can be explicitly named or referred to in text. \n",
      "    The goal of named entity extraction is to identify and classify these entities within a given text.\n",
      "    We are working with 18 types of entities of the OntoNote5 dataset that are listed below with their description :\n",
      "        \"CARDINAL\": \"Numerals that do not fall under another type.\",\n",
      "        \"ORDINAL\": \"Words or expressions indicating order.\",\n",
      "        \"WORK_OF_ART\": \"Titles of creative works.\",\n",
      "        \"PERSON\": \"Names of people, including fictional and real characters.\",\n",
      "        \"LOC\": \"Geographical locations, both physical and political.\",\n",
      "        \"DATE\": \"Temporal expressions indicating dates or periods.\",\n",
      "        \"PERCENT\": \"Percentage values.\",\n",
      "        \"PRODUCT\": \"Names of products or services.\",\n",
      "        \"MONEY\": \"Monetary values, including currency symbols.\",\n",
      "        \"FAC\": \"Named facilities, such as buildings, airports, or highways.\",\n",
      "        \"TIME\": \"Temporal expressions indicating times of the day.\",\n",
      "        \"ORG\": \"Names of organizations, institutions, or companies.\",\n",
      "        \"QUANTITY\": \"Measurements or counts, including units.\",\n",
      "        \"LANGUAGE\": \"Names of languages.\",\n",
      "        \"GPE\": \"Geopolitical entities, such as countries, cities, or states.\",\n",
      "        \"LAW\": \"Legal references, including laws and legal concepts.\",\n",
      "        \"NORP\": \"Nationalities, religious, or political groups.\",\n",
      "        \"EVENT\": \"Named occurrences or incidents.\n",
      "### USER : I want you to extract all the named entities in the text and tag them with one of the tag of the OntoNote5 dataset.\n",
      "### ASSISTANT : What is the format of the output ?\n",
      "### USER : You have to output a python list of tuples. In each tuple, you have a the named entity and its own tag. For exemple, with the sentence \"Japan is a country\" as input, you would answer \"[('Japan', 'GPE')]\". \n",
      "### ASSISTANT : Can you provide me examples ?  \n",
      "### USER : There are examples : \n",
      "### INPUT : <start_input> A reporter asked : on August 23rd , the US president signed the \" 1995 financial year overseas activities fund appropriation act \" in which it is stipulated that any donation made by the US to the UN population fund must not be used in China . <end_input>\n",
      "### OUTPUT : <start_output> [['August 23rd', 'DATE'], ['US', 'GPE'], ['1995', 'DATE'], ['financial year overseas activities fund appropriation act', 'LAW'], ['US', 'GPE'], ['UN', 'ORG'], ['China', 'GPE']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> And even if a nurse would wear flowers in her hair while on duty , if she were engaged she would know to wear them behind her left , not right , ear . <end_input>\n",
      "### OUTPUT : <start_output> [] <end_output>\n",
      "\n",
      "### INPUT : <start_input> We 're expecting that the Homeland Security Secretary will announce , that this Iraqi lawyer , who provided the information to U.S. military authority IES has been granted asylum here in the United States , together with his wife and daughter . <end_input>\n",
      "### OUTPUT : <start_output> [['Homeland Security', 'ORG'], ['Iraqi', 'NORP'], ['U.S.', 'GPE'], ['IES', 'ORG'], ['the United States', 'GPE']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> A glance at the title , people with a little political sensitivity may roughly understand the core topic of this article : the rule of benign interaction between planned economy and market economy , and between public ownership and private ownership -- because only their relationships are those between a father and a son , and it is only between them are there different conflicts involving \" human relations , \" \" rules \" and \" science , \" as well as bloody wrestling between classes , factions and individuals on the basis of morality and interests . <end_input>\n",
      "### OUTPUT : <start_output> [] <end_output>\n",
      "\n",
      "### INPUT : <start_input> Royal Bank of Scotland Group PLC , an Edinburgh , Scotland , financial services company , will list American depositary shares , representing preferred shares , with the symbol RBSPr . <end_input>\n",
      "### OUTPUT : <start_output> [['Royal Bank of Scotland Group PLC', 'ORG'], ['Edinburgh', 'GPE'], ['Scotland', 'GPE'], ['American', 'NORP'], ['RBSPr', 'ORG']] <end_output>\n",
      "\n",
      "### ASSISTANT : I will extract all the named entities in the text that has one of the 18 tags of the OntoNote5 dataset and output a python list of tuples containing the named entitiy and its own tag. Now provide me the sentence.\n",
      "### INPUT : <start_input> A relevant State Council Special Zone Office director expressed that , in order to encourage foreign businessmen to carry out investment in the mid and western areas , foreign businessmen will be allowed , in the mid and western areas , to initiate projects in which China 's industrial policy restricts foreign business investment but which can make use of manpower resources . <end_input>\n",
      "### OUTPUT : <start_output> [\n",
      "### SYSTEM : The task is to extract named entites in a sentence.\n",
      "    A named entity refers to a specific, named object, concept, location, person, organization, or other entities that have a proper name. Named entities are typically unique and distinguishable entities that can be explicitly named or referred to in text. \n",
      "    The goal of named entity extraction is to identify and classify these entities within a given text.\n",
      "    We are working with 18 types of entities of the OntoNote5 dataset that are listed below with their description :\n",
      "        \"CARDINAL\": \"Numerals that do not fall under another type.\",\n",
      "        \"ORDINAL\": \"Words or expressions indicating order.\",\n",
      "        \"WORK_OF_ART\": \"Titles of creative works.\",\n",
      "        \"PERSON\": \"Names of people, including fictional and real characters.\",\n",
      "        \"LOC\": \"Geographical locations, both physical and political.\",\n",
      "        \"DATE\": \"Temporal expressions indicating dates or periods.\",\n",
      "        \"PERCENT\": \"Percentage values.\",\n",
      "        \"PRODUCT\": \"Names of products or services.\",\n",
      "        \"MONEY\": \"Monetary values, including currency symbols.\",\n",
      "        \"FAC\": \"Named facilities, such as buildings, airports, or highways.\",\n",
      "        \"TIME\": \"Temporal expressions indicating times of the day.\",\n",
      "        \"ORG\": \"Names of organizations, institutions, or companies.\",\n",
      "        \"QUANTITY\": \"Measurements or counts, including units.\",\n",
      "        \"LANGUAGE\": \"Names of languages.\",\n",
      "        \"GPE\": \"Geopolitical entities, such as countries, cities, or states.\",\n",
      "        \"LAW\": \"Legal references, including laws and legal concepts.\",\n",
      "        \"NORP\": \"Nationalities, religious, or political groups.\",\n",
      "        \"EVENT\": \"Named occurrences or incidents.\n",
      "### USER : I want you to extract all the named entities in the text and tag them with one of the tag of the OntoNote5 dataset.\n",
      "### ASSISTANT : What is the format of the output ?\n",
      "### USER : You have to output a python list of tuples. In each tuple, you have a the named entity and its own tag. For exemple, with the sentence \"Japan is a country\" as input, you would answer \"[('Japan', 'GPE')]\". \n",
      "### ASSISTANT : Can you provide me examples ?  \n",
      "### USER : There are examples : \n",
      "### INPUT : <start_input> The next one was skip - generation custody , accounting for 16.9 percent . While those who lived with relatives or were entrusted to the care of someone else made up 4.1 percent and .9 percent of the total number of left - behind children , respectively . <end_input>\n",
      "### OUTPUT : <start_output> [['one', 'CARDINAL'], ['16.9 percent', 'PERCENT'], ['4.1 percent', 'PERCENT'], ['.9 percent', 'PERCENT']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> Its watchers are , on the whole , a disloyal group of channel - zapping `` grazers '' and news junkies , who spend an average of just 26 minutes a day watching CNN , according to audience research . <end_input>\n",
      "### OUTPUT : <start_output> [['just 26 minutes', 'TIME'], ['CNN', 'ORG']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> Because despite all the media prattle about comedy and politics not mixing , they are similar in one respect : Both can serve as mechanisms for easing tensions and facilitating the co-existence of groups in conflict . <end_input>\n",
      "### OUTPUT : <start_output> [['one', 'CARDINAL']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> Just as he did that , that 's when you saw the child just walking just a few feet away from him but the officers were able to get the child away . <end_input>\n",
      "### OUTPUT : <start_output> [['just a few feet', 'QUANTITY']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> Although low land and labor costs are Dongguan 's main attractions , Taiwan firms also choose the locale for the networks of people and producers that have been built up among Taiwanese in Dongguan over the last ten years . <end_input>\n",
      "### OUTPUT : <start_output> [['Dongguan', 'GPE'], ['Taiwan', 'GPE'], ['Taiwanese', 'NORP'], ['Dongguan', 'GPE'], ['the last ten years', 'DATE']] <end_output>\n",
      "\n",
      "### ASSISTANT : I will extract all the named entities in the text that has one of the 18 tags of the OntoNote5 dataset and output a python list of tuples containing the named entitiy and its own tag. Now provide me the sentence.\n",
      "### INPUT : <start_input> On the other hand , I think it can also fully show the level of people 's satisfaction with emergency mechanisms of the operational departments of the government in handling this incident . <end_input>\n",
      "### OUTPUT : <start_output> [\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 44/50 [00:03<00:00, 11.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### SYSTEM : The task is to extract named entites in a sentence.\n",
      "    A named entity refers to a specific, named object, concept, location, person, organization, or other entities that have a proper name. Named entities are typically unique and distinguishable entities that can be explicitly named or referred to in text. \n",
      "    The goal of named entity extraction is to identify and classify these entities within a given text.\n",
      "    We are working with 18 types of entities of the OntoNote5 dataset that are listed below with their description :\n",
      "        \"CARDINAL\": \"Numerals that do not fall under another type.\",\n",
      "        \"ORDINAL\": \"Words or expressions indicating order.\",\n",
      "        \"WORK_OF_ART\": \"Titles of creative works.\",\n",
      "        \"PERSON\": \"Names of people, including fictional and real characters.\",\n",
      "        \"LOC\": \"Geographical locations, both physical and political.\",\n",
      "        \"DATE\": \"Temporal expressions indicating dates or periods.\",\n",
      "        \"PERCENT\": \"Percentage values.\",\n",
      "        \"PRODUCT\": \"Names of products or services.\",\n",
      "        \"MONEY\": \"Monetary values, including currency symbols.\",\n",
      "        \"FAC\": \"Named facilities, such as buildings, airports, or highways.\",\n",
      "        \"TIME\": \"Temporal expressions indicating times of the day.\",\n",
      "        \"ORG\": \"Names of organizations, institutions, or companies.\",\n",
      "        \"QUANTITY\": \"Measurements or counts, including units.\",\n",
      "        \"LANGUAGE\": \"Names of languages.\",\n",
      "        \"GPE\": \"Geopolitical entities, such as countries, cities, or states.\",\n",
      "        \"LAW\": \"Legal references, including laws and legal concepts.\",\n",
      "        \"NORP\": \"Nationalities, religious, or political groups.\",\n",
      "        \"EVENT\": \"Named occurrences or incidents.\n",
      "### USER : I want you to extract all the named entities in the text and tag them with one of the tag of the OntoNote5 dataset.\n",
      "### ASSISTANT : What is the format of the output ?\n",
      "### USER : You have to output a python list of tuples. In each tuple, you have a the named entity and its own tag. For exemple, with the sentence \"Japan is a country\" as input, you would answer \"[('Japan', 'GPE')]\". \n",
      "### ASSISTANT : Can you provide me examples ?  \n",
      "### USER : There are examples : \n",
      "### INPUT : <start_input> I think that this mentality in facing emergencies , in one respect shows a great change of mentality that Beijing citizens now have after enduring several tests in the past , and a kind of calmness and maturity after having experienced frustrations . <end_input>\n",
      "### OUTPUT : <start_output> [['one', 'CARDINAL'], ['Beijing', 'GPE']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> The result is definitely a tragedy -- because even if you kill the \" father , \" your felony will be disdained by the age and condemned by the people , which naturally leads to nothing good ! <end_input>\n",
      "### OUTPUT : <start_output> [] <end_output>\n",
      "\n",
      "### INPUT : <start_input> Rather than the ridiculous accident censors tried to make it out to be , I think it has to be recognized as a planned , purposeful piece of black magic , perpetraited literally in front of the world , on a very alchemically significant day and time <end_input>\n",
      "### OUTPUT : <start_output> [] <end_output>\n",
      "\n",
      "### INPUT : <start_input> And this is another reason why I think for a relatively cheap price a face to face negotiation at the level of Chris Hill who again is very competent I believe would set the stage for a final agreement at the six party talks Which is essential Which is basically a good agreement /. <end_input>\n",
      "### OUTPUT : <start_output> [['Chris Hill', 'PERSON'], ['six', 'CARDINAL']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> These critics fail to distinguish between the type of ethnic humor that aims at disparaging another group , such as `` Polish jokes '' ; and the type that is double - edged , aiming inward as well as outward . <end_input>\n",
      "### OUTPUT : <start_output> [['Polish', 'NORP']] <end_output>\n",
      "\n",
      "### ASSISTANT : I will extract all the named entities in the text that has one of the 18 tags of the OntoNote5 dataset and output a python list of tuples containing the named entitiy and its own tag. Now provide me the sentence.\n",
      "### INPUT : <start_input> By next May 31 , stocks of U.S. wheat to be carried over into the next season -- before the winter wheat now being planted is harvested -- are projected to drop to 443 million bushels . <end_input>\n",
      "### OUTPUT : <start_output> [\n",
      "### SYSTEM : The task is to extract named entites in a sentence.\n",
      "    A named entity refers to a specific, named object, concept, location, person, organization, or other entities that have a proper name. Named entities are typically unique and distinguishable entities that can be explicitly named or referred to in text. \n",
      "    The goal of named entity extraction is to identify and classify these entities within a given text.\n",
      "    We are working with 18 types of entities of the OntoNote5 dataset that are listed below with their description :\n",
      "        \"CARDINAL\": \"Numerals that do not fall under another type.\",\n",
      "        \"ORDINAL\": \"Words or expressions indicating order.\",\n",
      "        \"WORK_OF_ART\": \"Titles of creative works.\",\n",
      "        \"PERSON\": \"Names of people, including fictional and real characters.\",\n",
      "        \"LOC\": \"Geographical locations, both physical and political.\",\n",
      "        \"DATE\": \"Temporal expressions indicating dates or periods.\",\n",
      "        \"PERCENT\": \"Percentage values.\",\n",
      "        \"PRODUCT\": \"Names of products or services.\",\n",
      "        \"MONEY\": \"Monetary values, including currency symbols.\",\n",
      "        \"FAC\": \"Named facilities, such as buildings, airports, or highways.\",\n",
      "        \"TIME\": \"Temporal expressions indicating times of the day.\",\n",
      "        \"ORG\": \"Names of organizations, institutions, or companies.\",\n",
      "        \"QUANTITY\": \"Measurements or counts, including units.\",\n",
      "        \"LANGUAGE\": \"Names of languages.\",\n",
      "        \"GPE\": \"Geopolitical entities, such as countries, cities, or states.\",\n",
      "        \"LAW\": \"Legal references, including laws and legal concepts.\",\n",
      "        \"NORP\": \"Nationalities, religious, or political groups.\",\n",
      "        \"EVENT\": \"Named occurrences or incidents.\n",
      "### USER : I want you to extract all the named entities in the text and tag them with one of the tag of the OntoNote5 dataset.\n",
      "### ASSISTANT : What is the format of the output ?\n",
      "### USER : You have to output a python list of tuples. In each tuple, you have a the named entity and its own tag. For exemple, with the sentence \"Japan is a country\" as input, you would answer \"[('Japan', 'GPE')]\". \n",
      "### ASSISTANT : Can you provide me examples ?  \n",
      "### USER : There are examples : \n",
      "### INPUT : <start_input> Ah , apart from this , Professor Zhou , what do you think are the areas for improvement for a city , especially a booming city , when handling this kind of public emergency ? <end_input>\n",
      "### OUTPUT : <start_output> [['Zhou', 'PERSON']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> Saddam Hussein -LRB- in language beaming with pride and arrogance -RRB- I want you first of all .. to set me a timetable for the withdrawal from Iraq that your government will commit itself to it in front of the world , and for you to begin the withdrawal operation immediately . <end_input>\n",
      "### OUTPUT : <start_output> [['Saddam Hussein', 'PERSON'], ['first', 'ORDINAL'], ['Iraq', 'GPE']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> In 1984 the EPA notified Gulf Resources , which was a part - owner of the smelter , that it was potentially liable for sharing cleanup costs at the site under the federal Superfund program . <end_input>\n",
      "### OUTPUT : <start_output> [['1984', 'DATE'], ['EPA', 'ORG'], ['Gulf Resources', 'ORG'], ['Superfund', 'ORG']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> Prices have risen 5.9 % in the first nine months of the year , outstripping both the initial 3 % inflation goal set by the government of Socialist Prime Minister Felipe Gonzalez and the second , revised goal of 5.8 % . <end_input>\n",
      "### OUTPUT : <start_output> [['5.9 %', 'PERCENT'], ['the first nine months of the year', 'DATE'], ['3 %', 'PERCENT'], ['Socialist', 'NORP'], ['Felipe Gonzalez', 'PERSON'], ['second', 'ORDINAL'], ['5.8 %', 'PERCENT']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> To make its point , it is challenging the Italian government to explain reports that Olivetti may have supplied the Soviet Union with sophisticated computer - driven devices that could be used to build parts for combat aircraft . <end_input>\n",
      "### OUTPUT : <start_output> [['Italian', 'NORP'], ['Olivetti', 'ORG'], ['the Soviet Union', 'GPE']] <end_output>\n",
      "\n",
      "### ASSISTANT : I will extract all the named entities in the text that has one of the 18 tags of the OntoNote5 dataset and output a python list of tuples containing the named entitiy and its own tag. Now provide me the sentence.\n",
      "### INPUT : <start_input> and that is we are willing to sit down and negotiate with the Iranians assuming and contingent upon their suspension of their nuclear activities at their plant in the in Iran /. <end_input>\n",
      "### OUTPUT : <start_output> [\n",
      "### SYSTEM : The task is to extract named entites in a sentence.\n",
      "    A named entity refers to a specific, named object, concept, location, person, organization, or other entities that have a proper name. Named entities are typically unique and distinguishable entities that can be explicitly named or referred to in text. \n",
      "    The goal of named entity extraction is to identify and classify these entities within a given text.\n",
      "    We are working with 18 types of entities of the OntoNote5 dataset that are listed below with their description :\n",
      "        \"CARDINAL\": \"Numerals that do not fall under another type.\",\n",
      "        \"ORDINAL\": \"Words or expressions indicating order.\",\n",
      "        \"WORK_OF_ART\": \"Titles of creative works.\",\n",
      "        \"PERSON\": \"Names of people, including fictional and real characters.\",\n",
      "        \"LOC\": \"Geographical locations, both physical and political.\",\n",
      "        \"DATE\": \"Temporal expressions indicating dates or periods.\",\n",
      "        \"PERCENT\": \"Percentage values.\",\n",
      "        \"PRODUCT\": \"Names of products or services.\",\n",
      "        \"MONEY\": \"Monetary values, including currency symbols.\",\n",
      "        \"FAC\": \"Named facilities, such as buildings, airports, or highways.\",\n",
      "        \"TIME\": \"Temporal expressions indicating times of the day.\",\n",
      "        \"ORG\": \"Names of organizations, institutions, or companies.\",\n",
      "        \"QUANTITY\": \"Measurements or counts, including units.\",\n",
      "        \"LANGUAGE\": \"Names of languages.\",\n",
      "        \"GPE\": \"Geopolitical entities, such as countries, cities, or states.\",\n",
      "        \"LAW\": \"Legal references, including laws and legal concepts.\",\n",
      "        \"NORP\": \"Nationalities, religious, or political groups.\",\n",
      "        \"EVENT\": \"Named occurrences or incidents.\n",
      "### USER : I want you to extract all the named entities in the text and tag them with one of the tag of the OntoNote5 dataset.\n",
      "### ASSISTANT : What is the format of the output ?\n",
      "### USER : You have to output a python list of tuples. In each tuple, you have a the named entity and its own tag. For exemple, with the sentence \"Japan is a country\" as input, you would answer \"[('Japan', 'GPE')]\". \n",
      "### ASSISTANT : Can you provide me examples ?  \n",
      "### USER : There are examples : \n",
      "### INPUT : <start_input> Thus , in a civil case , a defendant may be called as a witness , he may be forced to testify or take the Fifth , and his taking of the Fifth may permit the drawing of an adverse inference against him in the civil matter . <end_input>\n",
      "### OUTPUT : <start_output> [['Fifth', 'LAW'], ['Fifth', 'LAW']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> But more importantly , we have decided to open channels of dialogue with \" terrorist \" organizations such as Hamas and Jihad and Hezbollah who are loyal to Iran , and other fundamentalist organizations in the whole world . <end_input>\n",
      "### OUTPUT : <start_output> [['Hamas', 'ORG'], ['Jihad', 'ORG'], ['Hezbollah', 'ORG'], ['Iran', 'GPE']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> As Dave Gavlak reports , the US Cole was towed out of the Aden Harbor to a waiting Norwegian transport ship , that will actually carry the damaged destroyer home . <end_input>\n",
      "### OUTPUT : <start_output> [['Dave Gavlak', 'PERSON'], ['the US Cole', 'PRODUCT'], ['the Aden Harbor', 'FAC'], ['Norwegian', 'NORP']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> We are still in crisis and we will be I think for a while , but the current crisis Jonetic hopes will at least be one where government critics will not be branded as traitors and be banned from public performances . <end_input>\n",
      "### OUTPUT : <start_output> [['Jonetic', 'PERSON'], ['one', 'CARDINAL']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> They fear that their children , like they themselves , will have to search through photographs and memories to find Tanshui 's traditional simplicity and the joys of being close to nature . <end_input>\n",
      "### OUTPUT : <start_output> [['Tanshui', 'GPE']] <end_output>\n",
      "\n",
      "### ASSISTANT : I will extract all the named entities in the text that has one of the 18 tags of the OntoNote5 dataset and output a python list of tuples containing the named entitiy and its own tag. Now provide me the sentence.\n",
      "### INPUT : <start_input> Mr. Heinemann said the changes represent a new focus in the magazine industry : a magazine 's net revenue per subscriber , or the actual revenue from subscribers after discounts and the cost of premiums have been stripped away . <end_input>\n",
      "### OUTPUT : <start_output> [\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 46/50 [00:04<00:00, 11.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### SYSTEM : The task is to extract named entites in a sentence.\n",
      "    A named entity refers to a specific, named object, concept, location, person, organization, or other entities that have a proper name. Named entities are typically unique and distinguishable entities that can be explicitly named or referred to in text. \n",
      "    The goal of named entity extraction is to identify and classify these entities within a given text.\n",
      "    We are working with 18 types of entities of the OntoNote5 dataset that are listed below with their description :\n",
      "        \"CARDINAL\": \"Numerals that do not fall under another type.\",\n",
      "        \"ORDINAL\": \"Words or expressions indicating order.\",\n",
      "        \"WORK_OF_ART\": \"Titles of creative works.\",\n",
      "        \"PERSON\": \"Names of people, including fictional and real characters.\",\n",
      "        \"LOC\": \"Geographical locations, both physical and political.\",\n",
      "        \"DATE\": \"Temporal expressions indicating dates or periods.\",\n",
      "        \"PERCENT\": \"Percentage values.\",\n",
      "        \"PRODUCT\": \"Names of products or services.\",\n",
      "        \"MONEY\": \"Monetary values, including currency symbols.\",\n",
      "        \"FAC\": \"Named facilities, such as buildings, airports, or highways.\",\n",
      "        \"TIME\": \"Temporal expressions indicating times of the day.\",\n",
      "        \"ORG\": \"Names of organizations, institutions, or companies.\",\n",
      "        \"QUANTITY\": \"Measurements or counts, including units.\",\n",
      "        \"LANGUAGE\": \"Names of languages.\",\n",
      "        \"GPE\": \"Geopolitical entities, such as countries, cities, or states.\",\n",
      "        \"LAW\": \"Legal references, including laws and legal concepts.\",\n",
      "        \"NORP\": \"Nationalities, religious, or political groups.\",\n",
      "        \"EVENT\": \"Named occurrences or incidents.\n",
      "### USER : I want you to extract all the named entities in the text and tag them with one of the tag of the OntoNote5 dataset.\n",
      "### ASSISTANT : What is the format of the output ?\n",
      "### USER : You have to output a python list of tuples. In each tuple, you have a the named entity and its own tag. For exemple, with the sentence \"Japan is a country\" as input, you would answer \"[('Japan', 'GPE')]\". \n",
      "### ASSISTANT : Can you provide me examples ?  \n",
      "### USER : There are examples : \n",
      "### INPUT : <start_input> The fact of the matter is that there are lots of people in Washington and believe me they 're not all journalists who are speculating what if the guy gets indicted /. <end_input>\n",
      "### OUTPUT : <start_output> [['Washington', 'GPE']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> California 's Governor this week warned that intermittent cutoffs of power around the state may begin as early as next week if nothing more is done to alleviate the crisis . <end_input>\n",
      "### OUTPUT : <start_output> [['California', 'GPE'], ['this week', 'DATE'], ['next week', 'DATE']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> Moody 's Investors Service Inc. said it downgraded its rating to B - 2 from Ba - 3 on less than $ 20 million of this thrift 's senior subordinated notes . <end_input>\n",
      "### OUTPUT : <start_output> [[\"Moody 's Investors Service Inc.\", 'ORG'], ['less than $ 20 million', 'MONEY']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> I think a number of the reforms that have come via the Sarbanes - Oxley Act and a number of things that we have done at the SEC are basically making everybody take a new look at how they 're performing their duty as a director , how they 're performing their duties on audit committees and compensation committees and in Wall Street . <end_input>\n",
      "### OUTPUT : <start_output> [['the Sarbanes - Oxley Act', 'LAW'], ['SEC', 'ORG'], ['Wall Street', 'ORG']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> We do have to try to reduce the violee and take a turn back for a period of calmness so that we can move back to a peace process , but even if the violence subsides , Israelis and Palestinians will still have to deal with an open wound -- a scar so long and so deep from these last two weeks , it may be years before there is a real effort at talking peace again . <end_input>\n",
      "### OUTPUT : <start_output> [['Israelis', 'NORP'], ['Palestinians', 'NORP'], ['these last two weeks', 'DATE'], ['years', 'DATE']] <end_output>\n",
      "\n",
      "### ASSISTANT : I will extract all the named entities in the text that has one of the 18 tags of the OntoNote5 dataset and output a python list of tuples containing the named entitiy and its own tag. Now provide me the sentence.\n",
      "### INPUT : <start_input> Since the end of 1995 , when the program changed from the appraisal phase into the implementation phase , the three countries : China , Russia and North Korea , have all implemented some infrastructure construction and activities for attracting business and investment , and have initially started bilateral and multilateral cooperation . <end_input>\n",
      "### OUTPUT : <start_output> [\n",
      "### SYSTEM : The task is to extract named entites in a sentence.\n",
      "    A named entity refers to a specific, named object, concept, location, person, organization, or other entities that have a proper name. Named entities are typically unique and distinguishable entities that can be explicitly named or referred to in text. \n",
      "    The goal of named entity extraction is to identify and classify these entities within a given text.\n",
      "    We are working with 18 types of entities of the OntoNote5 dataset that are listed below with their description :\n",
      "        \"CARDINAL\": \"Numerals that do not fall under another type.\",\n",
      "        \"ORDINAL\": \"Words or expressions indicating order.\",\n",
      "        \"WORK_OF_ART\": \"Titles of creative works.\",\n",
      "        \"PERSON\": \"Names of people, including fictional and real characters.\",\n",
      "        \"LOC\": \"Geographical locations, both physical and political.\",\n",
      "        \"DATE\": \"Temporal expressions indicating dates or periods.\",\n",
      "        \"PERCENT\": \"Percentage values.\",\n",
      "        \"PRODUCT\": \"Names of products or services.\",\n",
      "        \"MONEY\": \"Monetary values, including currency symbols.\",\n",
      "        \"FAC\": \"Named facilities, such as buildings, airports, or highways.\",\n",
      "        \"TIME\": \"Temporal expressions indicating times of the day.\",\n",
      "        \"ORG\": \"Names of organizations, institutions, or companies.\",\n",
      "        \"QUANTITY\": \"Measurements or counts, including units.\",\n",
      "        \"LANGUAGE\": \"Names of languages.\",\n",
      "        \"GPE\": \"Geopolitical entities, such as countries, cities, or states.\",\n",
      "        \"LAW\": \"Legal references, including laws and legal concepts.\",\n",
      "        \"NORP\": \"Nationalities, religious, or political groups.\",\n",
      "        \"EVENT\": \"Named occurrences or incidents.\n",
      "### USER : I want you to extract all the named entities in the text and tag them with one of the tag of the OntoNote5 dataset.\n",
      "### ASSISTANT : What is the format of the output ?\n",
      "### USER : You have to output a python list of tuples. In each tuple, you have a the named entity and its own tag. For exemple, with the sentence \"Japan is a country\" as input, you would answer \"[('Japan', 'GPE')]\". \n",
      "### ASSISTANT : Can you provide me examples ?  \n",
      "### USER : There are examples : \n",
      "### INPUT : <start_input> Many others at the same time in life have opted to take early retirement and find a guru in India , work as a volunteer , or do whatever else they want to do . <end_input>\n",
      "### OUTPUT : <start_output> [['India', 'GPE']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> As we said , earlier this week , Christine Todd Whitman stepped down and now a whole lot of analysis is taking place as to why she stepped down , the job she 's done when she was in office and the job that has yet to be complete . <end_input>\n",
      "### OUTPUT : <start_output> [['earlier this week', 'DATE'], ['Christine Todd Whitman', 'PERSON']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> According to DPP lawmaker Lin Cho - shui , Chen Shui - bian has shown more goodwill to Beijing as president than Lee Teng - hui ever did , but without any response - <end_input>\n",
      "### OUTPUT : <start_output> [['DPP', 'ORG'], ['Lin Cho - shui', 'PERSON'], ['Chen Shui - bian', 'PERSON'], ['Beijing', 'GPE'], ['Lee Teng - hui', 'PERSON']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> Uruguay resolutely supports the recovery of China 's status as a signatory country of GATT , and believes that it will make active contributions in the future World Trade Organization . <end_input>\n",
      "### OUTPUT : <start_output> [['Uruguay', 'GPE'], ['China', 'GPE'], ['GATT', 'ORG'], ['World Trade Organization', 'ORG']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> Based on our experience in Iraq particularly with our emphasis on the weapons of mass destruction that did not materialize John Deutch the former head of the CIA offered this observation /. <end_input>\n",
      "### OUTPUT : <start_output> [['Iraq', 'GPE'], ['John Deutch', 'PERSON'], ['CIA', 'ORG']] <end_output>\n",
      "\n",
      "### ASSISTANT : I will extract all the named entities in the text that has one of the 18 tags of the OntoNote5 dataset and output a python list of tuples containing the named entitiy and its own tag. Now provide me the sentence.\n",
      "### INPUT : <start_input> The Wangma Computer Company , a high science and technology enterprise in Beijing 's Zhongguan village , held a press conference in the Great Hall Of the People on January 4th and announced : to meet urgent demands for office automation of all Party departments , the government and the army , it was decided to \" open \" a whole set of top - quality products of Wangma Software , which can profit more than one million yuan , to the home , all in the way to non-encoded floppy disks , exempting technical fees , so that all domestic computer users can copy and use . <end_input>\n",
      "### OUTPUT : <start_output> [\n",
      "### SYSTEM : The task is to extract named entites in a sentence.\n",
      "    A named entity refers to a specific, named object, concept, location, person, organization, or other entities that have a proper name. Named entities are typically unique and distinguishable entities that can be explicitly named or referred to in text. \n",
      "    The goal of named entity extraction is to identify and classify these entities within a given text.\n",
      "    We are working with 18 types of entities of the OntoNote5 dataset that are listed below with their description :\n",
      "        \"CARDINAL\": \"Numerals that do not fall under another type.\",\n",
      "        \"ORDINAL\": \"Words or expressions indicating order.\",\n",
      "        \"WORK_OF_ART\": \"Titles of creative works.\",\n",
      "        \"PERSON\": \"Names of people, including fictional and real characters.\",\n",
      "        \"LOC\": \"Geographical locations, both physical and political.\",\n",
      "        \"DATE\": \"Temporal expressions indicating dates or periods.\",\n",
      "        \"PERCENT\": \"Percentage values.\",\n",
      "        \"PRODUCT\": \"Names of products or services.\",\n",
      "        \"MONEY\": \"Monetary values, including currency symbols.\",\n",
      "        \"FAC\": \"Named facilities, such as buildings, airports, or highways.\",\n",
      "        \"TIME\": \"Temporal expressions indicating times of the day.\",\n",
      "        \"ORG\": \"Names of organizations, institutions, or companies.\",\n",
      "        \"QUANTITY\": \"Measurements or counts, including units.\",\n",
      "        \"LANGUAGE\": \"Names of languages.\",\n",
      "        \"GPE\": \"Geopolitical entities, such as countries, cities, or states.\",\n",
      "        \"LAW\": \"Legal references, including laws and legal concepts.\",\n",
      "        \"NORP\": \"Nationalities, religious, or political groups.\",\n",
      "        \"EVENT\": \"Named occurrences or incidents.\n",
      "### USER : I want you to extract all the named entities in the text and tag them with one of the tag of the OntoNote5 dataset.\n",
      "### ASSISTANT : What is the format of the output ?\n",
      "### USER : You have to output a python list of tuples. In each tuple, you have a the named entity and its own tag. For exemple, with the sentence \"Japan is a country\" as input, you would answer \"[('Japan', 'GPE')]\". \n",
      "### ASSISTANT : Can you provide me examples ?  \n",
      "### USER : There are examples : \n",
      "### INPUT : <start_input> Through more than ten years ' market development , China has now become the world 's main down manufacturing country and down products export country , annually exporting nearly 30,000 tons of down and over 20 million down products , with earned foreign exchange reaching 820 million US dollars , including down clothing export values accounting for more than 50 % of total industry export values . <end_input>\n",
      "### OUTPUT : <start_output> [[\"more than ten years '\", 'DATE'], ['China', 'GPE'], ['nearly 30,000 tons', 'QUANTITY'], ['over 20 million', 'CARDINAL'], ['820 million US dollars', 'MONEY'], ['more than 50 %', 'PERCENT']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> there would be a minimum amount of work , of about %uh , a day a week for the next two three years . mhm . Which is sufficient to pay all my bills then <end_input>\n",
      "### OUTPUT : <start_output> [['the next two three years', 'DATE']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> We are currently re-evaluating our positions , we want to stop the bloodshed on both sides and so our offer is made from the point of strength and not from the point of weakness . <end_input>\n",
      "### OUTPUT : <start_output> [] <end_output>\n",
      "\n",
      "### INPUT : <start_input> Rightly or wrongly , many giant institutional investors appear to be fighting the latest war by applying the lesson they learned in the October 1987 crash : Buying at the bottom pays off . <end_input>\n",
      "### OUTPUT : <start_output> [['October 1987', 'DATE']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> As a psychologist through all the interviews that I 've conducted all the cases that I 've reviewed what I 've learned is that these people while bright um and while at some level charming are emotionally and spiritually bankrupt /. <end_input>\n",
      "### OUTPUT : <start_output> [] <end_output>\n",
      "\n",
      "### ASSISTANT : I will extract all the named entities in the text that has one of the 18 tags of the OntoNote5 dataset and output a python list of tuples containing the named entitiy and its own tag. Now provide me the sentence.\n",
      "### INPUT : <start_input> For several years , the United Nations Development and Planning Office has , as always , supported the Tumen River development , and actively helped the three countries : China , Russia and North Korea , to attract world business and to help implement feasibility studies for development projects . <end_input>\n",
      "### OUTPUT : <start_output> [\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:04<00:00, 11.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### SYSTEM : The task is to extract named entites in a sentence.\n",
      "    A named entity refers to a specific, named object, concept, location, person, organization, or other entities that have a proper name. Named entities are typically unique and distinguishable entities that can be explicitly named or referred to in text. \n",
      "    The goal of named entity extraction is to identify and classify these entities within a given text.\n",
      "    We are working with 18 types of entities of the OntoNote5 dataset that are listed below with their description :\n",
      "        \"CARDINAL\": \"Numerals that do not fall under another type.\",\n",
      "        \"ORDINAL\": \"Words or expressions indicating order.\",\n",
      "        \"WORK_OF_ART\": \"Titles of creative works.\",\n",
      "        \"PERSON\": \"Names of people, including fictional and real characters.\",\n",
      "        \"LOC\": \"Geographical locations, both physical and political.\",\n",
      "        \"DATE\": \"Temporal expressions indicating dates or periods.\",\n",
      "        \"PERCENT\": \"Percentage values.\",\n",
      "        \"PRODUCT\": \"Names of products or services.\",\n",
      "        \"MONEY\": \"Monetary values, including currency symbols.\",\n",
      "        \"FAC\": \"Named facilities, such as buildings, airports, or highways.\",\n",
      "        \"TIME\": \"Temporal expressions indicating times of the day.\",\n",
      "        \"ORG\": \"Names of organizations, institutions, or companies.\",\n",
      "        \"QUANTITY\": \"Measurements or counts, including units.\",\n",
      "        \"LANGUAGE\": \"Names of languages.\",\n",
      "        \"GPE\": \"Geopolitical entities, such as countries, cities, or states.\",\n",
      "        \"LAW\": \"Legal references, including laws and legal concepts.\",\n",
      "        \"NORP\": \"Nationalities, religious, or political groups.\",\n",
      "        \"EVENT\": \"Named occurrences or incidents.\n",
      "### USER : I want you to extract all the named entities in the text and tag them with one of the tag of the OntoNote5 dataset.\n",
      "### ASSISTANT : What is the format of the output ?\n",
      "### USER : You have to output a python list of tuples. In each tuple, you have a the named entity and its own tag. For exemple, with the sentence \"Japan is a country\" as input, you would answer \"[('Japan', 'GPE')]\". \n",
      "### ASSISTANT : Can you provide me examples ?  \n",
      "### USER : There are examples : \n",
      "### INPUT : <start_input> Jeff Boucher 's piece mentions how victims of sexual abuse often have childlike voices , almost as if their development was ' frozen ' around the time of their abuse . <end_input>\n",
      "### OUTPUT : <start_output> [['Jeff', 'PERSON'], ['Boucher', 'PERSON']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> That is , when the government was handling this kind of public emergency , well , it went from a traditionally unilateral administrative management method , well , a method in which information was quite delayed , to disclosure and transparency of information , and very fast as well . <end_input>\n",
      "### OUTPUT : <start_output> [] <end_output>\n",
      "\n",
      "### INPUT : <start_input> As you watch the children laughing and arguing and playing , you can think back to the time when the Japanese government did not allow Taiwanese and Japanese to attend school together . <end_input>\n",
      "### OUTPUT : <start_output> [['Japanese', 'NORP'], ['Taiwanese', 'NORP'], ['Japanese', 'NORP']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> Rated single - A - 1 by Moody 's Investors Service Inc. and single - A by Standard & Poor 's Corp. , the non-callable issue will be sold through underwriters led by Merrill Lynch Capital Markets . <end_input>\n",
      "### OUTPUT : <start_output> [['1', 'CARDINAL'], [\"Moody 's Investors Service Inc.\", 'ORG'], [\"Standard & Poor 's Corp.\", 'ORG'], ['Merrill Lynch Capital Markets', 'ORG']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> He said that for the more than six years since the establishment of diplomatic relations between China and Uruguay , the friendly co-operative relations between the two countries had continued its steady development . <end_input>\n",
      "### OUTPUT : <start_output> [['the more than six years', 'DATE'], ['China', 'GPE'], ['Uruguay', 'GPE'], ['two', 'CARDINAL']] <end_output>\n",
      "\n",
      "### ASSISTANT : I will extract all the named entities in the text that has one of the 18 tags of the OntoNote5 dataset and output a python list of tuples containing the named entitiy and its own tag. Now provide me the sentence.\n",
      "### INPUT : <start_input> This is because the former two given \" fatherhood \" are indeed the most essential factors of the national character and institution of the socialist new China , while the latter two dubbed \" son \" in this article -- are indeed the ideological outcomes derived after the death of China 's founder Comrade Mao Zedong under tremendous international and domestic political pressures on planned economy and public ownership , which grew into today 's para-system after about 30 years of reform and opening up . <end_input>\n",
      "### OUTPUT : <start_output> [\n",
      "### SYSTEM : The task is to extract named entites in a sentence.\n",
      "    A named entity refers to a specific, named object, concept, location, person, organization, or other entities that have a proper name. Named entities are typically unique and distinguishable entities that can be explicitly named or referred to in text. \n",
      "    The goal of named entity extraction is to identify and classify these entities within a given text.\n",
      "    We are working with 18 types of entities of the OntoNote5 dataset that are listed below with their description :\n",
      "        \"CARDINAL\": \"Numerals that do not fall under another type.\",\n",
      "        \"ORDINAL\": \"Words or expressions indicating order.\",\n",
      "        \"WORK_OF_ART\": \"Titles of creative works.\",\n",
      "        \"PERSON\": \"Names of people, including fictional and real characters.\",\n",
      "        \"LOC\": \"Geographical locations, both physical and political.\",\n",
      "        \"DATE\": \"Temporal expressions indicating dates or periods.\",\n",
      "        \"PERCENT\": \"Percentage values.\",\n",
      "        \"PRODUCT\": \"Names of products or services.\",\n",
      "        \"MONEY\": \"Monetary values, including currency symbols.\",\n",
      "        \"FAC\": \"Named facilities, such as buildings, airports, or highways.\",\n",
      "        \"TIME\": \"Temporal expressions indicating times of the day.\",\n",
      "        \"ORG\": \"Names of organizations, institutions, or companies.\",\n",
      "        \"QUANTITY\": \"Measurements or counts, including units.\",\n",
      "        \"LANGUAGE\": \"Names of languages.\",\n",
      "        \"GPE\": \"Geopolitical entities, such as countries, cities, or states.\",\n",
      "        \"LAW\": \"Legal references, including laws and legal concepts.\",\n",
      "        \"NORP\": \"Nationalities, religious, or political groups.\",\n",
      "        \"EVENT\": \"Named occurrences or incidents.\n",
      "### USER : I want you to extract all the named entities in the text and tag them with one of the tag of the OntoNote5 dataset.\n",
      "### ASSISTANT : What is the format of the output ?\n",
      "### USER : You have to output a python list of tuples. In each tuple, you have a the named entity and its own tag. For exemple, with the sentence \"Japan is a country\" as input, you would answer \"[('Japan', 'GPE')]\". \n",
      "### ASSISTANT : Can you provide me examples ?  \n",
      "### USER : There are examples : \n",
      "### INPUT : <start_input> `` The capability of existing fields to deliver oil is dropping , '' and oil exploration activity is also down dramatically , as many producers shift their emphasis to natural gas , said Ronald Watkins , vice president for government and industry relations with Interprovincial 's parent , Interhome Energy Inc . <end_input>\n",
      "### OUTPUT : <start_output> [['Ronald Watkins', 'PERSON'], ['Interprovincial', 'ORG'], ['Interhome Energy Inc', 'ORG']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> As the politicians argued , Formosa Plastics boss Wang Yung - ching convened a meeting with other captains of industry to come up with some advice for the government on economic policy . <end_input>\n",
      "### OUTPUT : <start_output> [['Formosa Plastics', 'ORG'], ['Wang Yung - ching', 'PERSON']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> Conventional insurance lines such as transportation insurance , property insurance , automobile insurance , etc. are specially offered to foreign funded enterprises such as the Zhengda Company and the Huaxing Aluminum Firm , etc. and new types of insurance such as employer liability insurance , investment insurance , and profit - loss insurance , etc. are also offered at the appropriate time , satisfying the investment needs of foreign businessmen , bringing the insurance rate of the foreign business invested enterprises to more than 90 percent . <end_input>\n",
      "### OUTPUT : <start_output> [['the Zhengda Company', 'ORG'], ['the Huaxing Aluminum Firm', 'ORG'], ['more than 90 percent', 'PERCENT']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> This year , the spirit of National Economy Work Conference should be carried through and implemented , while deepening State - owned enterprise reform and continuing to reinforce restructuring , striving to increase effective demands , improving supply quality , promoting the healthy and steady development of an industrial economy . <end_input>\n",
      "### OUTPUT : <start_output> [['This year', 'DATE'], ['National Economy Work Conference', 'EVENT'], ['State', 'ORG']] <end_output>\n",
      "\n",
      "### INPUT : <start_input> Lovers of Tanshui , while keeping close watch over her , are fearful that the giant beast of development may eventually come and bulldoze Tanshui away one piece of land at a time . <end_input>\n",
      "### OUTPUT : <start_output> [['Tanshui', 'GPE'], ['Tanshui', 'GPE'], ['one', 'CARDINAL']] <end_output>\n",
      "\n",
      "### ASSISTANT : I will extract all the named entities in the text that has one of the 18 tags of the OntoNote5 dataset and output a python list of tuples containing the named entitiy and its own tag. Now provide me the sentence.\n",
      "### INPUT : <start_input> But Dirk Van Dongen , president of the National Association of Wholesaler - Distributors , said that last month 's rise `` is n't as bad an omen '' as the 0.9 % figure suggests . <end_input>\n",
      "### OUTPUT : <start_output> [\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/ketl2/.local/lib/python3.10/site-packages/numpy/core/_methods.py:269: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/ketl2/.local/lib/python3.10/site-packages/numpy/core/_methods.py:261: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_mean</th>\n",
       "      <th>f1_conf_inter</th>\n",
       "      <th>model</th>\n",
       "      <th>noshots</th>\n",
       "      <th>prompt_technique</th>\n",
       "      <th>few_shot_tecnique</th>\n",
       "      <th>nb_few_shots</th>\n",
       "      <th>precision</th>\n",
       "      <th>verifier</th>\n",
       "      <th>len_data_train</th>\n",
       "      <th>len_data_test</th>\n",
       "      <th>nb_test_run</th>\n",
       "      <th>confidence_interval</th>\n",
       "      <th>distribution_used</th>\n",
       "      <th>precision_mean</th>\n",
       "      <th>precision_conf_inter</th>\n",
       "      <th>recall_mean</th>\n",
       "      <th>recall_conf_inter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>(nan, nan)</td>\n",
       "      <td>none</td>\n",
       "      <td>False</td>\n",
       "      <td>discussion</td>\n",
       "      <td>random</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>1353</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>Student</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(nan, nan)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(nan, nan)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f1_mean f1_conf_inter model  noshots prompt_technique few_shot_tecnique  \\\n",
       "0      0.0    (nan, nan)  none    False       discussion            random   \n",
       "\n",
       "   nb_few_shots  precision verifier  len_data_train  len_data_test  \\\n",
       "0             5      False     None            1353             50   \n",
       "\n",
       "   nb_test_run  confidence_interval distribution_used  precision_mean  \\\n",
       "0            1                 0.95           Student             0.0   \n",
       "\n",
       "  precision_conf_inter  recall_mean recall_conf_inter  \n",
       "0           (nan, nan)          0.0        (nan, nan)  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ToDo \n",
    "from llm.LLMModel import *\n",
    "from ner.llm_ner.prompt_techniques.pt_abstract import PromptTechnique\n",
    "from ner.llm_ner.prompt_techniques.pt_discussion import PT_OutputList\n",
    "from ner.llm_ner.prompt_techniques.pt_gpt_ner import PT_GPT_NER\n",
    "from ner.llm_ner.prompt_techniques.pt_wrapper import PT_Wrapper\n",
    "from ner.llm_ner.few_shots_techniques import *\n",
    "from ner.llm_ner.prompts import *\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "model = NoLLM()\n",
    "\n",
    "results, results_df = model.classical_test_ontonote5(pts = [PT_OutputList], fsts = [FST_Random], nb_run_by_test=1, plus_plus= True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'OntoNote5Dataset' has no attribute 'get_test_cleaned_split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_693607/329038519.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOntoNotes5Dataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOntoNote5Dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mOntoNote5Dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_test_cleaned_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'OntoNote5Dataset' has no attribute 'get_test_cleaned_split'"
     ]
    }
   ],
   "source": [
    "from ner.Datasets.OntoNotes5Dataset import OntoNote5Dataset\n",
    "OntoNote5Dataset.get_test_cleaned_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'### ASSISTANT : Can you give me clarification on the different type of entities ? \\n### USER : Yes. Person entities are all the names you can find in the text. That can be celebrities, historical figures, fictional characters or just names but not pronouns like \"he\" or \"she\".\\nOrganization entities all the organizations you can find in the text. That can be business, educational organisation, broadcaster, sports organisation, scientific organisation, political organisation, institute or government agency.\\nLocation entities are all countries, the human-geographic territorials, geographical regions, areas in a single country or natural geographic objects.\\nMiscellaneous entities are all events, languages, adjectives to describe things particular to a country. It cannot be verbs, numbers or time related word like weekdays and months. \\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"### ASSISTANT : Can you give me clarification on the different type of entities ? \n",
    "### USER : Yes. \"\"\"+'\\n'.join([val for key, val in precision_ner.items()])+'\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "[nltk_data] Downloading package punkt to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "ggml_init_cublas: found 1 CUDA devices:\n",
      "  Device 0: NVIDIA A40, compute capability 8.6\n",
      "llama_model_loader: loaded meta data with 20 key-value pairs and 291 tensors from llm/models/mistral-7b-v0.1/mistral-7b-v0.1.Q5_0.gguf (version GGUF V2 (latest))\n",
      "llama_model_loader: - tensor    0:                token_embd.weight q5_0     [  4096, 32000,     1,     1 ]\n",
      "llama_model_loader: - tensor    1:              blk.0.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor    2:              blk.0.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor    3:              blk.0.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor    4:         blk.0.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor    5:            blk.0.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor    6:              blk.0.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor    7:            blk.0.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor    8:           blk.0.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor    9:            blk.0.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   10:              blk.1.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   11:              blk.1.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   12:              blk.1.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   13:         blk.1.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   14:            blk.1.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   15:              blk.1.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   16:            blk.1.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   17:           blk.1.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   18:            blk.1.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   19:              blk.2.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   20:              blk.2.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   21:              blk.2.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   22:         blk.2.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   23:            blk.2.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   24:              blk.2.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   25:            blk.2.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   26:           blk.2.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   27:            blk.2.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   28:              blk.3.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   29:              blk.3.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   30:              blk.3.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   31:         blk.3.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   32:            blk.3.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   33:              blk.3.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   34:            blk.3.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   35:           blk.3.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   36:            blk.3.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   37:              blk.4.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   38:              blk.4.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   39:              blk.4.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   40:         blk.4.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   41:            blk.4.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   42:              blk.4.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   43:            blk.4.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   44:           blk.4.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   45:            blk.4.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   46:              blk.5.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   47:              blk.5.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   48:              blk.5.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   49:         blk.5.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   50:            blk.5.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   51:              blk.5.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   52:            blk.5.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   53:           blk.5.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   54:            blk.5.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   55:              blk.6.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   56:              blk.6.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   57:              blk.6.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   58:         blk.6.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   59:            blk.6.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   60:              blk.6.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   61:            blk.6.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   62:           blk.6.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   63:            blk.6.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   64:              blk.7.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   65:              blk.7.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   66:              blk.7.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   67:         blk.7.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   68:            blk.7.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   69:              blk.7.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   70:            blk.7.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   71:           blk.7.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   72:            blk.7.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   73:              blk.8.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   74:              blk.8.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   75:              blk.8.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   76:         blk.8.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   77:            blk.8.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   78:              blk.8.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   79:            blk.8.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   80:           blk.8.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   81:            blk.8.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   82:              blk.9.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   83:              blk.9.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   84:              blk.9.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   85:         blk.9.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   86:            blk.9.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   87:              blk.9.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   88:            blk.9.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   89:           blk.9.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   90:            blk.9.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   91:             blk.10.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   92:             blk.10.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   93:             blk.10.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   94:        blk.10.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   95:           blk.10.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   96:             blk.10.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   97:           blk.10.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   98:          blk.10.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   99:           blk.10.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  100:             blk.11.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  101:             blk.11.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  102:             blk.11.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  103:        blk.11.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  104:           blk.11.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  105:             blk.11.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  106:           blk.11.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  107:          blk.11.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  108:           blk.11.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  109:             blk.12.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  110:             blk.12.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  111:             blk.12.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  112:        blk.12.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  113:           blk.12.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  114:             blk.12.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  115:           blk.12.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  116:          blk.12.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  117:           blk.12.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  118:             blk.13.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  119:             blk.13.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  120:             blk.13.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  121:        blk.13.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  122:           blk.13.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  123:             blk.13.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  124:           blk.13.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  125:          blk.13.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  126:           blk.13.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  127:             blk.14.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  128:             blk.14.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  129:             blk.14.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  130:        blk.14.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  131:           blk.14.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  132:             blk.14.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  133:           blk.14.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  134:          blk.14.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  135:           blk.14.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  136:             blk.15.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  137:             blk.15.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  138:             blk.15.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  139:        blk.15.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  140:           blk.15.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  141:             blk.15.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  142:           blk.15.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  143:          blk.15.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  144:           blk.15.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  145:             blk.16.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  146:             blk.16.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  147:             blk.16.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  148:        blk.16.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  149:           blk.16.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  150:             blk.16.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  151:           blk.16.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  152:          blk.16.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  153:           blk.16.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  154:             blk.17.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  155:             blk.17.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  156:             blk.17.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  157:        blk.17.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  158:           blk.17.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  159:             blk.17.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  160:           blk.17.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  161:          blk.17.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  162:           blk.17.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  163:             blk.18.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  164:             blk.18.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  165:             blk.18.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  166:        blk.18.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  167:           blk.18.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  168:             blk.18.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  169:           blk.18.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  170:          blk.18.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  171:           blk.18.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  172:             blk.19.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  173:             blk.19.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  174:             blk.19.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  175:        blk.19.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  176:           blk.19.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  177:             blk.19.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  178:           blk.19.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  179:          blk.19.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  180:           blk.19.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  181:             blk.20.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  182:             blk.20.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  183:             blk.20.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  184:        blk.20.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  185:           blk.20.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  186:             blk.20.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  187:           blk.20.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  188:          blk.20.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  189:           blk.20.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  190:             blk.21.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  191:             blk.21.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  192:             blk.21.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  193:        blk.21.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  194:           blk.21.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  195:             blk.21.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  196:           blk.21.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  197:          blk.21.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  198:           blk.21.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  199:             blk.22.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  200:             blk.22.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  201:             blk.22.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  202:        blk.22.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  203:           blk.22.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  204:             blk.22.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  205:           blk.22.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  206:          blk.22.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  207:           blk.22.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  208:             blk.23.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  209:             blk.23.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  210:             blk.23.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  211:        blk.23.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  212:           blk.23.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  213:             blk.23.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  214:           blk.23.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  215:          blk.23.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  216:           blk.23.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  217:             blk.24.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  218:             blk.24.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  219:             blk.24.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  220:        blk.24.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  221:           blk.24.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  222:             blk.24.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  223:           blk.24.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  224:          blk.24.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  225:           blk.24.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  226:             blk.25.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  227:             blk.25.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  228:             blk.25.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  229:        blk.25.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  230:           blk.25.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  231:             blk.25.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  232:           blk.25.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  233:          blk.25.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  234:           blk.25.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  235:             blk.26.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  236:             blk.26.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  237:             blk.26.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  238:        blk.26.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  239:           blk.26.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  240:             blk.26.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  241:           blk.26.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  242:          blk.26.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  243:           blk.26.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  244:             blk.27.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  245:             blk.27.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  246:             blk.27.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  247:        blk.27.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  248:           blk.27.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  249:             blk.27.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  250:           blk.27.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  251:          blk.27.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  252:           blk.27.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  253:             blk.28.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  254:             blk.28.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  255:             blk.28.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  256:        blk.28.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  257:           blk.28.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  258:             blk.28.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  259:           blk.28.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  260:          blk.28.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  261:           blk.28.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  262:             blk.29.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  263:             blk.29.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  264:             blk.29.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  265:        blk.29.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  266:           blk.29.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  267:             blk.29.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  268:           blk.29.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  269:          blk.29.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  270:           blk.29.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  271:             blk.30.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  272:             blk.30.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  273:             blk.30.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  274:        blk.30.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  275:           blk.30.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  276:             blk.30.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  277:           blk.30.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  278:          blk.30.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  279:           blk.30.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  280:             blk.31.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  281:             blk.31.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  282:             blk.31.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  283:        blk.31.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  284:           blk.31.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  285:             blk.31.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  286:           blk.31.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  287:          blk.31.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  288:           blk.31.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  289:               output_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  290:                    output.weight q6_K     [  4096, 32000,     1,     1 ]\n",
      "llama_model_loader: - kv   0:                       general.architecture str     \n",
      "llama_model_loader: - kv   1:                               general.name str     \n",
      "llama_model_loader: - kv   2:                       llama.context_length u32     \n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32     \n",
      "llama_model_loader: - kv   4:                          llama.block_count u32     \n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32     \n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32     \n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32     \n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32     \n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32     \n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32     \n",
      "llama_model_loader: - kv  11:                          general.file_type u32     \n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str     \n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr     \n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr     \n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr     \n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32     \n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32     \n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32     \n",
      "llama_model_loader: - kv  19:               general.quantization_version u32     \n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q5_0:  225 tensors\n",
      "llama_model_loader: - type q6_K:    1 tensors\n",
      "llm_load_print_meta: format         = GGUF V2 (latest)\n",
      "llm_load_print_meta: arch           = llama\n",
      "llm_load_print_meta: vocab type     = SPM\n",
      "llm_load_print_meta: n_vocab        = 32000\n",
      "llm_load_print_meta: n_merges       = 0\n",
      "llm_load_print_meta: n_ctx_train    = 32768\n",
      "llm_load_print_meta: n_ctx          = 2048\n",
      "llm_load_print_meta: n_embd         = 4096\n",
      "llm_load_print_meta: n_head         = 32\n",
      "llm_load_print_meta: n_head_kv      = 8\n",
      "llm_load_print_meta: n_layer        = 32\n",
      "llm_load_print_meta: n_rot          = 128\n",
      "llm_load_print_meta: n_gqa          = 4\n",
      "llm_load_print_meta: f_norm_eps     = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps = 1.0e-05\n",
      "llm_load_print_meta: n_ff           = 14336\n",
      "llm_load_print_meta: freq_base      = 10000.0\n",
      "llm_load_print_meta: freq_scale     = 1\n",
      "llm_load_print_meta: model type     = 7B\n",
      "llm_load_print_meta: model ftype    = mostly Q5_0\n",
      "llm_load_print_meta: model params   = 7.24 B\n",
      "llm_load_print_meta: model size     = 4.65 GiB (5.52 BPW) \n",
      "llm_load_print_meta: general.name   = mistralai_mistral-7b-v0.1\n",
      "llm_load_print_meta: BOS token = 1 '<s>'\n",
      "llm_load_print_meta: EOS token = 2 '</s>'\n",
      "llm_load_print_meta: UNK token = 0 '<unk>'\n",
      "llm_load_print_meta: LF token  = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.09 MB\n",
      "llm_load_tensors: using CUDA for GPU acceleration\n",
      "llm_load_tensors: mem required  =   86.03 MB (+  256.00 MB per state)\n",
      "llm_load_tensors: offloading 32 repeating layers to GPU\n",
      "llm_load_tensors: offloading non-repeating layers to GPU\n",
      "llm_load_tensors: offloading v cache to GPU\n",
      "llm_load_tensors: offloading k cache to GPU\n",
      "llm_load_tensors: offloaded 35/35 layers to GPU\n",
      "llm_load_tensors: VRAM used: 4936 MB\n",
      "..................................................................................................\n",
      "llama_new_context_with_model: kv self size  =  256.00 MB\n",
      "llama_new_context_with_model: compute buffer total size =  153.47 MB\n",
      "llama_new_context_with_model: VRAM scratch buffer: 152.00 MB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./llm/models/mistral-7b-v0.1/finetuned-discussion-10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 20 key-value pairs and 291 tensors from ./llm/models/mistral-7b-v0.1/finetuned-discussion-10000/model-Q5_0.gguf (version unknown)\n",
      "llama_model_loader: - tensor    0:                token_embd.weight q5_0     [  4096, 32000,     1,     1 ]\n",
      "llama_model_loader: - tensor    1:              blk.0.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor    2:              blk.0.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor    3:              blk.0.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor    4:         blk.0.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor    5:            blk.0.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor    6:              blk.0.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor    7:            blk.0.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor    8:           blk.0.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor    9:            blk.0.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   10:              blk.1.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   11:              blk.1.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   12:              blk.1.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   13:         blk.1.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   14:            blk.1.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   15:              blk.1.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   16:            blk.1.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   17:           blk.1.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   18:            blk.1.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   19:              blk.2.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   20:              blk.2.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   21:              blk.2.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   22:         blk.2.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   23:            blk.2.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   24:              blk.2.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   25:            blk.2.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   26:           blk.2.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   27:            blk.2.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   28:              blk.3.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   29:              blk.3.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   30:              blk.3.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   31:         blk.3.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   32:            blk.3.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   33:              blk.3.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   34:            blk.3.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   35:           blk.3.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   36:            blk.3.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   37:              blk.4.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   38:              blk.4.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   39:              blk.4.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   40:         blk.4.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   41:            blk.4.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   42:              blk.4.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   43:            blk.4.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   44:           blk.4.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   45:            blk.4.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   46:              blk.5.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   47:              blk.5.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   48:              blk.5.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   49:         blk.5.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   50:            blk.5.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   51:              blk.5.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   52:            blk.5.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   53:           blk.5.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   54:            blk.5.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   55:              blk.6.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   56:              blk.6.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   57:              blk.6.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   58:         blk.6.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   59:            blk.6.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   60:              blk.6.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   61:            blk.6.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   62:           blk.6.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   63:            blk.6.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   64:              blk.7.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   65:              blk.7.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   66:              blk.7.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   67:         blk.7.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   68:            blk.7.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   69:              blk.7.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   70:            blk.7.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   71:           blk.7.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   72:            blk.7.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   73:              blk.8.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   74:              blk.8.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   75:              blk.8.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   76:         blk.8.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   77:            blk.8.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   78:              blk.8.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   79:            blk.8.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   80:           blk.8.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   81:            blk.8.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   82:              blk.9.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   83:              blk.9.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   84:              blk.9.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   85:         blk.9.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   86:            blk.9.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   87:              blk.9.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   88:            blk.9.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   89:           blk.9.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   90:            blk.9.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   91:             blk.10.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   92:             blk.10.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   93:             blk.10.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   94:        blk.10.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   95:           blk.10.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   96:             blk.10.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   97:           blk.10.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   98:          blk.10.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   99:           blk.10.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  100:             blk.11.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  101:             blk.11.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  102:             blk.11.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  103:        blk.11.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  104:           blk.11.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  105:             blk.11.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  106:           blk.11.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  107:          blk.11.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  108:           blk.11.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  109:             blk.12.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  110:             blk.12.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  111:             blk.12.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  112:        blk.12.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  113:           blk.12.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  114:             blk.12.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  115:           blk.12.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  116:          blk.12.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  117:           blk.12.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  118:             blk.13.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  119:             blk.13.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  120:             blk.13.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  121:        blk.13.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  122:           blk.13.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  123:             blk.13.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  124:           blk.13.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  125:          blk.13.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  126:           blk.13.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  127:             blk.14.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  128:             blk.14.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  129:             blk.14.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  130:        blk.14.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  131:           blk.14.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  132:             blk.14.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  133:           blk.14.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  134:          blk.14.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  135:           blk.14.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  136:             blk.15.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  137:             blk.15.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  138:             blk.15.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  139:        blk.15.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  140:           blk.15.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  141:             blk.15.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  142:           blk.15.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  143:          blk.15.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  144:           blk.15.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  145:             blk.16.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  146:             blk.16.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  147:             blk.16.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  148:        blk.16.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  149:           blk.16.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  150:             blk.16.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  151:           blk.16.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  152:          blk.16.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  153:           blk.16.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  154:             blk.17.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  155:             blk.17.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  156:             blk.17.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  157:        blk.17.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  158:           blk.17.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  159:             blk.17.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  160:           blk.17.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  161:          blk.17.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  162:           blk.17.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  163:             blk.18.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  164:             blk.18.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  165:             blk.18.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  166:        blk.18.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  167:           blk.18.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  168:             blk.18.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  169:           blk.18.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  170:          blk.18.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  171:           blk.18.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  172:             blk.19.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  173:             blk.19.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  174:             blk.19.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  175:        blk.19.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  176:           blk.19.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  177:             blk.19.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  178:           blk.19.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  179:          blk.19.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  180:           blk.19.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  181:             blk.20.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  182:             blk.20.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  183:             blk.20.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  184:        blk.20.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  185:           blk.20.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  186:             blk.20.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  187:           blk.20.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  188:          blk.20.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  189:           blk.20.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  190:             blk.21.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  191:             blk.21.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  192:             blk.21.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  193:        blk.21.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  194:           blk.21.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  195:             blk.21.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  196:           blk.21.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  197:          blk.21.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  198:           blk.21.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  199:             blk.22.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  200:             blk.22.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  201:             blk.22.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  202:        blk.22.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  203:           blk.22.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  204:             blk.22.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  205:           blk.22.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  206:          blk.22.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  207:           blk.22.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  208:             blk.23.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  209:             blk.23.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  210:             blk.23.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  211:        blk.23.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  212:           blk.23.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  213:             blk.23.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  214:           blk.23.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  215:          blk.23.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  216:           blk.23.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  217:             blk.24.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  218:             blk.24.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  219:             blk.24.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  220:        blk.24.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  221:           blk.24.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  222:             blk.24.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  223:           blk.24.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  224:          blk.24.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  225:           blk.24.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  226:             blk.25.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  227:             blk.25.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  228:             blk.25.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  229:        blk.25.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  230:           blk.25.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  231:             blk.25.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  232:           blk.25.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  233:          blk.25.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  234:           blk.25.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  235:             blk.26.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  236:             blk.26.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  237:             blk.26.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  238:        blk.26.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  239:           blk.26.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  240:             blk.26.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  241:           blk.26.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  242:          blk.26.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  243:           blk.26.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  244:             blk.27.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  245:             blk.27.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  246:             blk.27.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  247:        blk.27.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  248:           blk.27.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  249:             blk.27.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  250:           blk.27.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  251:          blk.27.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  252:           blk.27.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  253:             blk.28.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  254:             blk.28.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  255:             blk.28.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  256:        blk.28.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  257:           blk.28.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  258:             blk.28.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  259:           blk.28.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  260:          blk.28.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  261:           blk.28.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  262:             blk.29.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  263:             blk.29.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  264:             blk.29.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  265:        blk.29.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  266:           blk.29.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  267:             blk.29.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  268:           blk.29.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  269:          blk.29.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  270:           blk.29.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  271:             blk.30.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  272:             blk.30.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  273:             blk.30.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  274:        blk.30.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  275:           blk.30.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  276:             blk.30.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  277:           blk.30.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  278:          blk.30.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  279:           blk.30.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  280:             blk.31.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  281:             blk.31.attn_k.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  282:             blk.31.attn_v.weight q5_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  283:        blk.31.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  284:           blk.31.ffn_gate.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  285:             blk.31.ffn_up.weight q5_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  286:           blk.31.ffn_down.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  287:          blk.31.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  288:           blk.31.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  289:               output_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  290:                    output.weight q6_K     [  4096, 32000,     1,     1 ]\n",
      "llama_model_loader: - kv   0:                       general.architecture str     \n",
      "llama_model_loader: - kv   1:                               general.name str     \n",
      "llama_model_loader: - kv   2:                       llama.context_length u32     \n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32     \n",
      "llama_model_loader: - kv   4:                          llama.block_count u32     \n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32     \n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32     \n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32     \n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32     \n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32     \n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32     \n",
      "llama_model_loader: - kv  11:                          general.file_type u32     \n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str     \n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr     \n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr     \n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr     \n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32     \n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32     \n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32     \n",
      "llama_model_loader: - kv  19:               general.quantization_version u32     \n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q5_0:  225 tensors\n",
      "llama_model_loader: - type q6_K:    1 tensors\n",
      "llm_load_print_meta: format         = unknown\n",
      "llm_load_print_meta: arch           = llama\n",
      "llm_load_print_meta: vocab type     = SPM\n",
      "llm_load_print_meta: n_vocab        = 32000\n",
      "llm_load_print_meta: n_merges       = 0\n",
      "llm_load_print_meta: n_ctx_train    = 32768\n",
      "llm_load_print_meta: n_ctx          = 2048\n",
      "llm_load_print_meta: n_embd         = 4096\n",
      "llm_load_print_meta: n_head         = 32\n",
      "llm_load_print_meta: n_head_kv      = 8\n",
      "llm_load_print_meta: n_layer        = 32\n",
      "llm_load_print_meta: n_rot          = 128\n",
      "llm_load_print_meta: n_gqa          = 4\n",
      "llm_load_print_meta: f_norm_eps     = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps = 1.0e-05\n",
      "llm_load_print_meta: n_ff           = 14336\n",
      "llm_load_print_meta: freq_base      = 10000.0\n",
      "llm_load_print_meta: freq_scale     = 1\n",
      "llm_load_print_meta: model type     = 7B\n",
      "llm_load_print_meta: model ftype    = mostly Q5_0\n",
      "llm_load_print_meta: model params   = 7.24 B\n",
      "llm_load_print_meta: model size     = 4.65 GiB (5.52 BPW) \n",
      "llm_load_print_meta: general.name   = mistralai_mistral-7b-v0.1\n",
      "llm_load_print_meta: BOS token = 1 '<s>'\n",
      "llm_load_print_meta: EOS token = 2 '</s>'\n",
      "llm_load_print_meta: UNK token = 0 '<unk>'\n",
      "llm_load_print_meta: LF token  = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.09 MB\n",
      "llm_load_tensors: using CUDA for GPU acceleration\n",
      "llm_load_tensors: mem required  =   86.03 MB (+  256.00 MB per state)\n",
      "llm_load_tensors: offloading 32 repeating layers to GPU\n",
      "llm_load_tensors: offloading non-repeating layers to GPU\n",
      "llm_load_tensors: offloading v cache to GPU\n",
      "llm_load_tensors: offloading k cache to GPU\n",
      "llm_load_tensors: offloaded 35/35 layers to GPU\n",
      "llm_load_tensors: VRAM used: 4936 MB\n",
      "..................................................................................................\n",
      "llama_new_context_with_model: kv self size  =  256.00 MB\n",
      "llama_new_context_with_model: compute buffer total size =  153.47 MB\n",
      "llama_new_context_with_model: VRAM scratch buffer: 152.00 MB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with entity\n",
      "      and discussion\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a93e6a51debe412181d63e7dad797b1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1538 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25cd5dd2f9b0461d9b66266039877e48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 - Robbie Earle ( Wimbledon ) , Les Ferdinand ( Newcastle ) "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|‚ñè         | 1/50 [00:09<07:25,  9.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned 7 - Robbie Earle ( Wimbledon ) , Les Ferdinand ( Newcastle ) \n",
      "-----------------------------------------------\n",
      " [['Czech Republic', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|‚ñç         | 2/50 [00:21<09:03, 11.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['China', 'LOC'], ['Guilin', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|‚ñå         | 3/50 [00:29<07:20,  9.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Santa Fe', 'ORG'], ['Newmont', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|‚ñä         | 4/50 [00:39<07:28,  9.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['DOT', 'ORG'], ['Reuters', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|‚ñà         | 5/50 [00:49<07:26,  9.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Havel', 'PER']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|‚ñà‚ñè        | 6/50 [01:00<07:27, 10.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['PSV', 'ORG'], ['Volendam', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|‚ñà‚ñç        | 7/50 [01:12<07:41, 10.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Democratic Left Alliance', 'ORG'], ['Catholic Church', 'ORG'], ['Poland', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|‚ñà‚ñå        | 8/50 [01:23<07:44, 11.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Italy', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|‚ñà‚ñä        | 9/50 [01:35<07:38, 11.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Real Madrid', 'ORG'], ['Barcelona', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|‚ñà‚ñà        | 10/50 [01:41<06:23,  9.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Woolmer', 'PER'], ['Kanpur', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|‚ñà‚ñà‚ñè       | 11/50 [01:50<06:10,  9.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['FIFA', 'ORG'], ['Liberian', 'MISC'], ['Fair Play', 'MISC'], ['Havelange', 'PER']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|‚ñà‚ñà‚ñç       | 12/50 [02:02<06:32, 10.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Radical Democrats', 'ORG'], ['FDP', 'ORG'], ['Swiss', 'MISC'], ['Swiss', 'MISC'], ['Jewish', 'MISC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|‚ñà‚ñà‚ñå       | 13/50 [02:21<07:52, 12.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.7 million shares traded . "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|‚ñà‚ñà‚ñä       | 14/50 [02:29<06:50, 11.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned 74.7 million shares traded . \n",
      "-----------------------------------------------\n",
      " [['Canadian', 'MISC'], ['Zaire', 'LOC'], ['Zaire', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|‚ñà‚ñà‚ñà       | 15/50 [02:44<07:12, 12.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['U.S.', 'LOC'], ['NYMEX', 'ORG'], ['ACCESS', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|‚ñà‚ñà‚ñà‚ñè      | 16/50 [02:58<07:15, 12.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10. Cuo Dan ( China ) 1:51.989 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|‚ñà‚ñà‚ñà‚ñç      | 17/50 [03:11<07:10, 13.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned 10. Cuo Dan ( China ) 1:51.989 \n",
      "-----------------------------------------------\n",
      " [['Reuters', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|‚ñà‚ñà‚ñà‚ñå      | 18/50 [03:21<06:31, 12.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Net', 'MISC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|‚ñà‚ñà‚ñà‚ñä      | 19/50 [03:28<05:28, 10.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 20/50 [03:36<04:49,  9.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned  [] \n",
      "-----------------------------------------------\n",
      " [['Japan', 'LOC'], ['Asian Cup', 'MISC'], ['Group C', 'MISC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 21/50 [03:48<05:03, 10.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Action Performance', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 22/50 [03:54<04:18,  9.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['World Series', 'MISC'], ['West Indies', 'LOC'], ['Australia', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/50 [04:07<04:34, 10.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 24/50 [04:13<03:51,  8.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned  [] \n",
      "-----------------------------------------------\n",
      " [['Jewish', 'MISC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 25/50 [04:21<03:40,  8.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Bre-X', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 26/50 [04:30<03:29,  8.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['KUUSAMO', 'LOC'], ['Finland', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 27/50 [04:36<03:05,  8.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 28/50 [04:43<02:46,  7.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned  [] \n",
      "-----------------------------------------------\n",
      "15 years ago . "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 29/50 [04:53<02:58,  8.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned 15 years ago . \n",
      "-----------------------------------------------\n",
      " [] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 30/50 [05:03<02:57,  8.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned  [] \n",
      "-----------------------------------------------\n",
      "70 , Brett Liddle 75 65 , Hugh Baiocchi 73 67 141 Adilson da Silva', 'PER'], ['Brazil', 'LOC'], ['Sammy Daniels', 'PER']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 31/50 [05:17<03:17, 10.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned 70 , Brett Liddle 75 65 , Hugh Baiocchi 73 67 141 Adilson da Silva', 'PER'], ['Brazil', 'LOC'], ['Sammy Daniels', 'PER']] \n",
      "-----------------------------------------------\n",
      " [['World Cup', 'MISC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 32/50 [05:27<03:05, 10.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['U.S.', 'LOC'], ['Italian', 'MISC'], ['Elf', 'ORG'], ['Med', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 33/50 [05:41<03:11, 11.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16,000 francs were seized from accounts of four or five Polish citizens , whose data we do not precisely know . "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 34/50 [05:53<03:07, 11.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned 16,000 francs were seized from accounts of four or five Polish citizens , whose data we do not precisely know . \n",
      "-----------------------------------------------\n",
      " [['Ireland', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 35/50 [06:04<02:52, 11.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 36/50 [06:13<02:29, 10.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned  [] \n",
      "-----------------------------------------------\n",
      " [['Toronto', 'LOC'], ['Jakarta', 'LOC'], ['Reuters', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 37/50 [06:25<02:23, 11.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.625 15.725 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 38/50 [06:33<02:00, 10.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned 15.625 15.725 \n",
      "-----------------------------------------------\n",
      " [['New York', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 39/50 [06:41<01:44,  9.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Russia', 'LOC'], ['Norilsk', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 40/50 [06:49<01:31,  9.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Piniel Sindiso Ncube', 'PER']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 41/50 [06:59<01:24,  9.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['ILO', 'ORG'], ['WTO', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 42/50 [07:12<01:23, 10.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 43/50 [07:22<01:12, 10.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned  [] \n",
      "-----------------------------------------------\n",
      "16,000 francs "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 44/50 [07:34<01:03, 10.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned 16,000 francs \n",
      "-----------------------------------------------\n",
      " [['Singapore', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 45/50 [07:44<00:53, 10.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 46/50 [07:53<00:40, 10.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned  [] \n",
      "-----------------------------------------------\n",
      " [['Pakistan', 'LOC'], ['New Zealand', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 47/50 [08:06<00:32, 10.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['I. Healy', 'PER'], ['P. Reiffel', 'PER'], ['S. Warne', 'PER'], ['J. Gillespie', 'PER']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 48/50 [08:18<00:22, 11.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Santa Fe', 'ORG'], ['Newmont', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 49/50 [08:31<00:11, 11.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1994 Lillehammer Winter Olympics', ['Gladishiva', 'PER']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [08:43<00:00, 10.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned 1994 Lillehammer Winter Olympics', ['Gladishiva', 'PER']] \n",
      "-----------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3378b0c710b549459935fea3e94a5b9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1538 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7340336db2ac4ebb9270ac5b2c5419af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Democratic Convention', 'ORG'], ['Social Democratic Union', 'ORG'], ['Hungarian Democratic Union', 'ORG'], ['UDMR', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|‚ñè         | 1/50 [00:12<10:19, 12.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|‚ñç         | 2/50 [00:20<07:47,  9.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned  [] \n",
      "-----------------------------------------------\n",
      " [['U.N.', 'ORG'], ['Central African Republic', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|‚ñå         | 3/50 [00:29<07:34,  9.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['FIFA', 'ORG'], ['Liberian', 'MISC'], ['Havelange', 'PER']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|‚ñä         | 4/50 [00:43<08:28, 11.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Polish', 'MISC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|‚ñà         | 5/50 [00:53<08:08, 10.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Campo', 'PER'], ['Andrew', 'PER'], ['Twickenham', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|‚ñà‚ñè        | 6/50 [01:06<08:21, 11.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Sakakibara', 'PER'], ['International Finance Bureau', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|‚ñà‚ñç        | 7/50 [01:24<09:47, 13.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Yangon', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|‚ñà‚ñå        | 8/50 [01:35<09:03, 12.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|‚ñà‚ñä        | 9/50 [01:42<07:35, 11.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned  [] \n",
      "-----------------------------------------------\n",
      " [['J. Vaughan', 'PER'], ['Moin Khan', 'PER'], ['Wasim', 'PER']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|‚ñà‚ñà        | 10/50 [01:51<06:55, 10.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Charleroi', 'ORG'], ['Eric Cleymans', 'PER'], ['Ron Ellis', 'PER'], ['Jacques Stas', 'PER']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|‚ñà‚ñà‚ñè       | 11/50 [02:04<07:16, 11.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Gorst', 'PER']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|‚ñà‚ñà‚ñç       | 12/50 [02:13<06:39, 10.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['CZECH', 'MISC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|‚ñà‚ñà‚ñå       | 13/50 [02:21<05:58,  9.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Italian', 'MISC'], ['Feyenoord', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|‚ñà‚ñà‚ñä       | 14/50 [02:33<06:11, 10.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Sale Grammar School', 'ORG'], ['England', 'LOC'], ['Manchester', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|‚ñà‚ñà‚ñà       | 15/50 [02:45<06:18, 10.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Britain', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|‚ñà‚ñà‚ñà‚ñè      | 16/50 [02:53<05:40, 10.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Clinton', 'PER'], ['Boris Yeltsin', 'PER']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|‚ñà‚ñà‚ñà‚ñç      | 17/50 [03:01<05:13,  9.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Czech', 'MISC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|‚ñà‚ñà‚ñà‚ñå      | 18/50 [03:12<05:15,  9.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Steers', 'MISC'], ['USDA', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|‚ñà‚ñà‚ñà‚ñä      | 19/50 [03:24<05:25, 10.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['JAPAN', 'LOC'], ['CHINA', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 20/50 [03:36<05:27, 10.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['West Indies', 'LOC'], ['Courtney Walsh', 'PER'], ['Australia', 'LOC'], ['Melbourne Cricket Ground', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 21/50 [03:48<05:31, 11.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['St Louis', 'ORG'], ['COLORADO', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 22/50 [03:58<05:05, 10.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Singapore', 'LOC'], ['Singaporean', 'MISC'], ['Tan', 'PER']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/50 [04:12<05:22, 11.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Thai Commerce Ministry', 'ORG'], ['Thai', 'MISC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 24/50 [04:23<05:00, 11.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Emil Constantinescu', 'PER']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 25/50 [04:31<04:19, 10.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 - Andreas Thom ( Celtic ) , Dean Windass ( Aberdeen ) , "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 26/50 [04:38<03:50,  9.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned 6 - Andreas Thom ( Celtic ) , Dean Windass ( Aberdeen ) , \n",
      "-----------------------------------------------\n",
      " [['Efan Ekoku', 'PER'], ['Dean Holdsworth', 'PER'], ['Wimbledon', 'ORG'], ['Arsenal', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 27/50 [04:52<04:05, 10.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 28/50 [05:01<03:47, 10.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned  [] \n",
      "-----------------------------------------------\n",
      " [['Brazilians', 'MISC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 29/50 [05:15<04:01, 11.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 30/50 [05:25<03:36, 10.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned  [] \n",
      "-----------------------------------------------\n",
      "1996 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 31/50 [05:34<03:17, 10.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned 1996 \n",
      "-----------------------------------------------\n",
      " [['C. Cairns', 'PER'], ['Saqlain', 'PER']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 32/50 [05:43<02:59,  9.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['ICFTU', 'ORG'], ['WTO', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 33/50 [05:56<03:04, 10.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['NTT', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 34/50 [06:07<02:54, 10.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 35/50 [06:15<02:31, 10.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned  [] \n",
      "-----------------------------------------------\n",
      " [['BJP', 'ORG'], ['India', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 36/50 [06:26<02:26, 10.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['West Indies', 'LOC'], ['Courtney Walsh', 'PER'], ['Melbourne Cricket Ground', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 37/50 [06:39<02:24, 11.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.80 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 38/50 [06:47<02:00, 10.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned 3.80 \n",
      "-----------------------------------------------\n",
      "475 million tax-exempt offering . "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 39/50 [06:56<01:47,  9.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned 475 million tax-exempt offering . \n",
      "-----------------------------------------------\n",
      "9.54 dn 0.05 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 40/50 [07:08<01:45, 10.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned 9.54 dn 0.05 \n",
      "-----------------------------------------------\n",
      " [['Singapore', 'LOC'], ['Tan Kong Yam', 'PER'], ['National University of Singapore', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 41/50 [07:26<01:54, 12.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Downing Street', 'LOC'], ['Major', 'PER']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 42/50 [07:34<01:31, 11.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Bill Brett', 'PER'], ['ILO Workers Group', 'ORG'], ['Reuters', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 43/50 [07:48<01:25, 12.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Rashid', 'PER'], ['Greece', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 44/50 [07:58<01:09, 11.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Cito', 'PER'], ['Stephen Cito', 'PER']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 45/50 [08:17<01:07, 13.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Fiorentina', 'ORG'], ['Daniele Carnasciali', 'PER'], ['Lorenzo Amoruso', 'PER'], ['Emiliano Bigica', 'PER'], ['Perugia', 'ORG'], ['Milan Rapajic', 'PER'], ['Fausto Pizzi', 'PER']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 46/50 [08:45<01:11, 17.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "855.8 million kroons , 295.1 million kroons "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 47/50 [08:58<00:49, 16.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned 855.8 million kroons , 295.1 million kroons \n",
      "-----------------------------------------------\n",
      " [['Itar-Tass', 'ORG'], ['Livshits', 'PER'], ['RAO Norilsky Nikel', 'ORG'], ['NKEL.RUO', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 48/50 [09:18<00:35, 17.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['IMC', 'ORG'], ['Dampier', 'ORG'], ['Kaohsiung', 'ORG'], ['China Steel', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 49/50 [09:30<00:15, 16.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Honda', 'ORG'], ['S-MX', 'MISC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [09:41<00:00, 11.63s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9751d9deb5a46f6abc9c394670b5b35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1538 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b7d478a0c53425aa7f7836665656172",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1970s , Poland received from unclaimed accounts in Switzerland a sum of 460,000 francs . "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|‚ñè         | 1/50 [00:12<10:19, 12.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned 1970s , Poland received from unclaimed accounts in Switzerland a sum of 460,000 francs . \n",
      "-----------------------------------------------\n",
      " [['National Weather Service', 'ORG'], ['U.S.', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|‚ñç         | 2/50 [00:24<09:50, 12.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Italian Serie A', 'MISC'], ['GMT', 'MISC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|‚ñå         | 3/50 [00:35<09:15, 11.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Bangui', 'LOC'], ['French', 'MISC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|‚ñä         | 4/50 [00:46<08:39, 11.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|‚ñà         | 5/50 [00:53<07:22,  9.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned  [] \n",
      "-----------------------------------------------\n",
      " [['East Timorese', 'MISC'], ['Roman Catholic', 'MISC'], ['Carlos Belo', 'PER'], ['Dili', 'LOC'], ['Norway', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|‚ñà‚ñè        | 6/50 [01:08<08:21, 11.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Ian Lang', 'PER'], ['Britain', 'LOC'], ['United States', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|‚ñà‚ñç        | 7/50 [01:25<09:37, 13.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['French', 'MISC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|‚ñà‚ñå        | 8/50 [01:36<08:51, 12.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Moin Khan', 'PER'], ['Astle', 'PER'], ['Harris', 'PER']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|‚ñà‚ñä        | 9/50 [01:44<07:31, 11.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Dow', 'MISC'], ['Jones', 'PER'], ['Greenspan', 'PER']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|‚ñà‚ñà        | 10/50 [02:00<08:23, 12.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Belo', 'PER'], ['Ramos Horta', 'PER'], ['East Timor', 'LOC'], ['Indonesia', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|‚ñà‚ñà‚ñè       | 11/50 [02:14<08:35, 13.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Paris St Germain', 'ORG'], ['Nancy', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|‚ñà‚ñà‚ñç       | 12/50 [02:21<07:07, 11.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|‚ñà‚ñà‚ñå       | 13/50 [02:29<06:13, 10.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned  [] \n",
      "-----------------------------------------------\n",
      " [] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|‚ñà‚ñà‚ñä       | 14/50 [02:36<05:35,  9.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned  [] \n",
      "-----------------------------------------------\n",
      " [['Tasmania', 'ORG'], ['David Boon', 'PER'], ['Shaun Young', 'PER'], ['Michael DiVenuto', 'PER'], ['Victoria', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|‚ñà‚ñà‚ñà       | 15/50 [02:50<06:16, 10.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['African', 'MISC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|‚ñà‚ñà‚ñà‚ñè      | 16/50 [03:05<06:41, 11.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Arafat', 'PER'], ['Nabil Abu Rdainah', 'PER']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|‚ñà‚ñà‚ñà‚ñç      | 17/50 [03:15<06:17, 11.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Guenther Huber', 'PER'], ['Antonio Tartaglia', 'PER'], ['Italy', 'LOC'], ['Americans', 'MISC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|‚ñà‚ñà‚ñà‚ñå      | 18/50 [03:28<06:21, 11.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['FIFA', 'ORG'], ['Joao Havelange', 'PER'], ['AC Milan', 'ORG'], ['George Weah', 'PER'], ['Porto', 'ORG'], ['Jorge Costa', 'PER']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|‚ñà‚ñà‚ñà‚ñä      | 19/50 [03:45<06:55, 13.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Internet', 'MISC'], ['Tim Casey', 'PER'], ['U.S.-based', 'MISC'], ['MCI Communications Corporation', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 20/50 [03:58<06:39, 13.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Bure', 'PER'], ['Burke', 'PER']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 21/50 [04:16<07:05, 14.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15-year-old girl is suffering from the disease . "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 22/50 [04:26<06:10, 13.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned 15-year-old girl is suffering from the disease . \n",
      "-----------------------------------------------\n",
      " [] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/50 [04:33<05:11, 11.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned  [] \n",
      "-----------------------------------------------\n",
      "1000 local / 1600 GMT', ['Communications and Transportation Ministry', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 24/50 [04:47<05:13, 12.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned 1000 local / 1600 GMT', ['Communications and Transportation Ministry', 'ORG']] \n",
      "-----------------------------------------------\n",
      " [['Chicago Newsdesk', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 25/50 [04:56<04:43, 11.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Australia', 'LOC'], ['West Indies', 'LOC'], ['World Series', 'MISC'], ['Melbourne Cricket Ground', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 26/50 [05:11<04:59, 12.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Singapore', 'LOC'], ['American', 'MISC'], ['Mickey Kantor', 'PER'], ['WTO', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 27/50 [05:32<05:44, 14.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 28/50 [05:43<05:03, 13.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned  [] \n",
      "-----------------------------------------------\n",
      " [['J. Murray', 'PER'], ['Blewett', 'PER'], ['Warne', 'PER']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 29/50 [05:51<04:14, 12.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Shwe Dagon', 'LOC'], ['Rangoon', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 30/50 [06:04<04:05, 12.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Canada', 'LOC'], ['Bre-X Minerals Ltd', 'ORG'], ['Barrick Gold Corp', 'ORG'], ['Busang', 'ORG'], ['Indonesia', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 31/50 [06:17<03:57, 12.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Saldanha', 'PER']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 32/50 [06:30<03:46, 12.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['VIEIRA', 'PER'], ['ARSENAL', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 33/50 [06:44<03:40, 12.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 to 28 kilometers / 11 to 17 miles "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 34/50 [06:57<03:27, 12.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned 19 to 28 kilometers / 11 to 17 miles \n",
      "-----------------------------------------------\n",
      "1997 Polish Market Share Van Boxmeer "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 35/50 [07:13<03:29, 13.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned 1997 Polish Market Share Van Boxmeer \n",
      "-----------------------------------------------\n",
      "37-year history . "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 36/50 [07:25<03:07, 13.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned 37-year history . \n",
      "-----------------------------------------------\n",
      " [['David Campese', 'PER'], ['England', 'LOC'], ['Australia', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 37/50 [07:39<02:56, 13.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 - Sheffield Shield . "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 38/50 [07:51<02:35, 12.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned 15 - Sheffield Shield . \n",
      "-----------------------------------------------\n",
      "3.47 3.35 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 39/50 [08:03<02:22, 12.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned 3.47 3.35 \n",
      "-----------------------------------------------\n",
      " [['Alessandra Mussolini', 'PER'], ['Italy', 'LOC'], ['Fascist', 'MISC'], ['Benito Mussolini', 'PER'], ['National Alliance', 'ORG'], ['AN', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 40/50 [08:20<02:21, 14.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['American', 'MISC'], ['U.S', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 41/50 [08:35<02:08, 14.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Action Performance Cos Inc', 'ORG'], ['Motorsport Traditions Ltd', 'ORG'], ['Creative Marketing & Promotions Inc', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 42/50 [08:50<01:55, 14.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Paul Justin', 'PER'], ['Jim Harbaugh', 'PER'], ['Colts', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 43/50 [09:06<01:45, 15.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78 cents higher at $ 25.58 a barrel , following breakthroughs of key technical levels and reports of tighter supplies . "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 44/50 [09:22<01:31, 15.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned 78 cents higher at $ 25.58 a barrel , following breakthroughs of key technical levels and reports of tighter supplies . \n",
      "-----------------------------------------------\n",
      " [['European', 'MISC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 45/50 [09:37<01:16, 15.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Bre-X', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 46/50 [09:53<01:01, 15.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['UK', 'LOC'], ['William Hill', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 47/50 [10:08<00:46, 15.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 48/50 [10:26<00:32, 16.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned  [] \n",
      "-----------------------------------------------\n",
      " [['M. Waugh', 'PER'], ['Murray', 'PER'], ['Benjamin', 'PER']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 49/50 [10:37<00:14, 14.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Clarke', 'PER'], ['Michael Heseltine', 'PER']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [10:52<00:00, 13.04s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db46367041c74cd88d2f6d3ceccb0c27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1538 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cf003bb4386428187ae7a9ff008b6a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['West Indies', 'LOC'], ['Brian Lara', 'PER'], ['Australian', 'MISC'], ['Australia', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|‚ñè         | 1/50 [00:17<14:31, 17.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Gorst', 'PER']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|‚ñç         | 2/50 [00:29<11:31, 14.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Statistics Canada', 'ORG'], ['U.S.', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|‚ñå         | 3/50 [00:44<11:13, 14.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['German', 'MISC'], ['Axel Schulz', 'PER'], ['Cuba', 'LOC'], ['Jose Ribalta', 'PER'], ['International Boxing Federation', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|‚ñä         | 4/50 [01:02<12:09, 15.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Forfar', 'ORG'], ['Alloa', 'ORG'], ['Inverness Thistle', 'ORG'], ['Queen 's Park', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|‚ñà         | 5/50 [01:18<11:56, 15.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|‚ñà‚ñè        | 6/50 [01:27<10:04, 13.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned  [] \n",
      "-----------------------------------------------\n",
      " [['WOOLMER', 'PER'], ['KANPUR', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|‚ñà‚ñç        | 7/50 [01:41<09:50, 13.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Liverpool', 'ORG'], ['Guy Whittingham', 'PER'], ['Sheffield Wednesday', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|‚ñà‚ñå        | 8/50 [01:57<10:04, 14.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|‚ñà‚ñä        | 9/50 [02:09<09:16, 13.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned  [] \n",
      "-----------------------------------------------\n",
      " [] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|‚ñà‚ñà        | 10/50 [02:20<08:30, 12.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned  [] \n",
      "-----------------------------------------------\n",
      " [['IPC', 'MISC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|‚ñà‚ñà‚ñè       | 11/50 [02:32<08:17, 12.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Myos Yang', 'ORG'], ['Indonesia', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|‚ñà‚ñà‚ñç       | 12/50 [02:40<07:12, 11.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Honda Motor Co Ltd', 'ORG'], ['S-MX', 'MISC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|‚ñà‚ñà‚ñå       | 13/50 [02:56<07:44, 12.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [] -----------------------------------------------\n",
      "response does not contain [[]]. Returned  [] \n",
      "-----------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|‚ñà‚ñà‚ñä       | 14/50 [03:05<06:57, 11.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|‚ñà‚ñà‚ñà       | 15/50 [03:15<06:29, 11.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned  [] \n",
      "-----------------------------------------------\n",
      " [['YIT', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|‚ñà‚ñà‚ñà‚ñè      | 16/50 [03:26<06:17, 11.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Kwasniewski', 'PER'], ['Italy', 'LOC'], ['Oscar Scalfaro', 'PER']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|‚ñà‚ñà‚ñà‚ñç      | 17/50 [03:38<06:11, 11.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['NYC', 'ORG'], ['Euro', 'MISC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|‚ñà‚ñà‚ñà‚ñå      | 18/50 [03:49<06:03, 11.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Britain', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|‚ñà‚ñà‚ñà‚ñä      | 19/50 [04:00<05:43, 11.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Suu Kyi', 'PER'], ['Nobel', 'PER'], ['Aung San', 'PER'], ['NLD', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 20/50 [04:15<06:11, 12.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.475 35.375 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 21/50 [04:28<05:58, 12.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned 34.475 35.375 \n",
      "-----------------------------------------------\n",
      "9. Michael Schumacher ( Germany ) Ferrari 1:51.799 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 22/50 [04:38<05:26, 11.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned 9. Michael Schumacher ( Germany ) Ferrari 1:51.799 \n",
      "-----------------------------------------------\n",
      " [['Pope', 'PER'], ['Dariusz Rosati', 'PER']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/50 [04:49<05:14, 11.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Muenchener Rueckversicherungs AG', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 24/50 [05:04<05:27, 12.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Lara', 'PER'], ['Australia', 'LOC'], ['Geoff Marsh', 'PER'], ['Ian Healy', 'PER']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 25/50 [05:19<05:29, 13.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Atalanta', 'ORG'], ['Filippo Inzaghi', 'PER']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 26/50 [05:32<05:18, 13.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Hindu', 'MISC'], ['Bharatiya Janata Party', 'ORG'], ['BJP', 'ORG'], ['Hindu', 'MISC'], ['Babri', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 27/50 [05:48<05:24, 14.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Lisbon', 'LOC'], ['Costa', 'PER']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 28/50 [06:05<05:29, 14.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Bernd Zobel', 'PER'], ['Canadian', 'MISC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 29/50 [06:21<05:21, 15.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Association of Southeast Asian Nations', 'ORG'], ['ASEAN', 'ORG'], ['ILO', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 30/50 [06:38<05:13, 15.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Lara', 'PER']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 31/50 [06:48<04:24, 13.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 games = 38 points "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 32/50 [06:59<03:54, 13.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned 16 games = 38 points \n",
      "-----------------------------------------------\n",
      "16-year-old Goetschl won the slalom to become history 's youngest World Cup victor . "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 33/50 [07:15<04:01, 14.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned 16-year-old Goetschl won the slalom to become history 's youngest World Cup victor . \n",
      "-----------------------------------------------\n",
      " [['Russia', 'LOC'], ['Norilsk', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 34/50 [07:27<03:36, 13.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Paul Crofts', 'PER'], ['Tony', 'PER'], ['New South Wales Supreme Court', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 35/50 [07:48<03:52, 15.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['National Weather Service', 'ORG'], ['U.S.', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 36/50 [08:03<03:36, 15.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Santa Fe', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 37/50 [08:18<03:17, 15.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Wallabies', 'ORG'], ['David Campese', 'PER'], ['Australian', 'MISC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 38/50 [08:40<03:27, 17.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 39/50 [08:52<02:54, 15.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned  [] \n",
      "-----------------------------------------------\n",
      " [['NYMEX', 'MISC'], ['Henry Hub', 'ORG'], ['National Weather Service', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 40/50 [09:10<02:43, 16.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38th person to die in Florida 's electric chair' "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 41/50 [09:24<02:20, 15.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned 38th person to die in Florida 's electric chair' \n",
      "-----------------------------------------------\n",
      "20,000 loan . "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 42/50 [09:37<01:58, 14.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned 20,000 loan . \n",
      "-----------------------------------------------\n",
      "347-year sentence . "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 43/50 [09:44<01:28, 12.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned 347-year sentence . \n",
      "-----------------------------------------------\n",
      "7 fire engines = 7 trucks . "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 44/50 [10:00<01:20, 13.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned 7 fire engines = 7 trucks . \n",
      "-----------------------------------------------\n",
      " [['London-to-Boston', 'MISC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 45/50 [10:11<01:03, 12.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95 centavos ( 12 cents ) "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 46/50 [10:18<00:44, 11.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned 95 centavos ( 12 cents ) \n",
      "-----------------------------------------------\n",
      " [['Scalfaro', 'PER'], ['Mantua', 'LOC'], ['Austrian', 'MISC'], ['Italians', 'MISC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 47/50 [10:35<00:38, 12.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 48/50 [10:49<00:26, 13.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned  [] \n",
      "-----------------------------------------------\n",
      "3.40s "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 49/50 [11:03<00:13, 13.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned 3.40s \n",
      "-----------------------------------------------\n",
      " [['Mexico', 'LOC'], ['Greenspan', 'PER']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [11:13<00:00, 13.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with sentence\n",
      "      and discussion\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a923f127e5264ae6ac29c70d8e4f3485",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1538 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e60082cb9e6414c841fe2ae5140cabd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Arafat', 'PER'], ['Netanyahu', 'PER']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|‚ñè         | 1/50 [00:02<01:59,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['ARAB CONTRACTORS', 'ORG'], ['AFRICAN CUP', 'MISC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|‚ñç         | 2/50 [00:05<02:04,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Singapore', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|‚ñå         | 3/50 [00:08<02:18,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Kesers', 'PER'], ['Karabuluts', 'PER'], ['Kurdish', 'MISC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|‚ñä         | 4/50 [00:12<02:38,  3.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Cambridge United', 'ORG'], ['Woking', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|‚ñà         | 5/50 [00:14<02:12,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|‚ñà‚ñè        | 6/50 [00:15<01:40,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned  [] \n",
      "-----------------------------------------------\n",
      " [['Ajax', 'ORG'], ['AZ Alkmaar', 'ORG'], ['Feyenoord', 'ORG'], ['UEFA Cup', 'MISC'], ['Tenerife', 'ORG'], ['De Graafschap Doetinchem', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|‚ñà‚ñç        | 7/50 [00:21<02:31,  3.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Rosati', 'PER']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|‚ñà‚ñå        | 8/50 [00:23<02:05,  2.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Pace', 'PER'], ['Ohio State', 'ORG'], ['Rose Bowl', 'LOC'], ['Arizona State', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|‚ñà‚ñä        | 9/50 [00:28<02:22,  3.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Iordanescu', 'PER'], ['National Bucharest', 'ORG'], ['Otelul Galati', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|‚ñà‚ñà        | 10/50 [00:32<02:31,  3.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Grove', 'PER'], ['Betcher', 'PER']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|‚ñà‚ñà‚ñè       | 11/50 [00:35<02:20,  3.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|‚ñà‚ñà‚ñç       | 12/50 [00:37<01:48,  2.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned  [] \n",
      "-----------------------------------------------\n",
      " [['Lazio', 'ORG'], ['Pierluigi Casiraghi', 'PER'], ['Czech', 'MISC'], ['Pavel Nedved', 'PER'], ['Paolo Negro', 'PER'], ['Roma', 'ORG'], ['Argentine', 'MISC'], ['Marco Delvecchio', 'PER'], ['Francesco Totti', 'PER']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|‚ñà‚ñà‚ñå       | 13/50 [00:45<02:52,  4.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['East Timorese', 'MISC'], ['Roman Catholic', 'MISC'], ['Carlos Belo', 'PER'], ['Dili', 'LOC'], ['Norway', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|‚ñà‚ñà‚ñä       | 14/50 [00:50<02:48,  4.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Jones', 'PER'], ['Tasmanian', 'MISC'], ['David Boon', 'PER'], ['Shaun Young', 'PER'], ['Michael DiVenuto', 'PER']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|‚ñà‚ñà‚ñà       | 15/50 [00:53<02:29,  4.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Langmore', 'PER'], ['Australia', 'LOC'], ['United Nations', 'ORG'], ['New York', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|‚ñà‚ñà‚ñà‚ñè      | 16/50 [00:57<02:15,  3.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 barges , two each week May-August , mid-Mississippi offered at a steady 135 percent , bid at 120 percent ( basis one each week ) . "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|‚ñà‚ñà‚ñà‚ñç      | 17/50 [01:02<02:21,  4.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned 36 barges , two each week May-August , mid-Mississippi offered at a steady 135 percent , bid at 120 percent ( basis one each week ) . \n",
      "-----------------------------------------------\n",
      " [] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|‚ñà‚ñà‚ñà‚ñå      | 18/50 [01:03<01:47,  3.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned  [] \n",
      "-----------------------------------------------\n",
      " [['R. Samuels', 'PER'], ['M. Waugh', 'PER'], ['Gillespie', 'PER']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|‚ñà‚ñà‚ñà‚ñä      | 19/50 [01:06<01:45,  3.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Switzerland', 'LOC'], ['Alfonse D'Amato', 'PER'], ['U.S.', 'LOC'], ['Senate Banking Committee', 'ORG'], ['Poland', 'LOC'], ['Polish', 'MISC'], ['Swiss', 'MISC'], ['Polish', 'MISC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 20/50 [01:12<02:04,  4.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 21/50 [01:14<01:37,  3.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned  [] \n",
      "-----------------------------------------------\n",
      " [['Gaulieder', 'PER']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 22/50 [01:16<01:25,  3.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Baril', 'PER']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/50 [01:18<01:12,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Internet', 'MISC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 24/50 [01:20<01:07,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Saldanha', 'PER']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 25/50 [01:22<00:59,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Scotland', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 26/50 [01:24<00:52,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 27/50 [01:26<00:46,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned  [] \n",
      "-----------------------------------------------\n",
      " [['Internet', 'MISC'], ['Information Technology Association of America', 'ORG'], ['U.S.', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 28/50 [01:30<00:59,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['BEIJING', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 29/50 [01:33<00:55,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 30/50 [01:34<00:45,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned  [] \n",
      "-----------------------------------------------\n",
      " [['Vicenza', 'ORG'], ['Bologna', 'ORG'], ['Italian', 'MISC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 31/50 [01:37<00:48,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Syria', 'LOC'], ['Lebanon', 'LOC'], ['France', 'LOC'], ['Spain', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 32/50 [01:41<00:53,  2.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['New Mexico Activities Association', 'ORG'], ['Cito', 'PER']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 33/50 [01:45<00:56,  3.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['South Korea', 'LOC'], ['Asian Cup', 'MISC'], ['Group A', 'MISC'], ['Indonesia', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 34/50 [01:50<00:59,  3.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Don Rieck', 'PER'], ['National Animal Control Association', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 35/50 [01:53<00:51,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Reuter', 'ORG'], ['Radiometer', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 36/50 [01:55<00:44,  3.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Reuters', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 37/50 [01:58<00:39,  3.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Jordan', 'PER'], ['World Trade Organisation', 'ORG'], ['WTO', 'ORG'], ['ILO', 'ORG'], ['Michel Hansenne', 'PER']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 38/50 [02:02<00:41,  3.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Germany 1,129,429 kg "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 39/50 [02:05<00:35,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned 1. Germany 1,129,429 kg \n",
      "-----------------------------------------------\n",
      " [] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 40/50 [02:06<00:26,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned  [] \n",
      "-----------------------------------------------\n",
      " [['DOT', 'ORG'], ['Reuters', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 41/50 [02:09<00:24,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Bulgaria', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 42/50 [02:11<00:19,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Wenchang', 'LOC'], ['Xinhua', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 43/50 [02:15<00:20,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Bre-X', 'ORG'], ['Barrick', 'ORG'], ['Mines and Energy Ministry', 'ORG'], ['Umar Said', 'PER'], ['Busang', 'LOC'], ['East Kalimantan', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 44/50 [02:21<00:22,  3.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['PKK', 'ORG'], ['Turkey', 'LOC'], ['Iraq', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 45/50 [02:24<00:17,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Asian Games', 'MISC'], ['Uzbekistan', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 46/50 [02:27<00:14,  3.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 47/50 [02:30<00:09,  3.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned  [] \n",
      "-----------------------------------------------\n",
      " [['Bitar', 'PER'], ['Miura', 'PER']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 48/50 [02:34<00:06,  3.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Meyers', 'PER'], ['American', 'MISC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 49/50 [02:36<00:03,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['U.S', 'LOC'], ['NYMEX', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [02:39<00:00,  3.18s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "753b08c2b14f40bcbb9cfb8f5304f5fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1538 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e91c37f69eff4402bbe37431106ee2bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['League', 'MISC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|‚ñè         | 1/50 [00:02<01:55,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38 Real Madrid Draw 16 games "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|‚ñç         | 2/50 [00:04<01:33,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned 38 Real Madrid Draw 16 games \n",
      "-----------------------------------------------\n",
      "104 USA I , Jim Herberich , Garrett Hines "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|‚ñå         | 3/50 [00:06<01:45,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned 104 USA I , Jim Herberich , Garrett Hines \n",
      "-----------------------------------------------\n",
      " [['Bitar', 'PER']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|‚ñä         | 4/50 [00:14<03:26,  4.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Italian', 'MISC'], ['Mantua', 'LOC'], ['Umberto Bossi', 'PER']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|‚ñà         | 5/50 [00:18<03:09,  4.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Manchester United', 'ORG'], ['Austrian', 'MISC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|‚ñà‚ñè        | 6/50 [00:20<02:41,  3.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['LEEDS', 'ORG'], ['BOWYER', 'PER']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|‚ñà‚ñç        | 7/50 [00:23<02:28,  3.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Billy Dodds', 'PER'], ['Aberdeen', 'ORG'], ['Pierre Van Hooydonk', 'PER'], ['Celtic', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|‚ñà‚ñå        | 8/50 [00:28<02:37,  3.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|‚ñà‚ñä        | 9/50 [00:29<02:01,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned  [] \n",
      "-----------------------------------------------\n",
      " [['United States I', 'ORG'], ['Jim Herberich', 'PER'], ['Garrett', 'PER']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|‚ñà‚ñà        | 10/50 [00:32<01:59,  3.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['East Timor', 'LOC'], ['Alatas', 'PER']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|‚ñà‚ñà‚ñè       | 11/50 [00:34<01:48,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Costa', 'PER']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|‚ñà‚ñà‚ñç       | 12/50 [00:36<01:35,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|‚ñà‚ñà‚ñå       | 13/50 [00:37<01:18,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned  [] \n",
      "-----------------------------------------------\n",
      " [['Japan', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|‚ñà‚ñà‚ñä       | 14/50 [00:40<01:17,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Russia', 'LOC'], ['Yeltsin', 'PER'], ['Kremlin', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|‚ñà‚ñà‚ñà       | 15/50 [00:42<01:20,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. S. Korea 10.000 10.000 10.000 10.000 10.000 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|‚ñà‚ñà‚ñà‚ñè      | 16/50 [00:48<01:48,  3.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned 1. S. Korea 10.000 10.000 10.000 10.000 10.000 \n",
      "-----------------------------------------------\n",
      " [['Xinhua', 'ORG'], ['Qinglan', 'LOC'], ['Wenchang', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|‚ñà‚ñà‚ñà‚ñç      | 17/50 [00:53<02:03,  3.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Labour', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|‚ñà‚ñà‚ñà‚ñå      | 18/50 [00:55<01:43,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Damascus', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|‚ñà‚ñà‚ñà‚ñä      | 19/50 [00:57<01:30,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Van Boxmeer', 'PER'], ['Zywiec', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 20/50 [01:00<01:33,  3.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 21/50 [01:02<01:17,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned  [] \n",
      "-----------------------------------------------\n",
      "20 years jail , Australian . "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 22/50 [01:05<01:15,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned 20 years jail , Australian . \n",
      "-----------------------------------------------\n",
      " [['Midcontinent', 'MISC'], ['New York', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/50 [01:08<01:20,  2.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350 lots were traded for January and 870 in all months . "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 24/50 [01:11<01:14,  2.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned 350 lots were traded for January and 870 in all months . \n",
      "-----------------------------------------------\n",
      " [['London Newsroom', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 25/50 [01:13<01:02,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34-year-old winger , Wallaby jersey , London , Saracens , Francois Pienaar , Michael Lynagh , Philippe Sella . "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 26/50 [01:21<01:38,  4.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned 34-year-old winger , Wallaby jersey , London , Saracens , Francois Pienaar , Michael Lynagh , Philippe Sella . \n",
      "-----------------------------------------------\n",
      " [['Pamplona', 'LOC'], ['Herri Batasuna', 'ORG'], ['Basque', 'MISC'], ['ETA', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 27/50 [01:26<01:41,  4.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['K.J. Matthew', 'PER'], ['Asia Rubber Markets', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 28/50 [01:29<01:28,  4.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 states , NWS "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 29/50 [01:30<01:09,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned 48 states , NWS \n",
      "-----------------------------------------------\n",
      " [['Frederick', 'PER']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 30/50 [01:32<00:57,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['West Indies', 'LOC'], ['Courtney Walsh', 'PER'], ['World Series', 'MISC'], ['Australia', 'LOC'], ['Melbourne Cricket Ground', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 31/50 [01:37<01:07,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 32/50 [01:40<00:56,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned  [] \n",
      "-----------------------------------------------\n",
      "600</start_output>\n",
      "\n",
      "### INPUT : <start_input> \" The United Nations would like to place on record its appreciation of the hospitality extended to the United Nations by the government of Burundi and its people , \" said Yasushi Akashi , the DHA undersecretary-general . <end_input>\n",
      "### OUTPUT : <start_output> [['United Nations', 'ORG'], ['United Nations', 'ORG'], ['Burundi', 'LOC'], ['DHA', 'ORG'], ['Yasushi Akashi', 'PER']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 33/50 [01:50<01:28,  5.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Bangui', 'LOC'], ['French', 'MISC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 34/50 [01:52<01:10,  4.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['POLAND', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 35/50 [01:55<00:58,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Switzerland', 'LOC'], ['Alfonse D'Amato', 'PER'], ['U.S.', 'LOC'], ['Senate Banking Committee', 'ORG'], ['Poland', 'LOC'], ['Polish', 'MISC'], ['Swiss', 'MISC'], ['Polish', 'MISC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 36/50 [02:01<01:03,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.80 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 37/50 [02:03<00:50,  3.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned 15.80 \n",
      "-----------------------------------------------\n",
      "3. Canada I ( Pierre Lueders , Dave MacEachern ) 1:45.94 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 38/50 [02:08<00:51,  4.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned 3. Canada I ( Pierre Lueders , Dave MacEachern ) 1:45.94 \n",
      "-----------------------------------------------\n",
      " [['Lahd', 'PER'], ['Israel', 'LOC'], ['Israel', 'LOC'], ['Lebanese', 'MISC'], ['Lebanese', 'MISC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 39/50 [02:16<00:56,  5.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Winnipeg', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 40/50 [02:18<00:43,  4.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 years ago', 'MISC'] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 41/50 [02:23<00:40,  4.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned 15 years ago', 'MISC'] \n",
      "-----------------------------------------------\n",
      " [['Shivnarine Chanderpaul', 'PER']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 42/50 [02:27<00:34,  4.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 43/50 [02:28<00:24,  3.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned  [] \n",
      "-----------------------------------------------\n",
      " [['Bure', 'PER'], ['Galley', 'PER'], ['NHL', 'ORG'], ['Brian Burke', 'PER']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 44/50 [02:34<00:24,  4.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['French-owned', 'MISC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 45/50 [02:37<00:19,  3.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Japan', 'LOC'], ['Shu Kamo', 'PER'], ['Syrian', 'MISC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 46/50 [02:42<00:16,  4.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Britain', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 47/50 [02:45<00:11,  3.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14,000+ ANC , Zulu , Mangosuthu Buthelezi , Inkatha Freedom Party , ANC , Zulu , Mangosuthu Buthelezi , Inkatha Freedom Party , ANC , Zulu , Mangosuthu Buthelezi , Inkatha Freedom Party , ANC , Zulu , Mangosuthu Buthelezi , Inkatha Freedom Party , ANC , Zulu , Mangosuthu Buthelezi , Inkatha Freedom Party , ANC , Zulu , Mangosuthu Buthelezi , Inkatha Freedom Party , ANC , Zulu , Mangosuthu Buthelezi , Inkatha Freedom Party , ANC , Zulu , Mangosuthu Buthelezi , Inkatha Freedom Party , ANC , Zulu , Mangosuthu Buthelezi , Inkatha Freedom Party , ANC"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 48/50 [03:05<00:17,  8.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned 14,000+ ANC , Zulu , Mangosuthu Buthelezi , Inkatha Freedom Party , ANC , Zulu , Mangosuthu Buthelezi , Inkatha Freedom Party , ANC , Zulu , Mangosuthu Buthelezi , Inkatha Freedom Party , ANC , Zulu , Mangosuthu Buthelezi , Inkatha Freedom Party , ANC , Zulu , Mangosuthu Buthelezi , Inkatha Freedom Party , ANC , Zulu , Mangosuthu Buthelezi , Inkatha Freedom Party , ANC , Zulu , Mangosuthu Buthelezi , Inkatha Freedom Party , ANC , Zulu , Mangosuthu Buthelezi , Inkatha Freedom Party , ANC , Zulu , Mangosuthu Buthelezi , Inkatha Freedom Party , ANC\n",
      "-----------------------------------------------\n",
      " [['Med', 'MISC'], ['Elf', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 49/50 [03:10<00:07,  7.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Artur Lekbello', 'PER'], ['Hafizi', 'PER'], ['Belfast', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [03:14<00:00,  3.89s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdc8565572694312898425c2415e35a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1538 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30b381af07dc406fa29a04656d6a3b43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Liverpool', 'ORG'], ['Sheffield Wednesday', 'ORG'], ['Whittingham', 'PER']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|‚ñè         | 1/50 [00:04<03:20,  4.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Romania', 'LOC'], ['Constantinescu', 'PER']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|‚ñç         | 2/50 [00:07<02:55,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Clinton', 'PER']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|‚ñå         | 3/50 [00:10<02:34,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|‚ñä         | 4/50 [00:11<02:00,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned  [] \n",
      "-----------------------------------------------\n",
      " [] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|‚ñà         | 5/50 [00:13<01:48,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned  [] \n",
      "-----------------------------------------------\n",
      " [['Tasmania', 'ORG'], ['David Boon', 'PER'], ['Shaun Young', 'PER'], ['Michael DiVenuto', 'PER'], ['Victoria', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|‚ñà‚ñè        | 6/50 [00:19<02:39,  3.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['HAVEL', 'PER']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|‚ñà‚ñç        | 7/50 [00:22<02:16,  3.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Zairean', 'MISC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|‚ñà‚ñå        | 8/50 [00:24<02:08,  3.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Electronic Data Systems', 'ORG'], ['Private Finance Initiative', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|‚ñà‚ñä        | 9/50 [00:28<02:11,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Norilsk', 'ORG'], ['Russian', 'MISC'], ['Uneximbank', 'ORG'], ['Interrosimpex', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|‚ñà‚ñà        | 10/50 [00:33<02:30,  3.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Gorst', 'PER'], ['Major', 'PER'], ['House of Commons', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|‚ñà‚ñà‚ñè       | 11/50 [00:37<02:33,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Kinder', 'ORG'], ['Zoran Savic', 'PER']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|‚ñà‚ñà‚ñç       | 12/50 [00:40<02:14,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|‚ñà‚ñà‚ñå       | 13/50 [00:42<01:48,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned  [] \n",
      "-----------------------------------------------\n",
      " [] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|‚ñà‚ñà‚ñä       | 14/50 [00:44<01:37,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned  [] \n",
      "-----------------------------------------------\n",
      "1988 - Kerwin Bell , a 1988 draft choice of the Miami Dolphins , made his NFL debut and was 5-of-5 for 75 yards , including a 20-yard scoring strike to Marvin Harrison in the third period . "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|‚ñà‚ñà‚ñà       | 15/50 [00:51<02:21,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned 1988 - Kerwin Bell , a 1988 draft choice of the Miami Dolphins , made his NFL debut and was 5-of-5 for 75 yards , including a 20-yard scoring strike to Marvin Harrison in the third period . \n",
      "-----------------------------------------------\n",
      " [['Interfax', 'ORG'], ['Igor Ivanov', 'PER'], ['Moscow', 'LOC'], ['Albright', 'PER']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|‚ñà‚ñà‚ñà‚ñè      | 16/50 [00:56<02:32,  4.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88th minute , Hiroshige Yanagimoto , Salem Bitar , Takuya Takagi "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|‚ñà‚ñà‚ñà‚ñç      | 17/50 [01:01<02:28,  4.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned 88th minute , Hiroshige Yanagimoto , Salem Bitar , Takuya Takagi \n",
      "-----------------------------------------------\n",
      " [['Barcelona', 'ORG'], ['Brazilian', 'MISC'], ['Ronaldo', 'PER']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|‚ñà‚ñà‚ñà‚ñå      | 18/50 [01:05<02:15,  4.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Mongolia', 'LOC'], ['Gundegma Jargalshaihan', 'PER'], ['Ulan Bator', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|‚ñà‚ñà‚ñà‚ñä      | 19/50 [01:08<02:08,  4.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Burmese', 'MISC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 20/50 [01:12<01:56,  3.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Wallaby', 'MISC'], ['Nick Farr-Jones', 'PER'], ['Campese', 'PER'], ['England', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 21/50 [01:17<02:01,  4.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['FRANKFURT', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 22/50 [01:19<01:40,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 lots , 35 lots "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/50 [01:21<01:25,  3.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned 33 lots , 35 lots \n",
      "-----------------------------------------------\n",
      " [] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 24/50 [01:23<01:17,  2.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned  [] \n",
      "-----------------------------------------------\n",
      " [['Internet', 'MISC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 25/50 [01:26<01:11,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 26/50 [01:28<00:59,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned  [] \n",
      "-----------------------------------------------\n",
      "65-80-litre level could be reached in the next ten years and make Poland , with its 40-million population , Europe 's third largest beer market after Germany and Britain . "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 27/50 [01:33<01:16,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned 65-80-litre level could be reached in the next ten years and make Poland , with its 40-million population , Europe 's third largest beer market after Germany and Britain . \n",
      "-----------------------------------------------\n",
      " [['Iowa-S Minn', 'LOC'], ['USDA', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 28/50 [01:37<01:15,  3.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 29/50 [01:38<00:58,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned  [] \n",
      "-----------------------------------------------\n",
      " [['Italy', 'LOC'], ['Roman Catholic', 'MISC'], ['Zaire', 'LOC'], ['Tutsi', 'MISC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 30/50 [01:43<01:09,  3.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['China', 'LOC'], ['Hainan', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 31/50 [01:46<01:03,  3.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30-day open , mid-Mississippi ( McGregor and south ) "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 32/50 [01:49<00:59,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned 30-day open , mid-Mississippi ( McGregor and south ) \n",
      "-----------------------------------------------\n",
      " [['Rosati', 'PER'], ['Warsaw', 'LOC'], ['Vatican', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 33/50 [01:52<00:55,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 34/50 [01:54<00:43,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned  [] \n",
      "-----------------------------------------------\n",
      " [['KCBT', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 35/50 [01:56<00:38,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['British', 'MISC'], ['John Major', 'PER'], ['Conservative', 'MISC'], ['Sir John Gorst', 'PER']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 36/50 [02:02<00:48,  3.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['ENGLISH', 'MISC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 37/50 [02:04<00:39,  3.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['St. Louis', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 38/50 [02:05<00:31,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Stephen Nisbet , International Bonds +44 171 6320 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 39/50 [02:08<00:29,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned ---- Stephen Nisbet , International Bonds +44 171 6320 \n",
      "-----------------------------------------------\n",
      " [['Eagles', 'ORG'], ['Ty Detmer', 'PER']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 40/50 [02:13<00:32,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6,000 plastic surgeons there , of which 4,500 have qualified to be members of the SBCP . "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 41/50 [02:16<00:28,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned 6,000 plastic surgeons there , of which 4,500 have qualified to be members of the SBCP . \n",
      "-----------------------------------------------\n",
      " [['Brazil', 'LOC'], ['Farid Hakme', 'PER'], ['Brazilian Plastic Surgery Society', 'ORG'], ['SBCP', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 42/50 [02:20<00:26,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Gorst', 'PER'], ['House of Commons', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 43/50 [02:23<00:23,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['NZ', 'LOC'], ['Bolger', 'PER'], ['Nats', 'ORG'], ['NZ First', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 44/50 [02:28<00:22,  3.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Havel', 'PER'], ['Czech', 'MISC'], ['Albright', 'PER']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 45/50 [02:33<00:21,  4.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['National Weather Service', 'ORG'], ['U.S.', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 46/50 [02:36<00:15,  3.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['South Korea', 'LOC'], ['Kim Byung Ji', 'PER'], ['Kim Pan Keun', 'PER'], ['Huh Ki Tae', 'PER'], ['Roh Sang Rae', 'PER'], ['Sin Tae Yong', 'PER'], ['Kim Do Hoon', 'PER'], ['Ko Jeong Woon', 'PER'], ['Ha Seok Ju', 'PER'], ['Hwang Sun Hong', 'PER'], ['Lee Young Jin', 'PER'], ['Yoo Sang Chul', 'PER'], ['Kim Joo Sung', 'PER']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 47/50 [02:48<00:18,  6.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1994 1995 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 48/50 [02:50<00:09,  5.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned 1994 1995 \n",
      "-----------------------------------------------\n",
      " [['French', 'MISC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 49/50 [02:52<00:04,  4.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['PKK', 'ORG'], ['Turkey', 'LOC'], ['Iraq', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [02:57<00:00,  3.54s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcc32ef0e7374ddabb7dbecadb1daade",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1538 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "450ccf1f40db45419f8177946d800712",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Wall St', 'LOC'], ['Santa Fe', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|‚ñè         | 1/50 [00:04<03:56,  4.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89,300 head confirmed including 30,600 head of contracted or formulated cattle . "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|‚ñç         | 2/50 [00:07<02:51,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned 89,300 head confirmed including 30,600 head of contracted or formulated cattle . \n",
      "-----------------------------------------------\n",
      " [] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|‚ñå         | 3/50 [00:08<02:01,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned  [] \n",
      "-----------------------------------------------\n",
      " [['Tampico', 'LOC'], ['Kenda', 'MISC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|‚ñä         | 4/50 [00:12<02:22,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Charleroi', 'ORG'], ['Eric Cleymans', 'PER'], ['Ron Ellis', 'PER'], ['Jacques Stas', 'PER']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|‚ñà         | 5/50 [00:18<03:07,  4.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Japan', 'LOC'], ['World Cup', 'MISC'], ['FIFA', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|‚ñà‚ñè        | 6/50 [00:22<02:47,  3.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['RKC Waalwijk', 'ORG'], ['Willem II Tilburg', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|‚ñà‚ñç        | 7/50 [00:25<02:37,  3.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Singapore', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|‚ñà‚ñå        | 8/50 [00:27<02:13,  3.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Hapoel Beit She'an', 'ORG'], ['Hapoel Beersheba', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|‚ñà‚ñä        | 9/50 [00:31<02:25,  3.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Langmore', 'PER'], ['Australia', 'LOC'], ['United Nations', 'ORG'], ['New York', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|‚ñà‚ñà        | 10/50 [00:36<02:33,  3.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.00 yen "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|‚ñà‚ñà‚ñè       | 11/50 [00:38<02:06,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned 5.00 yen \n",
      "-----------------------------------------------\n",
      " [] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|‚ñà‚ñà‚ñç       | 12/50 [00:39<01:36,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned  [] \n",
      "-----------------------------------------------\n",
      " [['Insein', 'LOC'], ['Rangoon', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|‚ñà‚ñà‚ñå       | 13/50 [00:42<01:37,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Tony Greig', 'PER'], ['England', 'LOC'], ['India', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|‚ñà‚ñà‚ñä       | 14/50 [00:45<01:45,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Leeds', 'ORG'], ['Bowyer', 'PER']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|‚ñà‚ñà‚ñà       | 15/50 [00:48<01:44,  2.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|‚ñà‚ñà‚ñà‚ñè      | 16/50 [00:50<01:26,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned  [] \n",
      "-----------------------------------------------\n",
      " [['Nader Jokhadar', 'PER'], ['Syria', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|‚ñà‚ñà‚ñà‚ñç      | 17/50 [00:53<01:34,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Rashid', 'PER'], ['Greece', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|‚ñà‚ñà‚ñà‚ñå      | 18/50 [00:57<01:40,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Burns', 'PER']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|‚ñà‚ñà‚ñà‚ñä      | 19/50 [00:59<01:24,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Shwe Dagon', 'LOC'], ['Rangoon', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 20/50 [01:02<01:23,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 people were known to have been killed in the more than two weeks of fighting . "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 21/50 [01:05<01:25,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned 10 people were known to have been killed in the more than two weeks of fighting . \n",
      "-----------------------------------------------\n",
      " [['BALKAN', 'LOC'], ['Real', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 22/50 [01:09<01:33,  3.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Basketball Association', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/50 [01:12<01:23,  3.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Santa Claus', 'PER'], ['German', 'MISC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 24/50 [01:15<01:20,  3.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['West Indies', 'LOC'], ['World Series', 'MISC'], ['Australia', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 25/50 [01:19<01:21,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Mexico', 'LOC'], ['Aninat', 'PER'], ['Canada', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 26/50 [01:23<01:24,  3.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Pakistan', 'LOC'], ['New Zealand', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 27/50 [01:27<01:25,  3.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 28/50 [01:29<01:07,  3.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned  [] \n",
      "-----------------------------------------------\n",
      "104 USA I , Jim Herberich , Garrett Hines "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 29/50 [01:31<01:00,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned 104 USA I , Jim Herberich , Garrett Hines \n",
      "-----------------------------------------------\n",
      " [] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 30/50 [01:33<00:50,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned  [] \n",
      "-----------------------------------------------\n",
      " [['Hwang Sun Hong', 'PER']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 31/50 [01:36<00:54,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['China', 'LOC'], ['Guilin', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 32/50 [01:40<00:53,  2.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Newmont-Santa Fe', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 33/50 [01:43<00:51,  3.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Albright', 'PER'], ['Europe', 'LOC'], ['U.S.', 'LOC'], ['United Nations', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 34/50 [01:48<00:56,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 35/50 [01:49<00:44,  2.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned  [] \n",
      "-----------------------------------------------\n",
      " [['Alatas', 'PER'], ['Oslo', 'LOC'], ['Belo', 'PER'], ['Vatican', 'LOC'], ['Helmut Kohl', 'PER'], ['Bonn', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 36/50 [01:55<00:53,  3.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['USDA', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 37/50 [01:57<00:42,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Brazil', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 38/50 [02:00<00:38,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 39/50 [02:02<00:30,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned  [] \n",
      "-----------------------------------------------\n",
      " [['Frederick', 'PER']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 40/50 [02:04<00:26,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 41/50 [02:06<00:20,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "response does not contain [[]]. Returned  [] \n",
      "-----------------------------------------------\n",
      " [['Jean van Boxmeer', 'PER'], ['Reuters', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 42/50 [02:11<00:25,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['State Council', 'ORG'], ['Port Office', 'ORG'], ['Civil Aviation Administration of China', 'ORG'], ['General Administration of Customs', 'ORG'], ['Xinhua', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 43/50 [02:17<00:27,  3.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Nicol', 'PER']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 44/50 [02:19<00:21,  3.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Munich Re', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 45/50 [02:22<00:17,  3.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['East Timor', 'LOC'], ['Alatas', 'PER']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 46/50 [02:25<00:13,  3.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Hakme', 'PER'], ['Brazil', 'LOC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 47/50 [02:29<00:09,  3.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Canadian West Coast', 'LOC'], ['CWB', 'ORG']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 48/50 [02:32<00:06,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Internet', 'MISC']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 49/50 [02:34<00:02,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [['Moustapha Niasse', 'PER']] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [02:38<00:00,  3.18s/it]\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/numpy/core/_methods.py:269: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/numpy/core/_methods.py:261: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'ResultInstanceWithConfidenceInterval' object has no attribute 'noshots'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/ubuntu/llm-project/Master-thesis/testing_llm_ner.ipynb Cell 1\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B194.182.171.183/home/ubuntu/llm-project/Master-thesis/testing_llm_ner.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m model \u001b[39m=\u001b[39m MistralAI()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B194.182.171.183/home/ubuntu/llm-project/Master-thesis/testing_llm_ner.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m model\u001b[39m.\u001b[39mload_finetuned_model(PT_OutputList\u001b[39m.\u001b[39mname(), \u001b[39m10000\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B194.182.171.183/home/ubuntu/llm-project/Master-thesis/testing_llm_ner.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m results, results_df \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mclassical_test(pts \u001b[39m=\u001b[39;49m [PT_OutputList],fsts \u001b[39m=\u001b[39;49m [FST_Entity, FST_Sentence] ,nb_run_by_test\u001b[39m=\u001b[39;49m\u001b[39m4\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B194.182.171.183/home/ubuntu/llm-project/Master-thesis/testing_llm_ner.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m results_df\n",
      "File \u001b[0;32m~/llm-project/Master-thesis/llm/LLMModel.py:133\u001b[0m, in \u001b[0;36mLLMModel.classical_test\u001b[0;34m(self, fsts, pts, nb_few_shots, verifier, confidence_checker, save, nb_run_by_test)\u001b[0m\n\u001b[1;32m    131\u001b[0m                 save_result_instance_with_CI(results[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[1;32m    132\u001b[0m             fst\u001b[39m.\u001b[39msave_few_shots()\n\u001b[0;32m--> 133\u001b[0m results_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame([result\u001b[39m.\u001b[39mget_dict() \u001b[39mfor\u001b[39;00m result \u001b[39min\u001b[39;00m results])\n\u001b[1;32m    134\u001b[0m \u001b[39mreturn\u001b[39;00m results, results_df\n",
      "File \u001b[0;32m~/llm-project/Master-thesis/llm/LLMModel.py:133\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    131\u001b[0m                 save_result_instance_with_CI(results[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[1;32m    132\u001b[0m             fst\u001b[39m.\u001b[39msave_few_shots()\n\u001b[0;32m--> 133\u001b[0m results_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame([result\u001b[39m.\u001b[39;49mget_dict() \u001b[39mfor\u001b[39;00m result \u001b[39min\u001b[39;00m results])\n\u001b[1;32m    134\u001b[0m \u001b[39mreturn\u001b[39;00m results, results_df\n",
      "File \u001b[0;32m~/llm-project/Master-thesis/ner/llm_ner/ResultInstance.py:84\u001b[0m, in \u001b[0;36mResultInstanceWithConfidenceInterval.get_dict\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_dict\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mdict\u001b[39m:\n\u001b[1;32m     80\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_scores()\n\u001b[1;32m     81\u001b[0m         \u001b[39mreturn\u001b[39;00m {\n\u001b[1;32m     82\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mf1_mean\u001b[39m\u001b[39m\"\u001b[39m : \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf1_mean, \u001b[39m\"\u001b[39m\u001b[39mf1_conf_inter\u001b[39m\u001b[39m\"\u001b[39m : \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf1_conf_inter, \n\u001b[1;32m     83\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m'\u001b[39m : \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mres_insts[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mmodel,\n\u001b[0;32m---> 84\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mnoshots\u001b[39m\u001b[39m'\u001b[39m : \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnoshots,\n\u001b[1;32m     85\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mprompt_technique\u001b[39m\u001b[39m'\u001b[39m : \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mres_insts[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mprompt_technique,\n\u001b[1;32m     86\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mfew_shot_tecnique\u001b[39m\u001b[39m'\u001b[39m : \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mres_insts[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mfew_shot_tecnique,\n\u001b[1;32m     87\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mnb_few_shots\u001b[39m\u001b[39m'\u001b[39m : \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mres_insts[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mnb_few_shots,\n\u001b[1;32m     88\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mprecision\u001b[39m\u001b[39m'\u001b[39m :  \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mres_insts[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mwith_precision \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mres_insts[\u001b[39m0\u001b[39m], \u001b[39m'\u001b[39m\u001b[39mwith_precision\u001b[39m\u001b[39m'\u001b[39m) \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mno-precision\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     89\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mverifier\u001b[39m\u001b[39m'\u001b[39m : \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mres_insts[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mverifier,\n\u001b[1;32m     90\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mlen_data_train\u001b[39m\u001b[39m'\u001b[39m : \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mres_insts[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mlen_data_train,\n\u001b[1;32m     91\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mlen_data_test\u001b[39m\u001b[39m'\u001b[39m : \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mres_insts[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mlen_data_test,\n\u001b[1;32m     92\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mnb_test_run\u001b[39m\u001b[39m'\u001b[39m : \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mres_insts),\n\u001b[1;32m     93\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mconfidence_interval\u001b[39m\u001b[39m'\u001b[39m : \u001b[39m0.95\u001b[39m,\n\u001b[1;32m     94\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mdistribution_used\u001b[39m\u001b[39m'\u001b[39m : \u001b[39m'\u001b[39m\u001b[39mStudent\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     95\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mprecision_mean\u001b[39m\u001b[39m\"\u001b[39m : \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprecision_mean, \u001b[39m\"\u001b[39m\u001b[39mprecision_conf_inter\u001b[39m\u001b[39m\"\u001b[39m : \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprecision_conf_inter, \n\u001b[1;32m     96\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mrecall_mean\u001b[39m\u001b[39m\"\u001b[39m : \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrecall_mean, \u001b[39m\"\u001b[39m\u001b[39mrecall_conf_inter\u001b[39m\u001b[39m\"\u001b[39m : \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrecall_conf_inter\n\u001b[1;32m     97\u001b[0m     }\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ResultInstanceWithConfidenceInterval' object has no attribute 'noshots'"
     ]
    }
   ],
   "source": [
    "# ToDo \n",
    "from llm.LLMModel import *\n",
    "from ner.llm_ner.prompt_techniques.pt_abstract import PromptTechnique\n",
    "from ner.llm_ner.prompt_techniques.pt_discussion import PT_OutputList\n",
    "from ner.llm_ner.prompt_techniques.pt_gpt_ner import PT_GPT_NER\n",
    "from ner.llm_ner.prompt_techniques.pt_wrapper import PT_Wrapper\n",
    "from ner.llm_ner.few_shots_techniques import *\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "model = MistralAI()\n",
    "model.load_finetuned_model(PT_OutputList.name(), 10000)\n",
    "\n",
    "results, results_df = model.classical_test(pts = [PT_OutputList],fsts = [FST_Entity, FST_Sentence] ,nb_run_by_test=4)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running\n",
    "from llm.LLMModel import *\n",
    "from ner.llm_ner.prompt_techniques.pt_abstract import PromptTechnique\n",
    "from ner.llm_ner.prompt_techniques.pt_discussion import PT_OutputList\n",
    "from ner.llm_ner.prompt_techniques.pt_gpt_ner import PT_GPT_NER\n",
    "from ner.llm_ner.prompt_techniques.pt_wrapper import PT_Wrapper\n",
    "from ner.llm_ner.few_shots_techniques import *\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "model = MistralAI()\n",
    "\n",
    "results, results_df = model.classical_test(pts = [PT_GPT_NER], nb_run_by_test=10)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo \n",
    "from llm.LLMModel import *\n",
    "from ner.llm_ner.prompt_techniques.pt_abstract import PromptTechnique\n",
    "from ner.llm_ner.prompt_techniques.pt_discussion import PT_OutputList\n",
    "from ner.llm_ner.prompt_techniques.pt_gpt_ner import PT_GPT_NER\n",
    "from ner.llm_ner.prompt_techniques.pt_wrapper import PT_Wrapper\n",
    "from ner.llm_ner.few_shots_techniques import *\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "model = Llama13b()\n",
    "\n",
    "results, results_df = model.classical_test(pts = [PT_OutputList])\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ner.llm_ner.prompt_techniques.pt_multi_pt import PT_Multi_PT\n",
    "from ner.llm_ner.prompt_techniques.pt_get_entities import PT_GetEntities\n",
    "from ner.llm_ner.prompt_techniques.pt_tagger import PT_Tagger\n",
    "\n",
    "from ner.llm_ner.few_shots_techniques import *\n",
    "from llm.LLMModel import *\n",
    "from ner.Datasets.Conll2003Dataset import get_test_cleaned_split\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "seed = 10 # random.randint(0, 1535468)\n",
    "data_train, data_test = get_test_cleaned_split(seed = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fst = FST_Sentence(data_train, 3)\n",
    "pts = [PT_GetEntities(fst), PT_Tagger(fst)]\n",
    "multi_pt = PT_Multi_PT(pts)\n",
    "llm = NoLLM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.invoke(\"Jeremy Ferrari is a french guys that lives in England\", multi_pt, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm.LLMModel import *\n",
    "from ner.llm_ner.prompt_techniques.pt_abstract import PromptTechnique\n",
    "from ner.llm_ner.prompt_techniques.pt_discussion import PT_OutputList\n",
    "from ner.llm_ner.prompt_techniques.pt_gpt_ner import PT_GPT_NER\n",
    "from ner.llm_ner.prompt_techniques.pt_wrapper import PT_Wrapper\n",
    "from ner.llm_ner.prompt_techniques.pt_multi_pt import PT_2Time_Tagger\n",
    "from ner.llm_ner.few_shots_techniques import *\n",
    "from ner.llm_ner.prompts import *\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "model = MistralAI()\n",
    "plus_plus = False\n",
    "pts = [\n",
    "       PT_GPT_NER, \n",
    "       # PT_OutputList, \n",
    "       # PT_Wrapper, \n",
    "       # PT_2Time_Tagger,\n",
    "       # PT_Filing\n",
    "       ]\n",
    "for plus_plus in [True, False]:\n",
    "       results, results_df = model.classical_test_ontonote5(pts = pts, fsts = [FST_NoShots], nb_few_shots=[0], nb_run_by_test=3, plus_plus= plus_plus, test_size = 100)\n",
    "\n",
    "\n",
    "for plus_plus in [True, False]:\n",
    "       results, results_df = model.classical_test_ontonote5(pts = pts, fsts = [FST_Sentence], nb_few_shots=[3], nb_run_by_test=3, plus_plus= plus_plus, test_size = 100)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test ft models\n",
    "\n",
    "from llm.LLMModel import *\n",
    "import torch\n",
    "from ner.llm_ner.prompt_techniques.pt_abstract import PromptTechnique\n",
    "from ner.llm_ner.prompt_techniques.pt_discussion import PT_OutputList\n",
    "from ner.llm_ner.prompt_techniques.pt_gpt_ner import PT_GPT_NER\n",
    "from ner.llm_ner.prompt_techniques.pt_wrapper import PT_Wrapper\n",
    "from ner.llm_ner.prompt_techniques.pt_multi_pt import PT_2Time_Tagger\n",
    "from ner.llm_ner.few_shots_techniques import *\n",
    "from ner.llm_ner.prompts import *\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "model = MistralAI()\n",
    "plus_plus = False\n",
    "pts = [\n",
    "       PT_GPT_NER, \n",
    "       PT_OutputList, \n",
    "       PT_Wrapper, \n",
    "       PT_2Time_Tagger,\n",
    "       PT_Filing\n",
    "       ]\n",
    "for pt in pts :\n",
    "    model.load_finetuned_model(pt = pt(None), prompt_type_name=\"raw\", nb_samples=2000)\n",
    "    for plus_plus in [True, False]:\n",
    "        results, results_df = model.classical_test_ontonote5(pts = pts, fsts = [FST_NoShots], nb_few_shots=[0], nb_run_by_test=3, plus_plus= plus_plus, test_size = 100)\n",
    "\n",
    "\n",
    "    for plus_plus in [True, False]:\n",
    "        results, results_df = model.classical_test_ontonote5(pts = pts, fsts = [FST_Sentence], nb_few_shots=[3], nb_run_by_test=3, plus_plus= plus_plus, test_size = 100)\n",
    "    results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with sentence\n",
      "      and discussion\n",
      "./ner/saves/datasets/ontonote5_test_1403.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:10<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'is'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/myhome/Master-thesis/testing_llm_ner.ipynb Cell 2\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B127.0.0.1/myhome/Master-thesis/testing_llm_ner.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m plus_plus \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B127.0.0.1/myhome/Master-thesis/testing_llm_ner.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m pts \u001b[39m=\u001b[39m [\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B127.0.0.1/myhome/Master-thesis/testing_llm_ner.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m        \u001b[39m# PT_GPT_NER, \u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B127.0.0.1/myhome/Master-thesis/testing_llm_ner.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m        PT_OutputList, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B127.0.0.1/myhome/Master-thesis/testing_llm_ner.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m        \u001b[39m# PT_Filing\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B127.0.0.1/myhome/Master-thesis/testing_llm_ner.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m        ]\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B127.0.0.1/myhome/Master-thesis/testing_llm_ner.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m results, results_df \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mclassical_test_ontonote5(pts \u001b[39m=\u001b[39;49m pts, fsts \u001b[39m=\u001b[39;49m [FST_Sentence], nb_few_shots\u001b[39m=\u001b[39;49m[\u001b[39m0\u001b[39;49m,\u001b[39m3\u001b[39;49m,\u001b[39m5\u001b[39;49m,\u001b[39m10\u001b[39;49m,\u001b[39m15\u001b[39;49m,\u001b[39m30\u001b[39;49m], nb_run_by_test\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m, plus_plus\u001b[39m=\u001b[39;49m plus_plus, test_size \u001b[39m=\u001b[39;49m \u001b[39m100\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B127.0.0.1/myhome/Master-thesis/testing_llm_ner.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mfor\u001b[39;00m pt \u001b[39min\u001b[39;00m pts :\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B127.0.0.1/myhome/Master-thesis/testing_llm_ner.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m     model\u001b[39m.\u001b[39mload_finetuned_model(pt\u001b[39m.\u001b[39mname(), \u001b[39m2000\u001b[39m)\n",
      "File \u001b[0;32m/myhome/Master-thesis/llm/LLMModel.py:110\u001b[0m, in \u001b[0;36mLLMModel.classical_test_ontonote5\u001b[0;34m(self, fsts, pts, nb_few_shots, verifier, confidence_checker, save, nb_run_by_test, with_precision, prompt_template, plus_plus, dataset_loader, test_size)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mclassical_test_ontonote5\u001b[39m(\u001b[39mself\u001b[39m, \n\u001b[1;32m     98\u001b[0m                    fsts : \u001b[39mlist\u001b[39m[FewShotsTechnique]\u001b[39m=\u001b[39m [FST_NoShots, FST_Sentence], \n\u001b[1;32m     99\u001b[0m                    pts : \u001b[39mlist\u001b[39m[PromptTechnique] \u001b[39m=\u001b[39m [PT_GPT_NER, PT_OutputList, PT_Wrapper],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    108\u001b[0m                    dataset_loader \u001b[39m=\u001b[39m ontonote_get_test_cleaned_split,\n\u001b[1;32m    109\u001b[0m                    test_size \u001b[39m=\u001b[39m \u001b[39m50\u001b[39m) :\n\u001b[0;32m--> 110\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclassical_test(fsts , \n\u001b[1;32m    111\u001b[0m                    pts,\n\u001b[1;32m    112\u001b[0m                    nb_few_shots, \n\u001b[1;32m    113\u001b[0m                    verifier, \n\u001b[1;32m    114\u001b[0m                    confidence_checker, \n\u001b[1;32m    115\u001b[0m                    save, \n\u001b[1;32m    116\u001b[0m                    nb_run_by_test ,\n\u001b[1;32m    117\u001b[0m                    with_precision ,\n\u001b[1;32m    118\u001b[0m                    prompt_template,\n\u001b[1;32m    119\u001b[0m                    plus_plus,\n\u001b[1;32m    120\u001b[0m                    dataset_loader \u001b[39m=\u001b[39;49m \u001b[39mlambda\u001b[39;49;00m seed \u001b[39m=\u001b[39;49m \u001b[39m42\u001b[39;49m : dataset_loader(seed \u001b[39m=\u001b[39;49m seed, test_size \u001b[39m=\u001b[39;49m test_size),\n\u001b[1;32m    121\u001b[0m                    tags \u001b[39m=\u001b[39;49m ONTONOTE5_TAGS,\n\u001b[1;32m    122\u001b[0m                    dataset_save_name \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39montonote5\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m/myhome/Master-thesis/llm/LLMModel.py:158\u001b[0m, in \u001b[0;36mLLMModel.classical_test\u001b[0;34m(self, fsts, pts, nb_few_shots, verifier, confidence_checker, save, nb_run_by_test, with_precision, prompt_template, plus_plus, dataset_loader, tags, dataset_save_name)\u001b[0m\n\u001b[1;32m    156\u001b[0m data_train, data_test \u001b[39m=\u001b[39m dataset_loader(seed \u001b[39m=\u001b[39m seed)\n\u001b[1;32m    157\u001b[0m fst\u001b[39m.\u001b[39mset_dataset(data_train)\n\u001b[0;32m--> 158\u001b[0m predictions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minvoke_mulitple(data_test[\u001b[39m'\u001b[39;49m\u001b[39mtext\u001b[39;49m\u001b[39m'\u001b[39;49m], pt, verifier, confidence_checker, tags)\n\u001b[1;32m    159\u001b[0m \u001b[39m# Calculate the elapsed time\u001b[39;00m\n\u001b[1;32m    160\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[0;32m/myhome/Master-thesis/llm/LLMModel.py:72\u001b[0m, in \u001b[0;36mLLMModel.invoke_mulitple\u001b[0;34m(self, sentences, pt, verifier, confidence_checker, tags)\u001b[0m\n\u001b[1;32m     70\u001b[0m all_entities \u001b[39m=\u001b[39m []\n\u001b[1;32m     71\u001b[0m \u001b[39mfor\u001b[39;00m sentence \u001b[39min\u001b[39;00m tqdm(sentences) :\n\u001b[0;32m---> 72\u001b[0m     all_entities\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minvoke(sentence, pt, verifier, confidence_checker, tags)[\u001b[39m0\u001b[39m])\n\u001b[1;32m     73\u001b[0m \u001b[39mreturn\u001b[39;00m all_entities\n",
      "File \u001b[0;32m/myhome/Master-thesis/llm/LLMModel.py:77\u001b[0m, in \u001b[0;36mLLMModel.invoke\u001b[0;34m(self, sentence, pt, verifier, confidence_checker, tags)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minvoke\u001b[39m(\u001b[39mself\u001b[39m, sentence : \u001b[39mstr\u001b[39m, pt : PromptTechnique, verifier : Verifier, confidence_checker : ConfidenceChecker, tags):\n\u001b[0;32m---> 77\u001b[0m     all_entities, response_all\u001b[39m=\u001b[39m pt\u001b[39m.\u001b[39;49mrun_prompt(\u001b[39mself\u001b[39;49m, sentence, verifier, confidence_checker, tags \u001b[39m=\u001b[39;49m tags)\n\u001b[1;32m     78\u001b[0m     \u001b[39mreturn\u001b[39;00m all_entities, response_all\n",
      "File \u001b[0;32m/myhome/Master-thesis/ner/llm_ner/prompt_techniques/pt_discussion.py:39\u001b[0m, in \u001b[0;36mPT_OutputList.run_prompt\u001b[0;34m(self, llm, sentence, verifier, confidence_checker, tags)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_prompt\u001b[39m(\u001b[39mself\u001b[39m, llm : \u001b[39m\"\u001b[39m\u001b[39mLLMModel\u001b[39m\u001b[39m\"\u001b[39m, \n\u001b[1;32m     35\u001b[0m                sentence : \u001b[39mstr\u001b[39m, \n\u001b[1;32m     36\u001b[0m                verifier : \u001b[39m\"\u001b[39m\u001b[39mVerifier\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \n\u001b[1;32m     37\u001b[0m                confidence_checker : ConfidenceChecker\u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     38\u001b[0m                tags \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mPER\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mORG\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mLOC\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMISC\u001b[39m\u001b[39m'\u001b[39m]) :\n\u001b[0;32m---> 39\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(PT_OutputList, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mrun_prompt(llm, sentence, verifier, confidence_checker, prefix \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39m[\u001b[39;49m\u001b[39m'\u001b[39;49m,tags \u001b[39m=\u001b[39;49m  tags)\n",
      "File \u001b[0;32m/myhome/Master-thesis/ner/llm_ner/prompt_techniques/pt_abstract.py:52\u001b[0m, in \u001b[0;36mPromptTechnique.run_prompt\u001b[0;34m(self, llm, sentence, verifier, confidence_checker, prefix, tags)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_prompt\u001b[39m(\u001b[39mself\u001b[39m, llm : \u001b[39m\"\u001b[39m\u001b[39mLLMModel\u001b[39m\u001b[39m\"\u001b[39m, \n\u001b[1;32m     46\u001b[0m                sentence : \u001b[39mstr\u001b[39m, \n\u001b[1;32m     47\u001b[0m                verifier : \u001b[39m\"\u001b[39m\u001b[39mVerifier\u001b[39m\u001b[39m\"\u001b[39m, \n\u001b[1;32m     48\u001b[0m                confidence_checker : \u001b[39m\"\u001b[39m\u001b[39mConfidenceChecker\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \n\u001b[1;32m     49\u001b[0m                prefix : \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     50\u001b[0m                tags \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mPER\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mORG\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mLOC\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMISC\u001b[39m\u001b[39m'\u001b[39m]) :\n\u001b[1;32m     51\u001b[0m     all_entities, all_responses \u001b[39m=\u001b[39m [], []\n\u001b[0;32m---> 52\u001b[0m     prompts \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_prompts_runnable(sentence, tags)\n\u001b[1;32m     53\u001b[0m     \u001b[39mfor\u001b[39;00m prompt,tag \u001b[39min\u001b[39;00m prompts :\n\u001b[1;32m     54\u001b[0m         \u001b[39mif\u001b[39;00m llm\u001b[39m.\u001b[39mcheck_nb_tokens :\n",
      "File \u001b[0;32m/myhome/Master-thesis/ner/llm_ner/prompt_techniques/pt_discussion.py:30\u001b[0m, in \u001b[0;36mPT_OutputList.get_prompts_runnable\u001b[0;34m(self, sentence, tags)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_prompts_runnable\u001b[39m(\u001b[39mself\u001b[39m, sentence, tags \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m     28\u001b[0m     nearest_neighbors \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfst\u001b[39m.\u001b[39mget_nearest_neighbors(sentence)\n\u001b[1;32m     29\u001b[0m     prompt \u001b[39m=\u001b[39m  \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprompt_template[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__str__\u001b[39m()]\u001b[39m.\u001b[39mformat(sentence \u001b[39m=\u001b[39m sentence,\n\u001b[0;32m---> 30\u001b[0m                                         few_shots \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_few_shots(sentence, [], nearest_neighbors),\n\u001b[1;32m     31\u001b[0m                                         precisions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_precision())\n\u001b[1;32m     32\u001b[0m     \u001b[39mreturn\u001b[39;00m [(prompt, \u001b[39m\"\u001b[39m\u001b[39mNone\u001b[39m\u001b[39m\"\u001b[39m)]\n",
      "File \u001b[0;32m/myhome/Master-thesis/ner/llm_ner/prompt_techniques/pt_abstract.py:83\u001b[0m, in \u001b[0;36mPromptTechnique.get_few_shots\u001b[0;34m(self, sentence, tag, nearest_neighbors)\u001b[0m\n\u001b[1;32m     80\u001b[0m         nearest_neighbors \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_nearest_neighbors(nearest_neighbors, tag)\n\u001b[1;32m     81\u001b[0m         \u001b[39mif\u001b[39;00m nearest_neighbors :\n\u001b[1;32m     82\u001b[0m             \u001b[39mreturn\u001b[39;00m \u001b[39m\"\"\"\u001b[39m\u001b[39m### ASSISTANT : Can you provide me examples ?  \u001b[39m\n\u001b[0;32m---> 83\u001b[0m \u001b[39m### USER : There are examples : \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\"\"\u001b[39m \u001b[39m+\u001b[39m few_shot_prompt(nearest_neighbors)\u001b[39m.\u001b[39;49mformat()\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m     84\u001b[0m         \u001b[39melse\u001b[39;00m : \n\u001b[1;32m     85\u001b[0m             \u001b[39mreturn\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/langchain_core/prompts/few_shot.py:159\u001b[0m, in \u001b[0;36mFewShotPromptTemplate.format\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    156\u001b[0m template \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexample_separator\u001b[39m.\u001b[39mjoin([piece \u001b[39mfor\u001b[39;00m piece \u001b[39min\u001b[39;00m pieces \u001b[39mif\u001b[39;00m piece])\n\u001b[1;32m    158\u001b[0m \u001b[39m# Format the template with the input variables.\u001b[39;00m\n\u001b[0;32m--> 159\u001b[0m \u001b[39mreturn\u001b[39;00m DEFAULT_FORMATTER_MAPPING[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtemplate_format](template, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/string.py:190\u001b[0m, in \u001b[0;36mFormatter.format\u001b[0;34m(self, format_string, *args, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mformat\u001b[39m(\u001b[39mself\u001b[39m, format_string, \u001b[39m/\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 190\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvformat(format_string, args, kwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/langchain_core/utils/formatting.py:29\u001b[0m, in \u001b[0;36mStrictFormatter.vformat\u001b[0;34m(self, format_string, args, kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     25\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     26\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo arguments should be provided, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     27\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39meverything should be passed as keyword arguments.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     28\u001b[0m     )\n\u001b[0;32m---> 29\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mvformat(format_string, args, kwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/string.py:194\u001b[0m, in \u001b[0;36mFormatter.vformat\u001b[0;34m(self, format_string, args, kwargs)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvformat\u001b[39m(\u001b[39mself\u001b[39m, format_string, args, kwargs):\n\u001b[1;32m    193\u001b[0m     used_args \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n\u001b[0;32m--> 194\u001b[0m     result, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_vformat(format_string, args, kwargs, used_args, \u001b[39m2\u001b[39;49m)\n\u001b[1;32m    195\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_unused_args(used_args, args, kwargs)\n\u001b[1;32m    196\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/string.py:234\u001b[0m, in \u001b[0;36mFormatter._vformat\u001b[0;34m(self, format_string, args, kwargs, used_args, recursion_depth, auto_arg_index)\u001b[0m\n\u001b[1;32m    230\u001b[0m     auto_arg_index \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[39m# given the field_name, find the object it references\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \u001b[39m#  and the argument it came from\u001b[39;00m\n\u001b[0;32m--> 234\u001b[0m obj, arg_used \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_field(field_name, args, kwargs)\n\u001b[1;32m    235\u001b[0m used_args\u001b[39m.\u001b[39madd(arg_used)\n\u001b[1;32m    237\u001b[0m \u001b[39m# do any conversion on the resulting object\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/string.py:299\u001b[0m, in \u001b[0;36mFormatter.get_field\u001b[0;34m(self, field_name, args, kwargs)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_field\u001b[39m(\u001b[39mself\u001b[39m, field_name, args, kwargs):\n\u001b[1;32m    297\u001b[0m     first, rest \u001b[39m=\u001b[39m _string\u001b[39m.\u001b[39mformatter_field_name_split(field_name)\n\u001b[0;32m--> 299\u001b[0m     obj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_value(first, args, kwargs)\n\u001b[1;32m    301\u001b[0m     \u001b[39m# loop through the rest of the field_name, doing\u001b[39;00m\n\u001b[1;32m    302\u001b[0m     \u001b[39m#  getattr or getitem as needed\u001b[39;00m\n\u001b[1;32m    303\u001b[0m     \u001b[39mfor\u001b[39;00m is_attr, i \u001b[39min\u001b[39;00m rest:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/string.py:256\u001b[0m, in \u001b[0;36mFormatter.get_value\u001b[0;34m(self, key, args, kwargs)\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[39mreturn\u001b[39;00m args[key]\n\u001b[1;32m    255\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 256\u001b[0m     \u001b[39mreturn\u001b[39;00m kwargs[key]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'is'"
     ]
    }
   ],
   "source": [
    "## Impact of few_shots\n",
    "from llm.LLMModel import *\n",
    "from ner.llm_ner.prompt_techniques.pt_abstract import PromptTechnique\n",
    "from ner.llm_ner.prompt_techniques.pt_discussion import PT_OutputList\n",
    "from ner.llm_ner.prompt_techniques.pt_gpt_ner import PT_GPT_NER\n",
    "from ner.llm_ner.prompt_techniques.pt_wrapper import PT_Wrapper\n",
    "from ner.llm_ner.prompt_techniques.pt_multi_pt import PT_2Time_Tagger\n",
    "from ner.llm_ner.few_shots_techniques import *\n",
    "from ner.llm_ner.prompts import *\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "model = MistralAI()\n",
    "plus_plus = True\n",
    "pts = [\n",
    "       # PT_GPT_NER, \n",
    "       PT_OutputList, \n",
    "       PT_Wrapper, \n",
    "       # PT_2Time_Tagger,\n",
    "       # PT_Filing\n",
    "       ]\n",
    "results, results_df = model.classical_test_ontonote5(pts = pts, fsts = [FST_Sentence], nb_few_shots=[0,3,5,10,15,30], nb_run_by_test=3, plus_plus= plus_plus, test_size = 100)\n",
    "\n",
    "for pt in pts :\n",
    "    model.load_finetuned_model(pt = pt(None), prompt_type_name=\"raw\", nb_samples=2000)\n",
    "    results, results_df = model.classical_test_ontonote5(pts = [pt],fsts = [FST_Sentence], nb_few_shots=[0,3,5,10,15,30] ,nb_run_by_test=3, plus_plus= plus_plus, test_size = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Impact of few_shots\n",
    "from llm.LLMModel import *\n",
    "from ner.llm_ner.prompt_techniques.pt_abstract import PromptTechnique\n",
    "from ner.llm_ner.prompt_techniques.pt_discussion import PT_OutputList\n",
    "from ner.llm_ner.prompt_techniques.pt_gpt_ner import PT_GPT_NER\n",
    "from ner.llm_ner.prompt_techniques.pt_wrapper import PT_Wrapper\n",
    "from ner.llm_ner.prompt_techniques.pt_multi_pt import PT_2Time_Tagger\n",
    "from ner.llm_ner.few_shots_techniques import *\n",
    "from ner.llm_ner.prompts import *\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "model = MistralAI()\n",
    "plus_plus = True\n",
    "pts = [\n",
    "       PT_OutputList, \n",
    "       PT_Wrapper,\n",
    "       ]\n",
    "\n",
    "for pt in pts :\n",
    "    for nb_samples in [1000, 2000, 3000, 4000] :\n",
    "        model.load_finetuned_model(pt = pt(None), prompt_type_name=\"raw\", nb_samples=nb_samples)\n",
    "        results, results_df = model.classical_test_ontonote5(pts = [pt],fsts = [FST_Sentence], nb_few_shots=[0,3] ,nb_run_by_test=3, plus_plus= plus_plus, test_size = 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm.LLMModel import *\n",
    "from ner.llm_ner.prompt_techniques.pt_abstract import PromptTechnique\n",
    "from ner.llm_ner.prompt_techniques.pt_discussion import PT_OutputList\n",
    "from ner.llm_ner.prompt_techniques.pt_gpt_ner import PT_GPT_NER\n",
    "from ner.llm_ner.prompt_techniques.pt_gpt_ner import PT_GPT_NER\n",
    "from ner.llm_ner.prompt_techniques.pt_wrapper import PT_Wrapper\n",
    "from ner.llm_ner.few_shots_techniques import *\n",
    "from ner.llm_ner.ResultInstance import load_all_results, load_result\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_mean</th>\n",
       "      <th>f1_conf_inter</th>\n",
       "      <th>model</th>\n",
       "      <th>noshots</th>\n",
       "      <th>prompt_technique</th>\n",
       "      <th>few_shot_tecnique</th>\n",
       "      <th>nb_few_shots</th>\n",
       "      <th>precision</th>\n",
       "      <th>plus_plus</th>\n",
       "      <th>verifier</th>\n",
       "      <th>len_data_train</th>\n",
       "      <th>len_data_test</th>\n",
       "      <th>nb_test_run</th>\n",
       "      <th>confidence_interval</th>\n",
       "      <th>distribution_used</th>\n",
       "      <th>precision_mean</th>\n",
       "      <th>precision_conf_inter</th>\n",
       "      <th>recall_mean</th>\n",
       "      <th>recall_conf_inter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.081</td>\n",
       "      <td>(nan, nan)</td>\n",
       "      <td>chat-gpt-3.5</td>\n",
       "      <td>False</td>\n",
       "      <td>discussion</td>\n",
       "      <td>no-shots</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>1488</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>Student</td>\n",
       "      <td>0.422</td>\n",
       "      <td>(nan, nan)</td>\n",
       "      <td>0.062</td>\n",
       "      <td>(nan, nan)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.224</td>\n",
       "      <td>(nan, nan)</td>\n",
       "      <td>chat-gpt-3.5</td>\n",
       "      <td>False</td>\n",
       "      <td>discussion</td>\n",
       "      <td>sentence</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>1488</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>Student</td>\n",
       "      <td>0.431</td>\n",
       "      <td>(nan, nan)</td>\n",
       "      <td>0.169</td>\n",
       "      <td>(nan, nan)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.159</td>\n",
       "      <td>(nan, nan)</td>\n",
       "      <td>chat-gpt-3.5</td>\n",
       "      <td>False</td>\n",
       "      <td>discussion</td>\n",
       "      <td>sentence</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>1488</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>Student</td>\n",
       "      <td>0.386</td>\n",
       "      <td>(nan, nan)</td>\n",
       "      <td>0.118</td>\n",
       "      <td>(nan, nan)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000</td>\n",
       "      <td>(nan, nan)</td>\n",
       "      <td>chat-gpt-3.5</td>\n",
       "      <td>False</td>\n",
       "      <td>filing</td>\n",
       "      <td>sentence</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>1488</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>Student</td>\n",
       "      <td>0.000</td>\n",
       "      <td>(nan, nan)</td>\n",
       "      <td>0.000</td>\n",
       "      <td>(nan, nan)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>(nan, nan)</td>\n",
       "      <td>chat-gpt-3.5</td>\n",
       "      <td>False</td>\n",
       "      <td>filing</td>\n",
       "      <td>sentence</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>1488</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>Student</td>\n",
       "      <td>0.000</td>\n",
       "      <td>(nan, nan)</td>\n",
       "      <td>0.000</td>\n",
       "      <td>(nan, nan)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.351</td>\n",
       "      <td>(nan, nan)</td>\n",
       "      <td>chat-gpt-3.5</td>\n",
       "      <td>False</td>\n",
       "      <td>wrapper</td>\n",
       "      <td>no-shots</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>1488</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>Student</td>\n",
       "      <td>0.383</td>\n",
       "      <td>(nan, nan)</td>\n",
       "      <td>0.326</td>\n",
       "      <td>(nan, nan)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.510</td>\n",
       "      <td>(nan, nan)</td>\n",
       "      <td>chat-gpt-3.5</td>\n",
       "      <td>False</td>\n",
       "      <td>wrapper</td>\n",
       "      <td>sentence</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>1488</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>Student</td>\n",
       "      <td>0.568</td>\n",
       "      <td>(nan, nan)</td>\n",
       "      <td>0.498</td>\n",
       "      <td>(nan, nan)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.526</td>\n",
       "      <td>(nan, nan)</td>\n",
       "      <td>chat-gpt-3.5</td>\n",
       "      <td>False</td>\n",
       "      <td>wrapper</td>\n",
       "      <td>sentence</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>1488</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>Student</td>\n",
       "      <td>0.609</td>\n",
       "      <td>(nan, nan)</td>\n",
       "      <td>0.529</td>\n",
       "      <td>(nan, nan)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f1_mean f1_conf_inter         model  noshots prompt_technique  \\\n",
       "2    0.081    (nan, nan)  chat-gpt-3.5    False       discussion   \n",
       "4    0.224    (nan, nan)  chat-gpt-3.5    False       discussion   \n",
       "3    0.159    (nan, nan)  chat-gpt-3.5    False       discussion   \n",
       "1    0.000    (nan, nan)  chat-gpt-3.5    False           filing   \n",
       "0    0.000    (nan, nan)  chat-gpt-3.5    False           filing   \n",
       "5    0.351    (nan, nan)  chat-gpt-3.5    False          wrapper   \n",
       "7    0.510    (nan, nan)  chat-gpt-3.5    False          wrapper   \n",
       "6    0.526    (nan, nan)  chat-gpt-3.5    False          wrapper   \n",
       "\n",
       "  few_shot_tecnique  nb_few_shots precision  plus_plus verifier  \\\n",
       "2          no-shots             0       100       True     None   \n",
       "4          sentence             3       100       True     None   \n",
       "3          sentence            10       100       True     None   \n",
       "1          sentence             3       100       True     None   \n",
       "0          sentence            10       100       True     None   \n",
       "5          no-shots             0       100       True     None   \n",
       "7          sentence             3       100       True     None   \n",
       "6          sentence            10       100       True     None   \n",
       "\n",
       "   len_data_train  len_data_test  nb_test_run  confidence_interval  \\\n",
       "2            1488            100            1                 0.95   \n",
       "4            1488            100            1                 0.95   \n",
       "3            1488            100            1                 0.95   \n",
       "1            1488            100            1                 0.95   \n",
       "0            1488            100            1                 0.95   \n",
       "5            1488            100            1                 0.95   \n",
       "7            1488            100            1                 0.95   \n",
       "6            1488            100            1                 0.95   \n",
       "\n",
       "  distribution_used  precision_mean precision_conf_inter  recall_mean  \\\n",
       "2           Student           0.422           (nan, nan)        0.062   \n",
       "4           Student           0.431           (nan, nan)        0.169   \n",
       "3           Student           0.386           (nan, nan)        0.118   \n",
       "1           Student           0.000           (nan, nan)        0.000   \n",
       "0           Student           0.000           (nan, nan)        0.000   \n",
       "5           Student           0.383           (nan, nan)        0.326   \n",
       "7           Student           0.568           (nan, nan)        0.498   \n",
       "6           Student           0.609           (nan, nan)        0.529   \n",
       "\n",
       "  recall_conf_inter  \n",
       "2        (nan, nan)  \n",
       "4        (nan, nan)  \n",
       "3        (nan, nan)  \n",
       "1        (nan, nan)  \n",
       "0        (nan, nan)  \n",
       "5        (nan, nan)  \n",
       "7        (nan, nan)  \n",
       "6        (nan, nan)  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = load_all_results(root_directory = \"ner/saves/results/conll2003_cleaned/chat-gpt-3.5/\")\n",
    "df_results[0].sort_values(['prompt_technique', 'nb_few_shots'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[['Livshits', 'PER']]\n",
      "[('Livshits', 'PER')]\n",
      "--------------------------------------------\n",
      "1\n",
      "[['Newmont-Santa Fe', 'MISC']]\n",
      "[('Newmont-Santa Fe', 'organisation')]\n",
      "--------------------------------------------\n",
      "2\n",
      "[['Australia', 'LOC'], ['Sydney Cricket Ground', 'LOC'], ['Lara', 'PER']]\n",
      "[('Australia', 'LOC'), ('Sydney Cricket Ground', 'LOC'), ('Lara', 'PER')]\n",
      "--------------------------------------------\n",
      "3\n",
      "[['NYMEX', 'ORG'], ['Henry Hub', 'LOC'], ['National Weather Service', 'ORG']]\n",
      "[('NYMEX', 'organisation'), ('Henry Hub', 'LOC'), ('National Weather Service', 'organisation')]\n",
      "--------------------------------------------\n",
      "4\n",
      "[['Lanarkshire', 'LOC']]\n",
      "[('Lanarkshire county', 'LOC')]\n",
      "--------------------------------------------\n",
      "5\n",
      "[['Lahd', 'PER'], ['Beirut', 'LOC'], ['Lebanese', 'MISC'], ['Israel', 'LOC']]\n",
      "[('Lahd', 'PER'), ('Beirut', 'LOC'), ('Lebanese army', 'organisation'), ('Israel', 'LOC')]\n",
      "--------------------------------------------\n",
      "6\n",
      "[]\n",
      "[]\n",
      "--------------------------------------------\n",
      "7\n",
      "[['Czech', 'LOC'], ['Vaclav Havel', 'PER']]\n",
      "[('Vaclav Havel', 'PER')]\n",
      "--------------------------------------------\n",
      "8\n",
      "[['Santa Fe', 'ORG'], ['Nevada', 'LOC'], ['California', 'LOC'], ['Montana', 'LOC'], ['Canada', 'LOC'], ['Brazil', 'LOC'], ['Australia', 'LOC'], ['Chile', 'LOC'], ['Kazakstan', 'LOC'], ['Mexico', 'LOC'], ['Ghana', 'LOC']]\n",
      "[('Santa Fe', 'LOC'), ('Nevada', 'LOC'), ('California', 'LOC'), ('Montana', 'LOC'), ('Canada', 'LOC'), ('Brazil', 'LOC'), ('Australia', 'LOC'), ('Chile', 'LOC'), ('Kazakstan', 'LOC'), ('Mexico', 'LOC'), ('Ghana', 'LOC')]\n",
      "--------------------------------------------\n",
      "9\n",
      "[['Spain', 'LOC']]\n",
      "[('Spain', 'MISC')]\n",
      "--------------------------------------------\n",
      "10\n",
      "[['Darrel Voeks', 'PER'], ['Outagmie County', 'LOC'], ['Dennis Luebke', 'PER']]\n",
      "[('Darrel Voeks', 'PER'), ('Dennis Luebke', 'PER')]\n",
      "--------------------------------------------\n",
      "11\n",
      "[['SHEFFIELD SHIELD', 'MISC']]\n",
      "[('SHEFFIELD SHIELD', 'ORG')]\n",
      "--------------------------------------------\n",
      "12\n",
      "[['German', 'MISC'], ['Santa', 'PER']]\n",
      "[('German', 'MISC'), ('Santa', 'PER'), ('bank', 'ORG')]\n",
      "--------------------------------------------\n",
      "13\n",
      "[['Italians', 'MISC'], ['Italia', 'LOC']]\n",
      "[('Italians', 'MISC')]\n",
      "--------------------------------------------\n",
      "14\n",
      "[['United Arab Emirates', 'LOC'], ['Kuwait', 'LOC']]\n",
      "[('United Arab Emirates', 'LOC'), ('Kuwait', 'LOC')]\n",
      "--------------------------------------------\n",
      "15\n",
      "[['Rottweilers', 'MISC'], ['German shepherds', 'MISC'], ['cocker spaniels', 'MISC'], ['Dalmatians', 'MISC']]\n",
      "[]\n",
      "--------------------------------------------\n",
      "16\n",
      "[]\n",
      "[]\n",
      "--------------------------------------------\n",
      "17\n",
      "[['Peters', 'PER'], ['Labour', 'ORG'], ['National', 'ORG']]\n",
      "[('Peters', 'PER'), ('Labour', 'organisation'), ('National', 'organisation')]\n",
      "--------------------------------------------\n",
      "18\n",
      "[]\n",
      "[]\n",
      "--------------------------------------------\n",
      "19\n",
      "[['Internet', 'MISC']]\n",
      "[('Internet', 'MISC')]\n",
      "--------------------------------------------\n",
      "20\n",
      "[['Turkey', 'LOC'], ['Syrian', 'MISC']]\n",
      "[('Turkey', 'LOC'), ('Syrian', 'LOC')]\n",
      "--------------------------------------------\n",
      "21\n",
      "[['Rashid', 'PER'], ['Greece', 'LOC']]\n",
      "[('Rashid', 'PER'), ('Greece', 'LOC')]\n",
      "--------------------------------------------\n",
      "22\n",
      "[['Maurice Baril', 'PER'], ['Nairobi', 'LOC'], ['Goma', 'LOC']]\n",
      "[('Maurice Baril', 'PER'), ('Nairobi', 'LOC'), ('Goma', 'LOC')]\n",
      "--------------------------------------------\n",
      "23\n",
      "[['Australia', 'LOC'], ['Barbarians', 'ORG'], ['European', 'MISC']]\n",
      "[('Australia', 'LOC'), ('Barbarians', 'organisation'), ('European', 'MISC')]\n",
      "--------------------------------------------\n",
      "24\n",
      "[['Patasse', 'PER']]\n",
      "[('Patasse', 'PER')]\n",
      "--------------------------------------------\n",
      "25\n",
      "[['Weah', 'PER'], ['Milan', 'ORG'], ['Rosenborg', 'ORG'], ['Norway', 'LOC']]\n",
      "[('Weah', 'PER'), ('Milan', 'organisation'), ('Rosenborg', 'LOC'), ('Norway', 'LOC')]\n",
      "--------------------------------------------\n",
      "26\n",
      "[['SCHULZ', 'PER'], ['RIBALTA', 'PER'], ['IBF', 'ORG']]\n",
      "[('BOXING', 'MISC'), ('SCHULZ', 'PER'), ('RIBALTA', 'PER'), ('IBF', 'organisation')]\n",
      "--------------------------------------------\n",
      "27\n",
      "[['Brett Liddle', 'PER'], ['Hugh Baiocchi', 'PER'], ['Adilson da Silva', 'PER'], ['Brazil', 'LOC'], ['Sammy Daniels', 'PER']]\n",
      "[('Brett Liddle', 'PER'), ('Hugh Baiocchi', 'PER'), ('Adilson da Silva', 'PER'), ('Brazil', 'LOC'), ('Sammy Daniels', 'PER')]\n",
      "--------------------------------------------\n",
      "28\n",
      "[]\n",
      "[]\n",
      "--------------------------------------------\n",
      "29\n",
      "[['Voeks', 'PER']]\n",
      "[('Voeks', 'PER')]\n",
      "--------------------------------------------\n",
      "30\n",
      "[]\n",
      "[('78 people', 'ORG'), ('64 confirmed cases', 'ORG')]\n",
      "--------------------------------------------\n",
      "31\n",
      "[]\n",
      "[]\n",
      "--------------------------------------------\n",
      "32\n",
      "[]\n",
      "[]\n",
      "--------------------------------------------\n",
      "33\n",
      "[['African', 'MISC']]\n",
      "[('African', 'MISC')]\n",
      "--------------------------------------------\n",
      "34\n",
      "[['Zimbabwe Open', 'MISC'], ['South African', 'MISC']]\n",
      "[('Zimbabwe Open', 'MISC'), ('South African', 'MISC')]\n",
      "--------------------------------------------\n",
      "35\n",
      "[['Pace', 'PER'], ['Ohio State', 'ORG'], ['Rose Bowl', 'MISC'], ['Arizona State', 'ORG']]\n",
      "[('Pace', 'PER'), ('junior', 'MISC'), ('Ohio State', 'organisation'), ('Rose Bowl', 'MISC'), ('Arizona State', 'organisation')]\n",
      "--------------------------------------------\n",
      "36\n",
      "[]\n",
      "[('one point', 'MISC'), ('one game', 'MISC')]\n",
      "--------------------------------------------\n",
      "37\n",
      "[['TEMBAU DENPASAR', 'LOC'], ['Bali', 'LOC']]\n",
      "[('TEMBAU DENPASAR', 'LOC'), ('Bali', 'LOC')]\n",
      "--------------------------------------------\n",
      "38\n",
      "[['Michael Cornwell', 'PER'], ['Glencoe Animal Hospital', 'ORG'], ['Columbus', 'LOC'], ['Ohio', 'LOC'], ['American Veterinary Medical Association', 'ORG']]\n",
      "[('Michael Cornwell', 'PER'), ('Glencoe Animal Hospital', 'ORG'), ('Columbus, Ohio', 'LOC'), ('American Veterinary Medical Association', 'ORG')]\n",
      "--------------------------------------------\n",
      "39\n",
      "[['Burmese', 'MISC'], ['Ranyon ( Rangoon ) University', 'ORG']]\n",
      "[('Burmese', 'MISC'), ('Ranyon', 'LOC'), ('Rangoon', 'LOC')]\n",
      "--------------------------------------------\n",
      "40\n",
      "[['Frankfurt', 'LOC']]\n",
      "[('1.5338 marks', 'MISC'), ('Frankfurt', 'LOC'), ('1.5607 marks', 'MISC')]\n",
      "--------------------------------------------\n",
      "41\n",
      "[['Saeed Anwar', 'PER']]\n",
      "[('Saeed Anwar', 'PER')]\n",
      "--------------------------------------------\n",
      "42\n",
      "[['U.S.', 'LOC'], ['St. Louis', 'LOC']]\n",
      "[('U.S.', 'LOC'), ('St. Louis Merchants Exchange', 'ORG')]\n",
      "--------------------------------------------\n",
      "43\n",
      "[['Frenchman', 'MISC'], ['Patrick Vieira', 'PER'], ['English', 'MISC'], ['Arsenal', 'ORG'], ['Derby', 'ORG']]\n",
      "[('Patrick Vieira', 'PER'), ('Arsenal', 'organisation'), ('Derby', 'organisation')]\n",
      "--------------------------------------------\n",
      "44\n",
      "[['Belgian', 'MISC'], ['Antwerp', 'ORG']]\n",
      "[('Belgian francs', 'MISC'), (\"public prosecutor's office\", 'organisation'), ('Antwerp', 'organisation')]\n",
      "--------------------------------------------\n",
      "45\n",
      "[]\n",
      "[]\n",
      "--------------------------------------------\n",
      "46\n",
      "[]\n",
      "[]\n",
      "--------------------------------------------\n",
      "47\n",
      "[['Zieleniec', 'PER'], ['Klaus', 'PER'], ['post-Communist', 'MISC']]\n",
      "[('Zieleniec', 'PER'), ('Klaus', 'PER')]\n",
      "--------------------------------------------\n",
      "48\n",
      "[['Pakistan', 'LOC'], ['Australia', 'LOC'], ['World Series', 'MISC']]\n",
      "[('Pakistan', 'PER'), ('Australia', 'LOC'), ('World Series', 'MISC')]\n",
      "--------------------------------------------\n",
      "49\n",
      "[['Bre-X', 'ORG'], ['Barrick', 'ORG']]\n",
      "[('Bre-X', 'organisation'), ('Barrick', 'organisation')]\n",
      "--------------------------------------------\n",
      "50\n",
      "[['Gladishiva', 'PER'], ['Lillehammer', 'LOC'], ['Winter Olympics', 'MISC'], ['World Championships', 'MISC']]\n",
      "[('Other Facts', 'MISC')]\n",
      "--------------------------------------------\n",
      "51\n",
      "[['Doetinchem', 'ORG'], ['The Super Peasants', 'ORG']]\n",
      "[('Doetinchem', 'LOC')]\n",
      "--------------------------------------------\n",
      "52\n",
      "[]\n",
      "[]\n",
      "--------------------------------------------\n",
      "53\n",
      "[['Mexican', 'MISC']]\n",
      "[]\n",
      "--------------------------------------------\n",
      "54\n",
      "[]\n",
      "[]\n",
      "--------------------------------------------\n",
      "55\n",
      "[['Mexico', 'LOC'], ['Greenspan', 'PER']]\n",
      "[('Mexico', 'MISC'), ('Greenspan', 'PER')]\n",
      "--------------------------------------------\n",
      "56\n",
      "[]\n",
      "[]\n",
      "--------------------------------------------\n",
      "57\n",
      "[]\n",
      "[]\n",
      "--------------------------------------------\n",
      "58\n",
      "[]\n",
      "[('people', 'PER')]\n",
      "--------------------------------------------\n",
      "59\n",
      "[['Kurdish', 'MISC'], ['Kurdistan Workers Party', 'ORG'], ['PKK', 'ORG']]\n",
      "[('Kurdish', 'MISC'), ('Kurdistan Workers Party', 'organisation'), ('PKK', 'organisation')]\n",
      "--------------------------------------------\n",
      "60\n",
      "[['Manchester United', 'ORG']]\n",
      "[('Manchester United', 'PER')]\n",
      "--------------------------------------------\n",
      "61\n",
      "[['Indian', 'MISC'], ['Moslem', 'MISC'], ['Bombay', 'LOC']]\n",
      "[('Moslem', 'MISC'), ('Bombay', 'LOC')]\n",
      "--------------------------------------------\n",
      "62\n",
      "[['Buza', 'PER'], ['Gjonaj', 'PER']]\n",
      "[('Buza', 'PER'), ('Gjonaj', 'PER')]\n",
      "--------------------------------------------\n",
      "63\n",
      "[['United States', 'LOC']]\n",
      "[('United States', 'LOC'), ('humans', 'MISC')]\n",
      "--------------------------------------------\n",
      "64\n",
      "[['ENGLISHMAN', 'MISC'], ['CHARLTON', 'PER'], ['IRISHMAN', 'MISC']]\n",
      "[('SOCCER', 'PER'), ('ENGLISHMAN', 'MISC'), ('CHARLTON', 'PER'), ('IRISHMAN', 'MISC')]\n",
      "--------------------------------------------\n",
      "65\n",
      "[['Eagles', 'ORG']]\n",
      "[('Eagles', 'organisation')]\n",
      "--------------------------------------------\n",
      "66\n",
      "[['Rosati', 'PER'], ['Warsaw', 'LOC'], ['Switzerland', 'LOC'], ['Swiss', 'MISC'], ['Soviet-imposed', 'MISC'], ['World War Two', 'MISC']]\n",
      "[('Rosati', 'PER'), ('Warsaw', 'LOC'), ('Switzerland', 'LOC'), ('Soviet-imposed communists authorities', 'MISC'), ('World War Two', 'MISC')]\n",
      "--------------------------------------------\n",
      "67\n",
      "[]\n",
      "[(\"girl's father\", 'PER')]\n",
      "--------------------------------------------\n",
      "68\n",
      "[['Jones', 'PER'], ['Tasmanian', 'MISC'], ['David Boon', 'PER'], ['Shaun Young', 'PER'], ['Michael DiVenuto', 'PER']]\n",
      "[('Jones', 'PER'), ('Tasmanian', 'organisation'), ('David Boon', 'PER'), ('Shaun Young', 'PER'), ('Michael DiVenuto', 'PER')]\n",
      "--------------------------------------------\n",
      "69\n",
      "[]\n",
      "[]\n",
      "--------------------------------------------\n",
      "70\n",
      "[['New York', 'LOC']]\n",
      "[('New York', 'LOC')]\n",
      "--------------------------------------------\n",
      "71\n",
      "[['Frederick', 'PER']]\n",
      "[('Frederick', 'PER')]\n",
      "--------------------------------------------\n",
      "72\n",
      "[['Aly Ashour', 'PER'], ['Mohamed Ouda', 'PER']]\n",
      "[('Aly Ashour', 'PER'), ('Mohamed Ouda', 'PER')]\n",
      "--------------------------------------------\n",
      "73\n",
      "[]\n",
      "[]\n",
      "--------------------------------------------\n",
      "74\n",
      "[['Hyundai Heavy', 'ORG'], ['Koram Bank', 'ORG']]\n",
      "[('Hyundai Heavy', 'organisation'), ('Koram Bank', 'organisation')]\n",
      "--------------------------------------------\n",
      "75\n",
      "[]\n",
      "[]\n",
      "--------------------------------------------\n",
      "76\n",
      "[['CAN', 'LOC'], ['U.S.', 'LOC']]\n",
      "[('CAN', 'MISC'), ('U.S. DOLLAR', 'MISC')]\n",
      "--------------------------------------------\n",
      "77\n",
      "[['Santa Fe', 'ORG'], ['Nevada', 'LOC'], ['Newmont', 'ORG']]\n",
      "[('Santa Fe', 'organisation'), ('Nevada', 'LOC'), ('Newmont', 'organisation')]\n",
      "--------------------------------------------\n",
      "78\n",
      "[['Zahoor Elahi', 'PER'], ['Cairns', 'PER']]\n",
      "[('Zahoor Elahi', 'PER'), ('Cairns', 'PER')]\n",
      "--------------------------------------------\n",
      "79\n",
      "[]\n",
      "[]\n",
      "--------------------------------------------\n",
      "80\n",
      "[['Fife', 'ORG'], ['Partick', 'ORG'], ['Stirling', 'ORG'], ['St Mirren', 'ORG']]\n",
      "[('Fife', 'LOC'), ('Partick', 'organisation'), ('Stirling', 'LOC'), ('St Mirren', 'organisation')]\n",
      "--------------------------------------------\n",
      "81\n",
      "[['Winters', 'PER'], ['Dundee United', 'ORG'], ['Paolo Di Canio', 'PER'], ['Celtic', 'ORG']]\n",
      "[('Dundee United', 'ORG'), ('Celtic', 'ORG')]\n",
      "--------------------------------------------\n",
      "82\n",
      "[['Blanc', 'PER'], ['World Cup', 'MISC'], ['Foucras', 'PER'], ['World Cup', 'MISC']]\n",
      "[('Blanc', 'PER'), ('Foucras', 'PER')]\n",
      "--------------------------------------------\n",
      "83\n",
      "[]\n",
      "[]\n",
      "--------------------------------------------\n",
      "84\n",
      "[['TASR', 'ORG']]\n",
      "[('terrorism', 'MISC'), ('wife', 'PER'), ('children', 'PER'), ('TASR', 'ORG')]\n",
      "--------------------------------------------\n",
      "85\n",
      "[]\n",
      "[]\n",
      "--------------------------------------------\n",
      "86\n",
      "[['TASR', 'ORG'], ['Frantisek Gaulieder', 'PER'], ['Galanta', 'LOC'], ['Slovakia', 'LOC']]\n",
      "[('Frantisek Gaulieder', 'PER'), ('Galanta', 'LOC'), ('Slovakia', 'LOC')]\n",
      "--------------------------------------------\n",
      "87\n",
      "[]\n",
      "[]\n",
      "--------------------------------------------\n",
      "88\n",
      "[]\n",
      "[('played', 'MISC'), ('won', 'MISC'), ('drawn', 'MISC'), ('lost', 'MISC'), ('goals', 'MISC')]\n",
      "--------------------------------------------\n",
      "89\n",
      "[['OPEC', 'ORG'], ['OPECNA', 'ORG'], ['OPEC', 'ORG']]\n",
      "[('OPEC', 'ORG'), ('OPECNA', 'ORG'), ('OPEC', 'ORG')]\n",
      "--------------------------------------------\n",
      "90\n",
      "[]\n",
      "[]\n",
      "--------------------------------------------\n",
      "91\n",
      "[['Alatas', 'PER'], ['Nobel Peace Prize', 'MISC'], ['Belo', 'PER']]\n",
      "[('Alatas', 'PER'), ('Nobel Peace Prize', 'MISC'), ('Belo', 'PER')]\n",
      "--------------------------------------------\n",
      "92\n",
      "[['Tampico', 'LOC'], ['Kenda', 'MISC']]\n",
      "[('Tampico', 'LOC'), ('Kenda', 'PER')]\n",
      "--------------------------------------------\n",
      "93\n",
      "[['Iran Sabr', 'MISC'], ['Iran', 'LOC']]\n",
      "[('Iran Sabr', 'PER'), ('Iran', 'LOC')]\n",
      "--------------------------------------------\n",
      "94\n",
      "[['Pace', 'PER'], ['Virginia Tech', 'ORG'], ['Cornell Brown', 'PER'], ['Arizona State', 'ORG'], ['Juan Roque', 'PER'], ['Jared Tomich', 'PER'], ['Nebraska', 'ORG']]\n",
      "[('Pace', 'PER'), ('Virginia Tech', 'organisation'), ('Cornell Brown', 'PER'), ('Arizona State', 'organisation'), ('Juan Roque', 'PER'), ('Jared Tomich', 'PER'), ('Nebraska', 'organisation')]\n",
      "--------------------------------------------\n",
      "95\n",
      "[['Dariusz Rosati', 'PER'], ['Poland', 'LOC'], ['Swiss', 'MISC']]\n",
      "[('Foreign Minister Dariusz Rosati', 'PER'), ('Poland', 'LOC'), ('Swiss', 'LOC')]\n",
      "--------------------------------------------\n",
      "96\n",
      "[['Scottish', 'MISC']]\n",
      "[('Scottish premier division', 'MISC'), ('Saturday', 'MISC')]\n",
      "--------------------------------------------\n",
      "97\n",
      "[]\n",
      "[]\n",
      "--------------------------------------------\n",
      "98\n",
      "[]\n",
      "[]\n",
      "--------------------------------------------\n",
      "99\n",
      "[]\n",
      "[('official', 'MISC')]\n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "df_results[1][7].res_insts[0].analyse_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_mean</th>\n",
       "      <th>f1_conf_inter</th>\n",
       "      <th>model</th>\n",
       "      <th>noshots</th>\n",
       "      <th>prompt_technique</th>\n",
       "      <th>few_shot_tecnique</th>\n",
       "      <th>nb_few_shots</th>\n",
       "      <th>precision</th>\n",
       "      <th>plus_plus</th>\n",
       "      <th>verifier</th>\n",
       "      <th>len_data_train</th>\n",
       "      <th>len_data_test</th>\n",
       "      <th>nb_test_run</th>\n",
       "      <th>confidence_interval</th>\n",
       "      <th>distribution_used</th>\n",
       "      <th>precision_mean</th>\n",
       "      <th>precision_conf_inter</th>\n",
       "      <th>recall_mean</th>\n",
       "      <th>recall_conf_inter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.244</td>\n",
       "      <td>(0.244, 0.244)</td>\n",
       "      <td>mistral-7b-v0.1</td>\n",
       "      <td>False</td>\n",
       "      <td>discussion</td>\n",
       "      <td>sentence</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>1303</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>0.95</td>\n",
       "      <td>Student</td>\n",
       "      <td>0.309</td>\n",
       "      <td>(0.309, 0.309)</td>\n",
       "      <td>0.209</td>\n",
       "      <td>(0.209, 0.209)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.238</td>\n",
       "      <td>(0.202, 0.274)</td>\n",
       "      <td>mistral-7b-v0.1</td>\n",
       "      <td>False</td>\n",
       "      <td>discussion</td>\n",
       "      <td>sentence</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>1303</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>0.95</td>\n",
       "      <td>Student</td>\n",
       "      <td>0.320</td>\n",
       "      <td>(0.267, 0.374)</td>\n",
       "      <td>0.200</td>\n",
       "      <td>(0.165, 0.234)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.236</td>\n",
       "      <td>(0.194, 0.277)</td>\n",
       "      <td>mistral-7b-v0.1</td>\n",
       "      <td>False</td>\n",
       "      <td>discussion</td>\n",
       "      <td>sentence</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>1303</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>0.95</td>\n",
       "      <td>Student</td>\n",
       "      <td>0.305</td>\n",
       "      <td>(0.233, 0.376)</td>\n",
       "      <td>0.201</td>\n",
       "      <td>(0.166, 0.236)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.517</td>\n",
       "      <td>(0.470, 0.564)</td>\n",
       "      <td>mistral-7b-v0.1-ft-raw-1000-Q5_0</td>\n",
       "      <td>False</td>\n",
       "      <td>discussion</td>\n",
       "      <td>sentence</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>1303</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>0.95</td>\n",
       "      <td>Student</td>\n",
       "      <td>0.572</td>\n",
       "      <td>(0.504, 0.640)</td>\n",
       "      <td>0.484</td>\n",
       "      <td>(0.444, 0.523)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.281</td>\n",
       "      <td>(0.223, 0.339)</td>\n",
       "      <td>mistral-7b-v0.1-ft-raw-2000-Q5_0</td>\n",
       "      <td>False</td>\n",
       "      <td>discussion</td>\n",
       "      <td>sentence</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>1303</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>0.95</td>\n",
       "      <td>Student</td>\n",
       "      <td>0.328</td>\n",
       "      <td>(0.258, 0.398)</td>\n",
       "      <td>0.261</td>\n",
       "      <td>(0.210, 0.312)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.274</td>\n",
       "      <td>(0.222, 0.326)</td>\n",
       "      <td>mistral-7b-v0.1-ft-raw-2000-Q5_0</td>\n",
       "      <td>False</td>\n",
       "      <td>discussion</td>\n",
       "      <td>sentence</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>1303</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>0.95</td>\n",
       "      <td>Student</td>\n",
       "      <td>0.315</td>\n",
       "      <td>(0.273, 0.357)</td>\n",
       "      <td>0.256</td>\n",
       "      <td>(0.203, 0.310)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.506</td>\n",
       "      <td>(0.477, 0.534)</td>\n",
       "      <td>mistral-7b-v0.1-ft-raw-3000-Q5_0</td>\n",
       "      <td>False</td>\n",
       "      <td>discussion</td>\n",
       "      <td>sentence</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>1303</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>0.95</td>\n",
       "      <td>Student</td>\n",
       "      <td>0.563</td>\n",
       "      <td>(0.526, 0.600)</td>\n",
       "      <td>0.467</td>\n",
       "      <td>(0.410, 0.524)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.540</td>\n",
       "      <td>(0.508, 0.571)</td>\n",
       "      <td>mistral-7b-v0.1-ft-raw-4000-Q5_0</td>\n",
       "      <td>False</td>\n",
       "      <td>discussion</td>\n",
       "      <td>sentence</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>1303</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>0.95</td>\n",
       "      <td>Student</td>\n",
       "      <td>0.601</td>\n",
       "      <td>(0.576, 0.626)</td>\n",
       "      <td>0.499</td>\n",
       "      <td>(0.455, 0.543)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.284</td>\n",
       "      <td>(0.228, 0.339)</td>\n",
       "      <td>mistral-7b-v0.1</td>\n",
       "      <td>False</td>\n",
       "      <td>discussion</td>\n",
       "      <td>sentence</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>1303</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>0.95</td>\n",
       "      <td>Student</td>\n",
       "      <td>0.314</td>\n",
       "      <td>(0.259, 0.370)</td>\n",
       "      <td>0.267</td>\n",
       "      <td>(0.214, 0.319)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.258</td>\n",
       "      <td>(0.207, 0.309)</td>\n",
       "      <td>mistral-7b-v0.1</td>\n",
       "      <td>False</td>\n",
       "      <td>discussion</td>\n",
       "      <td>sentence</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>1303</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>0.95</td>\n",
       "      <td>Student</td>\n",
       "      <td>0.332</td>\n",
       "      <td>(0.245, 0.419)</td>\n",
       "      <td>0.220</td>\n",
       "      <td>(0.186, 0.254)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.539</td>\n",
       "      <td>(0.487, 0.592)</td>\n",
       "      <td>mistral-7b-v0.1-ft-raw-2000-Q5_0</td>\n",
       "      <td>False</td>\n",
       "      <td>discussion</td>\n",
       "      <td>sentence</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>1303</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>0.95</td>\n",
       "      <td>Student</td>\n",
       "      <td>0.559</td>\n",
       "      <td>(0.497, 0.620)</td>\n",
       "      <td>0.528</td>\n",
       "      <td>(0.482, 0.575)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.284</td>\n",
       "      <td>(0.228, 0.339)</td>\n",
       "      <td>mistral-7b-v0.1-ft-raw-2000-Q5_0</td>\n",
       "      <td>False</td>\n",
       "      <td>discussion</td>\n",
       "      <td>sentence</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>1303</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>0.95</td>\n",
       "      <td>Student</td>\n",
       "      <td>0.314</td>\n",
       "      <td>(0.259, 0.370)</td>\n",
       "      <td>0.267</td>\n",
       "      <td>(0.214, 0.319)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.277</td>\n",
       "      <td>(0.220, 0.334)</td>\n",
       "      <td>mistral-7b-v0.1</td>\n",
       "      <td>False</td>\n",
       "      <td>discussion</td>\n",
       "      <td>sentence</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>1303</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>0.95</td>\n",
       "      <td>Student</td>\n",
       "      <td>0.298</td>\n",
       "      <td>(0.234, 0.362)</td>\n",
       "      <td>0.267</td>\n",
       "      <td>(0.215, 0.319)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.236</td>\n",
       "      <td>(0.217, 0.256)</td>\n",
       "      <td>mistral-7b-v0.1</td>\n",
       "      <td>False</td>\n",
       "      <td>discussion</td>\n",
       "      <td>sentence</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>1303</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>0.95</td>\n",
       "      <td>Student</td>\n",
       "      <td>0.300</td>\n",
       "      <td>(0.278, 0.323)</td>\n",
       "      <td>0.202</td>\n",
       "      <td>(0.181, 0.222)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.544</td>\n",
       "      <td>(0.499, 0.589)</td>\n",
       "      <td>mistral-7b-v0.1-ft-raw-2000-Q5_0</td>\n",
       "      <td>False</td>\n",
       "      <td>discussion</td>\n",
       "      <td>sentence</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>1303</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>0.95</td>\n",
       "      <td>Student</td>\n",
       "      <td>0.574</td>\n",
       "      <td>(0.521, 0.627)</td>\n",
       "      <td>0.525</td>\n",
       "      <td>(0.486, 0.565)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.277</td>\n",
       "      <td>(0.220, 0.335)</td>\n",
       "      <td>mistral-7b-v0.1-ft-raw-2000-Q5_0</td>\n",
       "      <td>False</td>\n",
       "      <td>discussion</td>\n",
       "      <td>sentence</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>1303</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>0.95</td>\n",
       "      <td>Student</td>\n",
       "      <td>0.298</td>\n",
       "      <td>(0.234, 0.362)</td>\n",
       "      <td>0.267</td>\n",
       "      <td>(0.216, 0.319)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.249</td>\n",
       "      <td>(0.219, 0.280)</td>\n",
       "      <td>mistral-7b-v0.1</td>\n",
       "      <td>False</td>\n",
       "      <td>discussion</td>\n",
       "      <td>sentence</td>\n",
       "      <td>20</td>\n",
       "      <td>300</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>1303</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>0.95</td>\n",
       "      <td>Student</td>\n",
       "      <td>0.258</td>\n",
       "      <td>(0.240, 0.277)</td>\n",
       "      <td>0.250</td>\n",
       "      <td>(0.213, 0.288)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.249</td>\n",
       "      <td>(0.219, 0.280)</td>\n",
       "      <td>mistral-7b-v0.1-ft-raw-2000-Q5_0</td>\n",
       "      <td>False</td>\n",
       "      <td>discussion</td>\n",
       "      <td>sentence</td>\n",
       "      <td>20</td>\n",
       "      <td>300</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>1303</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>0.95</td>\n",
       "      <td>Student</td>\n",
       "      <td>0.258</td>\n",
       "      <td>(0.240, 0.277)</td>\n",
       "      <td>0.250</td>\n",
       "      <td>(0.213, 0.288)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    f1_mean   f1_conf_inter                             model  noshots  \\\n",
       "20    0.244  (0.244, 0.244)                   mistral-7b-v0.1    False   \n",
       "24    0.238  (0.202, 0.274)                   mistral-7b-v0.1    False   \n",
       "23    0.236  (0.194, 0.277)                   mistral-7b-v0.1    False   \n",
       "1     0.517  (0.470, 0.564)  mistral-7b-v0.1-ft-raw-1000-Q5_0    False   \n",
       "48    0.281  (0.223, 0.339)  mistral-7b-v0.1-ft-raw-2000-Q5_0    False   \n",
       "49    0.274  (0.222, 0.326)  mistral-7b-v0.1-ft-raw-2000-Q5_0    False   \n",
       "63    0.506  (0.477, 0.534)  mistral-7b-v0.1-ft-raw-3000-Q5_0    False   \n",
       "5     0.540  (0.508, 0.571)  mistral-7b-v0.1-ft-raw-4000-Q5_0    False   \n",
       "15    0.284  (0.228, 0.339)                   mistral-7b-v0.1    False   \n",
       "16    0.258  (0.207, 0.309)                   mistral-7b-v0.1    False   \n",
       "42    0.539  (0.487, 0.592)  mistral-7b-v0.1-ft-raw-2000-Q5_0    False   \n",
       "41    0.284  (0.228, 0.339)  mistral-7b-v0.1-ft-raw-2000-Q5_0    False   \n",
       "19    0.277  (0.220, 0.334)                   mistral-7b-v0.1    False   \n",
       "18    0.236  (0.217, 0.256)                   mistral-7b-v0.1    False   \n",
       "44    0.544  (0.499, 0.589)  mistral-7b-v0.1-ft-raw-2000-Q5_0    False   \n",
       "45    0.277  (0.220, 0.335)  mistral-7b-v0.1-ft-raw-2000-Q5_0    False   \n",
       "21    0.249  (0.219, 0.280)                   mistral-7b-v0.1    False   \n",
       "46    0.249  (0.219, 0.280)  mistral-7b-v0.1-ft-raw-2000-Q5_0    False   \n",
       "\n",
       "   prompt_technique few_shot_tecnique  nb_few_shots precision  plus_plus  \\\n",
       "20       discussion          sentence             3       500      False   \n",
       "24       discussion          sentence             3       300       True   \n",
       "23       discussion          sentence             3       300      False   \n",
       "1        discussion          sentence             3       300       True   \n",
       "48       discussion          sentence             3       300      False   \n",
       "49       discussion          sentence             3       300       True   \n",
       "63       discussion          sentence             3       300       True   \n",
       "5        discussion          sentence             3       300       True   \n",
       "15       discussion          sentence             5       300      False   \n",
       "16       discussion          sentence             5       300       True   \n",
       "42       discussion          sentence             5       300       True   \n",
       "41       discussion          sentence             5       300      False   \n",
       "19       discussion          sentence            10       300      False   \n",
       "18       discussion          sentence            10       300       True   \n",
       "44       discussion          sentence            10       300       True   \n",
       "45       discussion          sentence            10       300      False   \n",
       "21       discussion          sentence            20       300      False   \n",
       "46       discussion          sentence            20       300      False   \n",
       "\n",
       "   verifier  len_data_train  len_data_test  nb_test_run  confidence_interval  \\\n",
       "20     None            1303            100            5                 0.95   \n",
       "24     None            1303            100            3                 0.95   \n",
       "23     None            1303            100            3                 0.95   \n",
       "1      None            1303            100            3                 0.95   \n",
       "48     None            1303            100            3                 0.95   \n",
       "49     None            1303            100            3                 0.95   \n",
       "63     None            1303            100            3                 0.95   \n",
       "5      None            1303            100            3                 0.95   \n",
       "15     None            1303            100            3                 0.95   \n",
       "16     None            1303            100            3                 0.95   \n",
       "42     None            1303            100            3                 0.95   \n",
       "41     None            1303            100            3                 0.95   \n",
       "19     None            1303            100            3                 0.95   \n",
       "18     None            1303            100            3                 0.95   \n",
       "44     None            1303            100            3                 0.95   \n",
       "45     None            1303            100            3                 0.95   \n",
       "21     None            1303            100            3                 0.95   \n",
       "46     None            1303            100            3                 0.95   \n",
       "\n",
       "   distribution_used  precision_mean precision_conf_inter  recall_mean  \\\n",
       "20           Student           0.309       (0.309, 0.309)        0.209   \n",
       "24           Student           0.320       (0.267, 0.374)        0.200   \n",
       "23           Student           0.305       (0.233, 0.376)        0.201   \n",
       "1            Student           0.572       (0.504, 0.640)        0.484   \n",
       "48           Student           0.328       (0.258, 0.398)        0.261   \n",
       "49           Student           0.315       (0.273, 0.357)        0.256   \n",
       "63           Student           0.563       (0.526, 0.600)        0.467   \n",
       "5            Student           0.601       (0.576, 0.626)        0.499   \n",
       "15           Student           0.314       (0.259, 0.370)        0.267   \n",
       "16           Student           0.332       (0.245, 0.419)        0.220   \n",
       "42           Student           0.559       (0.497, 0.620)        0.528   \n",
       "41           Student           0.314       (0.259, 0.370)        0.267   \n",
       "19           Student           0.298       (0.234, 0.362)        0.267   \n",
       "18           Student           0.300       (0.278, 0.323)        0.202   \n",
       "44           Student           0.574       (0.521, 0.627)        0.525   \n",
       "45           Student           0.298       (0.234, 0.362)        0.267   \n",
       "21           Student           0.258       (0.240, 0.277)        0.250   \n",
       "46           Student           0.258       (0.240, 0.277)        0.250   \n",
       "\n",
       "   recall_conf_inter  \n",
       "20    (0.209, 0.209)  \n",
       "24    (0.165, 0.234)  \n",
       "23    (0.166, 0.236)  \n",
       "1     (0.444, 0.523)  \n",
       "48    (0.210, 0.312)  \n",
       "49    (0.203, 0.310)  \n",
       "63    (0.410, 0.524)  \n",
       "5     (0.455, 0.543)  \n",
       "15    (0.214, 0.319)  \n",
       "16    (0.186, 0.254)  \n",
       "42    (0.482, 0.575)  \n",
       "41    (0.214, 0.319)  \n",
       "19    (0.215, 0.319)  \n",
       "18    (0.181, 0.222)  \n",
       "44    (0.486, 0.565)  \n",
       "45    (0.216, 0.319)  \n",
       "21    (0.213, 0.288)  \n",
       "46    (0.213, 0.288)  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = load_all_results(root_directory = \"ner/saves/results/ontonote5/\")\n",
    "df_results = df_results[df_results['prompt_technique'] == 'discussion']\n",
    "df_results = df_results[df_results['few_shot_tecnique'] == 'sentence']\n",
    "df_results.sort_values(['nb_few_shots', 'model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8826/2272134630.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_res['tech_name'] = df_res.apply(lambda row :f\"With {row['nb_few_shots']} few_shots {'and ++' if row['plus_plus']  else ''}\", axis = 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_mean</th>\n",
       "      <th>f1_conf_inter</th>\n",
       "      <th>prompt_technique</th>\n",
       "      <th>few_shot_tecnique</th>\n",
       "      <th>nb_few_shots</th>\n",
       "      <th>precision</th>\n",
       "      <th>plus_plus</th>\n",
       "      <th>tech_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.323</td>\n",
       "      <td>(0.297, 0.350)</td>\n",
       "      <td>wrapper</td>\n",
       "      <td>sentence</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>True</td>\n",
       "      <td>With 3 few_shots and ++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.321</td>\n",
       "      <td>(0.275, 0.367)</td>\n",
       "      <td>wrapper</td>\n",
       "      <td>sentence</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>False</td>\n",
       "      <td>With 3 few_shots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.246</td>\n",
       "      <td>(0.216, 0.275)</td>\n",
       "      <td>multi_prompt-get-entities-tagger</td>\n",
       "      <td>sentence</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>True</td>\n",
       "      <td>With 3 few_shots and ++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.238</td>\n",
       "      <td>(0.202, 0.274)</td>\n",
       "      <td>discussion</td>\n",
       "      <td>sentence</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>True</td>\n",
       "      <td>With 3 few_shots and ++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.238</td>\n",
       "      <td>(0.205, 0.271)</td>\n",
       "      <td>multi_prompt-get-entities-tagger</td>\n",
       "      <td>sentence</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>False</td>\n",
       "      <td>With 3 few_shots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.236</td>\n",
       "      <td>(0.194, 0.277)</td>\n",
       "      <td>discussion</td>\n",
       "      <td>sentence</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>False</td>\n",
       "      <td>With 3 few_shots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.161</td>\n",
       "      <td>(0.132, 0.191)</td>\n",
       "      <td>filing</td>\n",
       "      <td>sentence</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>True</td>\n",
       "      <td>With 3 few_shots and ++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.152</td>\n",
       "      <td>(0.098, 0.205)</td>\n",
       "      <td>filing</td>\n",
       "      <td>sentence</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>False</td>\n",
       "      <td>With 3 few_shots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.119</td>\n",
       "      <td>(0.103, 0.135)</td>\n",
       "      <td>discussion</td>\n",
       "      <td>no-shots</td>\n",
       "      <td>0</td>\n",
       "      <td>300</td>\n",
       "      <td>True</td>\n",
       "      <td>With 0 few_shots and ++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.110</td>\n",
       "      <td>(0.100, 0.119)</td>\n",
       "      <td>discussion</td>\n",
       "      <td>no-shots</td>\n",
       "      <td>0</td>\n",
       "      <td>300</td>\n",
       "      <td>False</td>\n",
       "      <td>With 0 few_shots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.088</td>\n",
       "      <td>(0.077, 0.098)</td>\n",
       "      <td>filing</td>\n",
       "      <td>no-shots</td>\n",
       "      <td>0</td>\n",
       "      <td>300</td>\n",
       "      <td>True</td>\n",
       "      <td>With 0 few_shots and ++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.081</td>\n",
       "      <td>(0.077, 0.084)</td>\n",
       "      <td>filing</td>\n",
       "      <td>no-shots</td>\n",
       "      <td>0</td>\n",
       "      <td>300</td>\n",
       "      <td>False</td>\n",
       "      <td>With 0 few_shots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.026</td>\n",
       "      <td>(0.009, 0.043)</td>\n",
       "      <td>wrapper</td>\n",
       "      <td>no-shots</td>\n",
       "      <td>0</td>\n",
       "      <td>300</td>\n",
       "      <td>False</td>\n",
       "      <td>With 0 few_shots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.021</td>\n",
       "      <td>(0.011, 0.031)</td>\n",
       "      <td>wrapper</td>\n",
       "      <td>no-shots</td>\n",
       "      <td>0</td>\n",
       "      <td>300</td>\n",
       "      <td>True</td>\n",
       "      <td>With 0 few_shots and ++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.000</td>\n",
       "      <td>(0.000, 0.000)</td>\n",
       "      <td>multi_prompt-get-entities-tagger</td>\n",
       "      <td>no-shots</td>\n",
       "      <td>0</td>\n",
       "      <td>300</td>\n",
       "      <td>False</td>\n",
       "      <td>With 0 few_shots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.000</td>\n",
       "      <td>(0.000, 0.000)</td>\n",
       "      <td>multi_prompt-get-entities-tagger</td>\n",
       "      <td>no-shots</td>\n",
       "      <td>0</td>\n",
       "      <td>300</td>\n",
       "      <td>True</td>\n",
       "      <td>With 0 few_shots and ++</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    f1_mean   f1_conf_inter                  prompt_technique  \\\n",
       "96    0.323  (0.297, 0.350)                           wrapper   \n",
       "95    0.321  (0.275, 0.367)                           wrapper   \n",
       "90    0.246  (0.216, 0.275)  multi_prompt-get-entities-tagger   \n",
       "85    0.238  (0.202, 0.274)                        discussion   \n",
       "89    0.238  (0.205, 0.271)  multi_prompt-get-entities-tagger   \n",
       "84    0.236  (0.194, 0.277)                        discussion   \n",
       "80    0.161  (0.132, 0.191)                            filing   \n",
       "79    0.152  (0.098, 0.205)                            filing   \n",
       "81    0.119  (0.103, 0.135)                        discussion   \n",
       "83    0.110  (0.100, 0.119)                        discussion   \n",
       "76    0.088  (0.077, 0.098)                            filing   \n",
       "78    0.081  (0.077, 0.084)                            filing   \n",
       "93    0.026  (0.009, 0.043)                           wrapper   \n",
       "91    0.021  (0.011, 0.031)                           wrapper   \n",
       "88    0.000  (0.000, 0.000)  multi_prompt-get-entities-tagger   \n",
       "86    0.000  (0.000, 0.000)  multi_prompt-get-entities-tagger   \n",
       "\n",
       "   few_shot_tecnique  nb_few_shots precision  plus_plus  \\\n",
       "96          sentence             3       300       True   \n",
       "95          sentence             3       300      False   \n",
       "90          sentence             3       300       True   \n",
       "85          sentence             3       300       True   \n",
       "89          sentence             3       300      False   \n",
       "84          sentence             3       300      False   \n",
       "80          sentence             3       300       True   \n",
       "79          sentence             3       300      False   \n",
       "81          no-shots             0       300       True   \n",
       "83          no-shots             0       300      False   \n",
       "76          no-shots             0       300       True   \n",
       "78          no-shots             0       300      False   \n",
       "93          no-shots             0       300      False   \n",
       "91          no-shots             0       300       True   \n",
       "88          no-shots             0       300      False   \n",
       "86          no-shots             0       300       True   \n",
       "\n",
       "                  tech_name  \n",
       "96  With 3 few_shots and ++  \n",
       "95        With 3 few_shots   \n",
       "90  With 3 few_shots and ++  \n",
       "85  With 3 few_shots and ++  \n",
       "89        With 3 few_shots   \n",
       "84        With 3 few_shots   \n",
       "80  With 3 few_shots and ++  \n",
       "79        With 3 few_shots   \n",
       "81  With 0 few_shots and ++  \n",
       "83        With 0 few_shots   \n",
       "76  With 0 few_shots and ++  \n",
       "78        With 0 few_shots   \n",
       "93        With 0 few_shots   \n",
       "91  With 0 few_shots and ++  \n",
       "88        With 0 few_shots   \n",
       "86  With 0 few_shots and ++  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_to_show = df_results[~df_results['model'].str.contains('ft')][['f1_mean', 'f1_conf_inter', 'prompt_technique',\n",
    "       'few_shot_tecnique', 'nb_few_shots', 'precision', 'plus_plus']]\n",
    "\n",
    "df_res = df_to_show[df_to_show['precision'] == '300']\n",
    "df_res['tech_name'] = df_res.apply(lambda row :f\"With {row['nb_few_shots']} few_shots {'and ++' if row['plus_plus']  else ''}\", axis = 1)\n",
    "df_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Showing prompts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------filing-------------------------\n",
      "---------------------raw---------------------\n",
      "\n",
      "[('### SYSTEM : The task is to extract named entities in a sentence.\\n    The types of the entities have to be one of the OntoNote5 dataset that you can find here : [\\'CARDINAL\\', \\'ORDINAL\\', \\'WORK_OF_ART\\', \\'PERSON\\', \\'LOC\\', \\'DATE\\', \\'PERCENT\\', \\'PRODUCT\\', \\'MONEY\\', \\'FAC\\', \\'TIME\\', \\'ORG\\', \\'QUANTITY\\', \\'LANGUAGE\\', \\'GPE\\', \\'LAW\\', \\'NORP\\', \\'EVENT\\'].\\n### USER : I want you to extract all the named entities in the text and tag them with one of the tag of the OntoNote5 dataset.\\n### ASSISTANT : What is the format of the output ?\\n### USER : You will output a json disctionnary that has all the 18 tags as keys and a list of named entities as values assigned to the right key. For example, with the sentence \"Japan is the second country that pays $ 13 for a burger 20 percent more than France\" as input. The output should be this dictionnary : {\\'CARDINAL\\' : [], \\'ORDINAL\\' : [\"second\"], \\'WORK_OF_ART\\' : [], \\'PERSON\\' : [], \\'LOC\\' : [], \\'DATE\\' : [], \\'PERCENT\\' : [\"20 percent\"], \\'PRODUCT\\' : [], \\'MONEY\\' : [\"$ 13\"], \\'FAC\\' : [], \\'TIME\\' : [], \\'ORG\\' : [], \\'QUANTITY\\' : [], \\'LANGUAGE\\' : [], \\'GPE\\' : [\"Japan\", \"France\"], \\'LAW\\' : [], \\'NORP\\' : [], \\'EVENT\\' : []}.  \\n### ASSISTANT : Can you provide me examples ?  \\n### USER : There are examples : \\n### USER : <start_input> With 3,000 Taiwan - owned businesses here , and 10 - 20,000 Taiwanese business people and their dependants coming in and out every day , the Dong - guan area has already developed an economic circle in which Taiwan firms can conduct most of their business among themselves . <end_input>\\n### ASSISTANT : <start_output> {\\'CARDINAL\\' : [\\'3,000, 10 - 20,000\\'], \\'ORDINAL\\' : [], \\'WORK_OF_ART\\' : [], \\'PERSON\\' : [], \\'LOC\\' : [], \\'DATE\\' : [], \\'PERCENT\\' : [], \\'PRODUCT\\' : [], \\'MONEY\\' : [], \\'FAC\\' : [], \\'TIME\\' : [], \\'ORG\\' : [], \\'QUANTITY\\' : [], \\'LANGUAGE\\' : [], \\'GPE\\' : [\\'Taiwan, Dong - guan, Taiwan\\'], \\'LAW\\' : [], \\'NORP\\' : [\\'Taiwanese\\'], \\'EVENT\\' : []} <end_output>\\n\\n### USER : <start_input> Invoking the Taiwanese business battle cry of \" victory to those who strive the hardest , \" 20,000 - 30,000 Taiwan expats in Dongguan have in little more than a decade turned a county of banana and lichee plantations into a big city with exports behind only Shenzhen \\'s and Shanghai \\'s . <end_input>\\n### ASSISTANT : <start_output> {\\'CARDINAL\\' : [\\'20,000, 30,000\\'], \\'ORDINAL\\' : [], \\'WORK_OF_ART\\' : [], \\'PERSON\\' : [], \\'LOC\\' : [], \\'DATE\\' : [], \\'PERCENT\\' : [], \\'PRODUCT\\' : [], \\'MONEY\\' : [], \\'FAC\\' : [], \\'TIME\\' : [], \\'ORG\\' : [], \\'QUANTITY\\' : [], \\'LANGUAGE\\' : [], \\'GPE\\' : [\\'Taiwan, Dongguan, Shenzhen, Shanghai\\'], \\'LAW\\' : [], \\'NORP\\' : [\\'Taiwanese\\'], \\'EVENT\\' : []} <end_output>\\n\\n### USER : <start_input> Although the Taiwan firms in Dongguan have left home , their success can largely be attributed to an ethos they transplanted from Taiwan - that \" victory goes to those who strive the hardest . \" <end_input>\\n### ASSISTANT : <start_output> {\\'CARDINAL\\' : [], \\'ORDINAL\\' : [], \\'WORK_OF_ART\\' : [], \\'PERSON\\' : [], \\'LOC\\' : [], \\'DATE\\' : [], \\'PERCENT\\' : [], \\'PRODUCT\\' : [], \\'MONEY\\' : [], \\'FAC\\' : [], \\'TIME\\' : [], \\'ORG\\' : [], \\'QUANTITY\\' : [], \\'LANGUAGE\\' : [], \\'GPE\\' : [\\'Taiwan, Dongguan, Taiwan\\'], \\'LAW\\' : [], \\'NORP\\' : [], \\'EVENT\\' : []} <end_output>\\n\\n### USER : <start_input> With 27 departures a day , these buses run by a Taiwan firm out of Dongguan take Taiwan expats to their adopted home , which boasts the largest concentration of Taiwan firms in the PRC . <end_input>\\n### ASSISTANT : <start_output> {\\'CARDINAL\\' : [\\'27\\'], \\'ORDINAL\\' : [], \\'WORK_OF_ART\\' : [], \\'PERSON\\' : [], \\'LOC\\' : [], \\'DATE\\' : [], \\'PERCENT\\' : [], \\'PRODUCT\\' : [], \\'MONEY\\' : [], \\'FAC\\' : [], \\'TIME\\' : [], \\'ORG\\' : [], \\'QUANTITY\\' : [], \\'LANGUAGE\\' : [], \\'GPE\\' : [\\'Taiwan, Dongguan, Taiwan, Taiwan, PRC\\'], \\'LAW\\' : [], \\'NORP\\' : [], \\'EVENT\\' : []} <end_output>\\n\\n### USER : <start_input> \" We make our money here , but we pay taxes in Taiwan , and most of our families and children do most of their consumer spending in Taiwan , \" insists TBAD chairperson Chang Mei - liang . <end_input>\\n### ASSISTANT : <start_output> {\\'CARDINAL\\' : [], \\'ORDINAL\\' : [], \\'WORK_OF_ART\\' : [], \\'PERSON\\' : [\\'Chang Mei - liang\\'], \\'LOC\\' : [], \\'DATE\\' : [], \\'PERCENT\\' : [], \\'PRODUCT\\' : [], \\'MONEY\\' : [], \\'FAC\\' : [], \\'TIME\\' : [], \\'ORG\\' : [\\'TBAD\\'], \\'QUANTITY\\' : [], \\'LANGUAGE\\' : [], \\'GPE\\' : [\\'Taiwan, Taiwan\\'], \\'LAW\\' : [], \\'NORP\\' : [], \\'EVENT\\' : []} <end_output>\\n\\n### ASSISTANT : I will provide you a json containing all the tags as values and a list of named entities that are of this type of tag as value. Now provide me the sentence.\\n### INPUT : <start_input> Although low land and labor costs are Dongguan \\'s main attractions , Taiwan firms also choose the locale for the networks of people and producers that have been built up among Taiwanese in Dongguan over the last ten years . <end_input>\\n### OUTPUT : <start_output> [', 'None')] {'FAC : []\\n', 'ORG : []\\n', 'LAW : []\\n', 'PRODUCT : []\\n', 'DATE : [the last ten years]\\n', 'TIME : []\\n', 'QUANTITY : []\\n', 'EVENT : []\\n', 'NORP : [Taiwanese]\\n', 'GPE : [Dongguan, Taiwan, Dongguan]\\n', 'WORK_OF_ART : []\\n', 'PERSON : []\\n', 'LOC : []\\n', 'PERCENT : []\\n', 'CARDINAL : []\\n', 'ORDINAL : []\\n', 'MONEY : []\\n', 'LANGUAGE : []\\n'}\n",
      "----------------------------------------------------\n",
      "---------------------prompt++---------------------\n",
      "\n",
      "[('### SYSTEM : The task is to extract named entities in a sentence.\\n    A named entity refers to a specific, named object, concept, location, person, organization, or other entities that have a proper name. Named entities are typically unique and distinguishable entities that can be explicitly named or referred to in text. Named entities are stopwords like \\'the\\', verbs like \\'serving\\' or question words like \\'why\\'. \\n    The goal of named entity extraction is to identify and classify these entities within a given text.\\n    We are working with 18 types of entities of the OntoNote5 dataset that are listed below with their description :\\n        \"CARDINAL\": \"Numerals that do not fall under another type (e.g. 1, 100, twenty-nine).\",\\n        \"ORDINAL\": \"Words or expressions indicating order (e.g. first, 60th).\",\\n        \"WORK_OF_ART\": \"Titles of creative works like books, films or artistic work.\",\\n        \"PERSON\": \"Names of people, including fictional and real characters.\",\\n        \"LOC\": \"Geographical locations, both physical and political.\",\\n        \"DATE\": \"Temporal expressions indicating dates or periods, weekday, months,\",\\n        \"PERCENT\": \"Percentage values (e.g. 70%).\",\\n        \"PRODUCT\": \"Names of products or services.\",\\n        \"MONEY\": \"Monetary values, including currency symbols.\",\\n        \"FAC\": \"Named facilities, such as buildings, airports, or highways.\",\\n        \"TIME\": \"Temporal expressions indicating times of the day.\",\\n        \"ORG\": \"Names of organizations, institutions, or companies.\",\\n        \"QUANTITY\": \"Measurements or counts, including units (e.g. 10 grams, 1 litre)\",\\n        \"LANGUAGE\": \"Names of languages.\",\\n        \"GPE\": \"Geopolitical entities, such as countries, cities, or states.\",\\n        \"LAW\": \"Legal references, including laws and legal concepts.\",\\n        \"NORP\": \"Nationalities, religious group, or political groups. Can be adjective for nationality like \"Canadian\".\",\\n        \"EVENT\": \"Named occurrences and social, political, cultural, or genera incidents.\\n### USER : I want you to extract all the named entities in the text and tag them with one of the tag of the OntoNote5 dataset.\\n### ASSISTANT : What is the format of the output ?\\n### USER : You will output a json disctionnary that has all the 18 tags as keys and a list of named entities as values assigned to the right key. For example, with the sentence \"Japan is the second country that pays $ 13 for a burger 20 percent more than France\" as input. The output should be this dictionnary : {\\'CARDINAL\\' : [], \\'ORDINAL\\' : [\"second\"], \\'WORK_OF_ART\\' : [], \\'PERSON\\' : [], \\'LOC\\' : [], \\'DATE\\' : [], \\'PERCENT\\' : [\"20 percent\"], \\'PRODUCT\\' : [], \\'MONEY\\' : [\"$ 13\"], \\'FAC\\' : [], \\'TIME\\' : [], \\'ORG\\' : [], \\'QUANTITY\\' : [], \\'LANGUAGE\\' : [], \\'GPE\\' : [\"Japan\", \"France\"], \\'LAW\\' : [], \\'NORP\\' : [], \\'EVENT\\' : []}.  \\n### ASSISTANT : Can you provide me examples ?  \\n### USER : There are examples : \\n### USER : <start_input> With 3,000 Taiwan - owned businesses here , and 10 - 20,000 Taiwanese business people and their dependants coming in and out every day , the Dong - guan area has already developed an economic circle in which Taiwan firms can conduct most of their business among themselves . <end_input>\\n### ASSISTANT : <start_output> {\\'CARDINAL\\' : [\\'3,000, 10 - 20,000\\'], \\'ORDINAL\\' : [], \\'WORK_OF_ART\\' : [], \\'PERSON\\' : [], \\'LOC\\' : [], \\'DATE\\' : [], \\'PERCENT\\' : [], \\'PRODUCT\\' : [], \\'MONEY\\' : [], \\'FAC\\' : [], \\'TIME\\' : [], \\'ORG\\' : [], \\'QUANTITY\\' : [], \\'LANGUAGE\\' : [], \\'GPE\\' : [\\'Taiwan, Dong - guan, Taiwan\\'], \\'LAW\\' : [], \\'NORP\\' : [\\'Taiwanese\\'], \\'EVENT\\' : []} <end_output>\\n\\n### USER : <start_input> Invoking the Taiwanese business battle cry of \" victory to those who strive the hardest , \" 20,000 - 30,000 Taiwan expats in Dongguan have in little more than a decade turned a county of banana and lichee plantations into a big city with exports behind only Shenzhen \\'s and Shanghai \\'s . <end_input>\\n### ASSISTANT : <start_output> {\\'CARDINAL\\' : [\\'20,000, 30,000\\'], \\'ORDINAL\\' : [], \\'WORK_OF_ART\\' : [], \\'PERSON\\' : [], \\'LOC\\' : [], \\'DATE\\' : [], \\'PERCENT\\' : [], \\'PRODUCT\\' : [], \\'MONEY\\' : [], \\'FAC\\' : [], \\'TIME\\' : [], \\'ORG\\' : [], \\'QUANTITY\\' : [], \\'LANGUAGE\\' : [], \\'GPE\\' : [\\'Taiwan, Dongguan, Shenzhen, Shanghai\\'], \\'LAW\\' : [], \\'NORP\\' : [\\'Taiwanese\\'], \\'EVENT\\' : []} <end_output>\\n\\n### USER : <start_input> Although the Taiwan firms in Dongguan have left home , their success can largely be attributed to an ethos they transplanted from Taiwan - that \" victory goes to those who strive the hardest . \" <end_input>\\n### ASSISTANT : <start_output> {\\'CARDINAL\\' : [], \\'ORDINAL\\' : [], \\'WORK_OF_ART\\' : [], \\'PERSON\\' : [], \\'LOC\\' : [], \\'DATE\\' : [], \\'PERCENT\\' : [], \\'PRODUCT\\' : [], \\'MONEY\\' : [], \\'FAC\\' : [], \\'TIME\\' : [], \\'ORG\\' : [], \\'QUANTITY\\' : [], \\'LANGUAGE\\' : [], \\'GPE\\' : [\\'Taiwan, Dongguan, Taiwan\\'], \\'LAW\\' : [], \\'NORP\\' : [], \\'EVENT\\' : []} <end_output>\\n\\n### USER : <start_input> With 27 departures a day , these buses run by a Taiwan firm out of Dongguan take Taiwan expats to their adopted home , which boasts the largest concentration of Taiwan firms in the PRC . <end_input>\\n### ASSISTANT : <start_output> {\\'CARDINAL\\' : [\\'27\\'], \\'ORDINAL\\' : [], \\'WORK_OF_ART\\' : [], \\'PERSON\\' : [], \\'LOC\\' : [], \\'DATE\\' : [], \\'PERCENT\\' : [], \\'PRODUCT\\' : [], \\'MONEY\\' : [], \\'FAC\\' : [], \\'TIME\\' : [], \\'ORG\\' : [], \\'QUANTITY\\' : [], \\'LANGUAGE\\' : [], \\'GPE\\' : [\\'Taiwan, Dongguan, Taiwan, Taiwan, PRC\\'], \\'LAW\\' : [], \\'NORP\\' : [], \\'EVENT\\' : []} <end_output>\\n\\n### USER : <start_input> \" We make our money here , but we pay taxes in Taiwan , and most of our families and children do most of their consumer spending in Taiwan , \" insists TBAD chairperson Chang Mei - liang . <end_input>\\n### ASSISTANT : <start_output> {\\'CARDINAL\\' : [], \\'ORDINAL\\' : [], \\'WORK_OF_ART\\' : [], \\'PERSON\\' : [\\'Chang Mei - liang\\'], \\'LOC\\' : [], \\'DATE\\' : [], \\'PERCENT\\' : [], \\'PRODUCT\\' : [], \\'MONEY\\' : [], \\'FAC\\' : [], \\'TIME\\' : [], \\'ORG\\' : [\\'TBAD\\'], \\'QUANTITY\\' : [], \\'LANGUAGE\\' : [], \\'GPE\\' : [\\'Taiwan, Taiwan\\'], \\'LAW\\' : [], \\'NORP\\' : [], \\'EVENT\\' : []} <end_output>\\n\\n### ASSISTANT : I will provide you a json containing all the tags as values and a list of named entities that are of this type of tag as value. Now provide me the sentence.\\n### INPUT : <start_input> Although low land and labor costs are Dongguan \\'s main attractions , Taiwan firms also choose the locale for the networks of people and producers that have been built up among Taiwanese in Dongguan over the last ten years . <end_input>\\n### OUTPUT : <start_output> [', 'None')] {'FAC : []\\n', 'ORG : []\\n', 'LAW : []\\n', 'PRODUCT : []\\n', 'DATE : [the last ten years]\\n', 'TIME : []\\n', 'QUANTITY : []\\n', 'EVENT : []\\n', 'NORP : [Taiwanese]\\n', 'GPE : [Dongguan, Taiwan, Dongguan]\\n', 'WORK_OF_ART : []\\n', 'PERSON : []\\n', 'LOC : []\\n', 'PERCENT : []\\n', 'CARDINAL : []\\n', 'ORDINAL : []\\n', 'MONEY : []\\n', 'LANGUAGE : []\\n'}\n",
      "----------------------------------------------------\n",
      "\n",
      "------------discussion-------------------------\n",
      "---------------------raw---------------------\n",
      "\n",
      "[('### SYSTEM : The task is to extract named entities in a sentence.\\n    The types of the entities have to be one of the OntoNote5 dataset that you can find here : [\\'CARDINAL\\', \\'ORDINAL\\', \\'WORK_OF_ART\\', \\'PERSON\\', \\'LOC\\', \\'DATE\\', \\'PERCENT\\', \\'PRODUCT\\', \\'MONEY\\', \\'FAC\\', \\'TIME\\', \\'ORG\\', \\'QUANTITY\\', \\'LANGUAGE\\', \\'GPE\\', \\'LAW\\', \\'NORP\\', \\'EVENT\\'].\\n### USER : I want you to extract all the named entities in the text and tag them with one of the tag of the OntoNote5 dataset. I do not want any entity that has tag outside these 18 tags.\\n### ASSISTANT : What is the format of the output ?\\n### USER : You have to output a python list of UNIQUE tuples. Do not repeat a tuple. In each tuple, you have a the named entity and its own tag. For example, with the sentence \"Japan is a country\" as input, you would answer \"[(\\'Japan\\', \\'GPE\\')]\". \\n### ASSISTANT : Can you provide me examples ?  \\n### USER : There are examples : \\n### USER : <start_input> With 3,000 Taiwan - owned businesses here , and 10 - 20,000 Taiwanese business people and their dependants coming in and out every day , the Dong - guan area has already developed an economic circle in which Taiwan firms can conduct most of their business among themselves . <end_input>\\n### ASSISTANT : <start_output> [(\\'3,000\\', \\'CARDINAL\\'), (\\'Taiwan\\', \\'GPE\\'), (\\'10 - 20,000\\', \\'CARDINAL\\'), (\\'Taiwanese\\', \\'NORP\\'), (\\'Dong - guan\\', \\'GPE\\'), (\\'Taiwan\\', \\'GPE\\')] <end_output>\\n\\n### USER : <start_input> Invoking the Taiwanese business battle cry of \" victory to those who strive the hardest , \" 20,000 - 30,000 Taiwan expats in Dongguan have in little more than a decade turned a county of banana and lichee plantations into a big city with exports behind only Shenzhen \\'s and Shanghai \\'s . <end_input>\\n### ASSISTANT : <start_output> [(\\'Taiwanese\\', \\'NORP\\'), (\\'20,000\\', \\'CARDINAL\\'), (\\'30,000\\', \\'CARDINAL\\'), (\\'Taiwan\\', \\'GPE\\'), (\\'Dongguan\\', \\'GPE\\'), (\\'Shenzhen\\', \\'GPE\\'), (\\'Shanghai\\', \\'GPE\\')] <end_output>\\n\\n### USER : <start_input> Although the Taiwan firms in Dongguan have left home , their success can largely be attributed to an ethos they transplanted from Taiwan - that \" victory goes to those who strive the hardest . \" <end_input>\\n### ASSISTANT : <start_output> [(\\'Taiwan\\', \\'GPE\\'), (\\'Dongguan\\', \\'GPE\\'), (\\'Taiwan\\', \\'GPE\\')] <end_output>\\n\\n### USER : <start_input> With 27 departures a day , these buses run by a Taiwan firm out of Dongguan take Taiwan expats to their adopted home , which boasts the largest concentration of Taiwan firms in the PRC . <end_input>\\n### ASSISTANT : <start_output> [(\\'27\\', \\'CARDINAL\\'), (\\'Taiwan\\', \\'GPE\\'), (\\'Dongguan\\', \\'GPE\\'), (\\'Taiwan\\', \\'GPE\\'), (\\'Taiwan\\', \\'GPE\\'), (\\'PRC\\', \\'GPE\\')] <end_output>\\n\\n### USER : <start_input> \" We make our money here , but we pay taxes in Taiwan , and most of our families and children do most of their consumer spending in Taiwan , \" insists TBAD chairperson Chang Mei - liang . <end_input>\\n### ASSISTANT : <start_output> [(\\'Taiwan\\', \\'GPE\\'), (\\'Taiwan\\', \\'GPE\\'), (\\'TBAD\\', \\'ORG\\'), (\\'Chang Mei - liang\\', \\'PERSON\\')] <end_output>\\n\\n### ASSISTANT : I will extract all the named entities in the text that has one of the 18 tags of the OntoNote5 dataset and will not add other tags. Then I will output a python list of tuples containing the named entitiy and its own tag. There will be NO REPETITIONS in the list and no stopwords that are not entities. Now provide me the sentence.\\n### USER : <start_input> Although low land and labor costs are Dongguan \\'s main attractions , Taiwan firms also choose the locale for the networks of people and producers that have been built up among Taiwanese in Dongguan over the last ten years . <end_input>\\n### ASSISTANT : <start_output> [', 'None')] [['Dongguan', 'GPE'], ['Taiwan', 'GPE'], ['Taiwanese', 'NORP'], ['Dongguan', 'GPE'], ['the last ten years', 'DATE']]\n",
      "----------------------------------------------------\n",
      "---------------------prompt++---------------------\n",
      "\n",
      "[('### SYSTEM : The task is to extract named entities in a sentence.\\n    A named entity refers to a specific, named object, concept, location, person, organization, or other entities that have a proper name. Named entities are typically unique and distinguishable entities that can be explicitly named or referred to in text. Named entities are stopwords like \\'the\\', verbs like \\'serving\\' or question words like \\'why\\'. \\n    The goal of named entity extraction is to identify and classify these entities within a given text.\\n    We are working with 18 types of entities of the OntoNote5 dataset that are listed below with their description :\\n        \"CARDINAL\": \"Numerals that do not fall under another type (e.g. 1, 100, twenty-nine).\",\\n        \"ORDINAL\": \"Words or expressions indicating order (e.g. first, 60th).\",\\n        \"WORK_OF_ART\": \"Titles of creative works like books, films or artistic work.\",\\n        \"PERSON\": \"Names of people, including fictional and real characters.\",\\n        \"LOC\": \"Geographical locations, both physical and political.\",\\n        \"DATE\": \"Temporal expressions indicating dates or periods, weekday, months,\",\\n        \"PERCENT\": \"Percentage values (e.g. 70%).\",\\n        \"PRODUCT\": \"Names of products or services.\",\\n        \"MONEY\": \"Monetary values, including currency symbols.\",\\n        \"FAC\": \"Named facilities, such as buildings, airports, or highways.\",\\n        \"TIME\": \"Temporal expressions indicating times of the day.\",\\n        \"ORG\": \"Names of organizations, institutions, or companies.\",\\n        \"QUANTITY\": \"Measurements or counts, including units (e.g. 10 grams, 1 litre)\",\\n        \"LANGUAGE\": \"Names of languages.\",\\n        \"GPE\": \"Geopolitical entities, such as countries, cities, or states.\",\\n        \"LAW\": \"Legal references, including laws and legal concepts.\",\\n        \"NORP\": \"Nationalities, religious group, or political groups. Can be adjective for nationality like \"Canadian\".\",\\n        \"EVENT\": \"Named occurrences and social, political, cultural, or genera incidents.\\n### USER : I want you to extract all the named entities in the text and tag them with one of the tag of the OntoNote5 dataset. I do not want any entity that has tag outside these 18 tags.\\n### ASSISTANT : What is the format of the output ?\\n### USER : You have to output a python list of UNIQUE tuples. Do not repeat a tuple. In each tuple, you have a the named entity and its own tag. For example, with the sentence \"Japan is a country\" as input, you would answer \"[(\\'Japan\\', \\'GPE\\')]\". \\n### ASSISTANT : Can you provide me examples ?  \\n### USER : There are examples : \\n### USER : <start_input> With 3,000 Taiwan - owned businesses here , and 10 - 20,000 Taiwanese business people and their dependants coming in and out every day , the Dong - guan area has already developed an economic circle in which Taiwan firms can conduct most of their business among themselves . <end_input>\\n### ASSISTANT : <start_output> [(\\'3,000\\', \\'CARDINAL\\'), (\\'Taiwan\\', \\'GPE\\'), (\\'10 - 20,000\\', \\'CARDINAL\\'), (\\'Taiwanese\\', \\'NORP\\'), (\\'Dong - guan\\', \\'GPE\\'), (\\'Taiwan\\', \\'GPE\\')] <end_output>\\n\\n### USER : <start_input> Invoking the Taiwanese business battle cry of \" victory to those who strive the hardest , \" 20,000 - 30,000 Taiwan expats in Dongguan have in little more than a decade turned a county of banana and lichee plantations into a big city with exports behind only Shenzhen \\'s and Shanghai \\'s . <end_input>\\n### ASSISTANT : <start_output> [(\\'Taiwanese\\', \\'NORP\\'), (\\'20,000\\', \\'CARDINAL\\'), (\\'30,000\\', \\'CARDINAL\\'), (\\'Taiwan\\', \\'GPE\\'), (\\'Dongguan\\', \\'GPE\\'), (\\'Shenzhen\\', \\'GPE\\'), (\\'Shanghai\\', \\'GPE\\')] <end_output>\\n\\n### USER : <start_input> Although the Taiwan firms in Dongguan have left home , their success can largely be attributed to an ethos they transplanted from Taiwan - that \" victory goes to those who strive the hardest . \" <end_input>\\n### ASSISTANT : <start_output> [(\\'Taiwan\\', \\'GPE\\'), (\\'Dongguan\\', \\'GPE\\'), (\\'Taiwan\\', \\'GPE\\')] <end_output>\\n\\n### USER : <start_input> With 27 departures a day , these buses run by a Taiwan firm out of Dongguan take Taiwan expats to their adopted home , which boasts the largest concentration of Taiwan firms in the PRC . <end_input>\\n### ASSISTANT : <start_output> [(\\'27\\', \\'CARDINAL\\'), (\\'Taiwan\\', \\'GPE\\'), (\\'Dongguan\\', \\'GPE\\'), (\\'Taiwan\\', \\'GPE\\'), (\\'Taiwan\\', \\'GPE\\'), (\\'PRC\\', \\'GPE\\')] <end_output>\\n\\n### USER : <start_input> \" We make our money here , but we pay taxes in Taiwan , and most of our families and children do most of their consumer spending in Taiwan , \" insists TBAD chairperson Chang Mei - liang . <end_input>\\n### ASSISTANT : <start_output> [(\\'Taiwan\\', \\'GPE\\'), (\\'Taiwan\\', \\'GPE\\'), (\\'TBAD\\', \\'ORG\\'), (\\'Chang Mei - liang\\', \\'PERSON\\')] <end_output>\\n\\n### ASSISTANT : I will extract all the named entities in the text that has one of the 18 tags of the OntoNote5 dataset and will not add other tags. Then I will output a python list of tuples containing the named entitiy and its own tag. There will be NO REPETITIONS in the list and no stopwords that are not entities. Now provide me the sentence.\\n### USER : <start_input> Although low land and labor costs are Dongguan \\'s main attractions , Taiwan firms also choose the locale for the networks of people and producers that have been built up among Taiwanese in Dongguan over the last ten years . <end_input>\\n### ASSISTANT : <start_output> [', 'None')] [['Dongguan', 'GPE'], ['Taiwan', 'GPE'], ['Taiwanese', 'NORP'], ['Dongguan', 'GPE'], ['the last ten years', 'DATE']]\n",
      "----------------------------------------------------\n",
      "\n",
      "------------wrapper-------------------------\n",
      "---------------------raw---------------------\n",
      "\n",
      "[('### SYSTEM : The task is to extract named entities in a sentence.\\n    The types of the entities have to be one of the OntoNote5 dataset that you can find here : [\\'CARDINAL\\', \\'ORDINAL\\', \\'WORK_OF_ART\\', \\'PERSON\\', \\'LOC\\', \\'DATE\\', \\'PERCENT\\', \\'PRODUCT\\', \\'MONEY\\', \\'FAC\\', \\'TIME\\', \\'ORG\\', \\'QUANTITY\\', \\'LANGUAGE\\', \\'GPE\\', \\'LAW\\', \\'NORP\\', \\'EVENT\\'].\\n### USER : I want you to extract all the named entities in the text and tag them with one of the tag of the OntoNote5 dataset.\\n### ASSISTANT : What is the format of the output ?\\n### USER : As output, you have to rewrite the sentence that I gave you and wrap all the named entities with \"<[tag]>\" and \"</[tag]>\" where \"[tag]\" is one of the 18 tags of the OntoNote5 dataset. For example, with the sentence \"Japan is a country\" as input, you would answer \"<GPE>Japan</GPE> is a country\". \\n### ASSISTANT : Can you provide me examples ?  \\n### USER : There are examples : \\n### USER : <start_input> With 3,000 Taiwan - owned businesses here , and 10 - 20,000 Taiwanese business people and their dependants coming in and out every day , the Dong - guan area has already developed an economic circle in which Taiwan firms can conduct most of their business among themselves . <end_input>\\n### ASSISTANT : <start_output> With <CARDINAL>3,000</CARDINAL> <GPE>Taiwan</GPE> - owned businesses here , and <CARDINAL>10 - 20,000</CARDINAL> <GPE>Taiwan</GPE>ese business people and their dependants coming in and out every day , the <GPE>Dong - guan</GPE> area has already developed an economic circle in which <GPE>Taiwan</GPE> firms can conduct most of their business among themselves . <end_output>\\n\\n### USER : <start_input> Invoking the Taiwanese business battle cry of \" victory to those who strive the hardest , \" 20,000 - 30,000 Taiwan expats in Dongguan have in little more than a decade turned a county of banana and lichee plantations into a big city with exports behind only Shenzhen \\'s and Shanghai \\'s . <end_input>\\n### ASSISTANT : <start_output> Invoking the <NORP><GPE>Taiwan</GPE>ese</NORP> business battle cry of \" victory to those who strive the hardest , \" <CARDINAL>20,000</CARDINAL> - <CARDINAL>30,000</CARDINAL> <GPE>Taiwan</GPE> expats in <GPE>Dongguan</GPE> have in little more than a decade turned a county of banana and lichee plantations into a big city with exports behind only <GPE>Shenzhen</GPE> \\'s and <GPE>Shanghai</GPE> \\'s . <end_output>\\n\\n### USER : <start_input> Although the Taiwan firms in Dongguan have left home , their success can largely be attributed to an ethos they transplanted from Taiwan - that \" victory goes to those who strive the hardest . \" <end_input>\\n### ASSISTANT : <start_output> Although the <GPE>Taiwan</GPE> firms in <GPE>Dongguan</GPE> have left home , their success can largely be attributed to an ethos they transplanted from <GPE>Taiwan</GPE> - that \" victory goes to those who strive the hardest . \" <end_output>\\n\\n### USER : <start_input> With 27 departures a day , these buses run by a Taiwan firm out of Dongguan take Taiwan expats to their adopted home , which boasts the largest concentration of Taiwan firms in the PRC . <end_input>\\n### ASSISTANT : <start_output> With <CARDINAL>27</CARDINAL> departures a day , these buses run by a <GPE>Taiwan</GPE> firm out of <GPE>Dongguan</GPE> take <GPE>Taiwan</GPE> expats to their adopted home , which boasts the largest concentration of <GPE>Taiwan</GPE> firms in the <GPE>PRC</GPE> . <end_output>\\n\\n### USER : <start_input> \" We make our money here , but we pay taxes in Taiwan , and most of our families and children do most of their consumer spending in Taiwan , \" insists TBAD chairperson Chang Mei - liang . <end_input>\\n### ASSISTANT : <start_output> \" We make our money here , but we pay taxes in <GPE>Taiwan</GPE> , and most of our families and children do most of their consumer spending in <GPE>Taiwan</GPE> , \" insists <ORG>TBAD</ORG> chairperson <PERSON>Chang Mei - liang</PERSON> . <end_output>\\n\\n### ASSISTANT : I understand I need to rewrite the sentence and wrap the named entity with\"<[tag]>\" and \"</[tag]>\" where \"[tag]\" is one of the 18 tags of the OntoNote5 dataset. Now, provide me the sentence ? \\n### USER : <start_input> Although low land and labor costs are Dongguan \\'s main attractions , Taiwan firms also choose the locale for the networks of people and producers that have been built up among Taiwanese in Dongguan over the last ten years . <end_input>\\n### ASSISTANT : <start_output> ', 'None')] Although low land and labor costs are <GPE>Dongguan</GPE> 's main attractions , <GPE>Taiwan</GPE> firms also choose the locale for the networks of people and producers that have been built up among <GPE>Taiwan</GPE>ese in <GPE>Dongguan</GPE> over <DATE>the last ten years</DATE> .\n",
      "----------------------------------------------------\n",
      "---------------------prompt++---------------------\n",
      "\n",
      "[('### SYSTEM : The task is to extract named entities in a sentence.\\n    A named entity refers to a specific, named object, concept, location, person, organization, or other entities that have a proper name. Named entities are typically unique and distinguishable entities that can be explicitly named or referred to in text. Named entities are stopwords like \\'the\\', verbs like \\'serving\\' or question words like \\'why\\'. \\n    The goal of named entity extraction is to identify and classify these entities within a given text.\\n    We are working with 18 types of entities of the OntoNote5 dataset that are listed below with their description :\\n        \"CARDINAL\": \"Numerals that do not fall under another type (e.g. 1, 100, twenty-nine).\",\\n        \"ORDINAL\": \"Words or expressions indicating order (e.g. first, 60th).\",\\n        \"WORK_OF_ART\": \"Titles of creative works like books, films or artistic work.\",\\n        \"PERSON\": \"Names of people, including fictional and real characters.\",\\n        \"LOC\": \"Geographical locations, both physical and political.\",\\n        \"DATE\": \"Temporal expressions indicating dates or periods, weekday, months,\",\\n        \"PERCENT\": \"Percentage values (e.g. 70%).\",\\n        \"PRODUCT\": \"Names of products or services.\",\\n        \"MONEY\": \"Monetary values, including currency symbols.\",\\n        \"FAC\": \"Named facilities, such as buildings, airports, or highways.\",\\n        \"TIME\": \"Temporal expressions indicating times of the day.\",\\n        \"ORG\": \"Names of organizations, institutions, or companies.\",\\n        \"QUANTITY\": \"Measurements or counts, including units (e.g. 10 grams, 1 litre)\",\\n        \"LANGUAGE\": \"Names of languages.\",\\n        \"GPE\": \"Geopolitical entities, such as countries, cities, or states.\",\\n        \"LAW\": \"Legal references, including laws and legal concepts.\",\\n        \"NORP\": \"Nationalities, religious group, or political groups. Can be adjective for nationality like \"Canadian\".\",\\n        \"EVENT\": \"Named occurrences and social, political, cultural, or genera incidents.\\n### USER : I want you to extract all the named entities in the text and tag them with one of the tag of the OntoNote5 dataset.\\n### ASSISTANT : What is the format of the output ?\\n### USER : As output, you have to rewrite the sentence that I gave you and wrap all the named entities with \"<[tag]>\" and \"</[tag]>\" where \"[tag]\" is one of the 18 tags of the OntoNote5 dataset. For example, with the sentence \"Japan is a country\" as input, you would answer \"<GPE>Japan</GPE> is a country\". \\n### ASSISTANT : Can you provide me examples ?  \\n### USER : There are examples : \\n### USER : <start_input> With 3,000 Taiwan - owned businesses here , and 10 - 20,000 Taiwanese business people and their dependants coming in and out every day , the Dong - guan area has already developed an economic circle in which Taiwan firms can conduct most of their business among themselves . <end_input>\\n### ASSISTANT : <start_output> With <CARDINAL>3,000</CARDINAL> <GPE>Taiwan</GPE> - owned businesses here , and <CARDINAL>10 - 20,000</CARDINAL> <GPE>Taiwan</GPE>ese business people and their dependants coming in and out every day , the <GPE>Dong - guan</GPE> area has already developed an economic circle in which <GPE>Taiwan</GPE> firms can conduct most of their business among themselves . <end_output>\\n\\n### USER : <start_input> Invoking the Taiwanese business battle cry of \" victory to those who strive the hardest , \" 20,000 - 30,000 Taiwan expats in Dongguan have in little more than a decade turned a county of banana and lichee plantations into a big city with exports behind only Shenzhen \\'s and Shanghai \\'s . <end_input>\\n### ASSISTANT : <start_output> Invoking the <NORP><GPE>Taiwan</GPE>ese</NORP> business battle cry of \" victory to those who strive the hardest , \" <CARDINAL>20,000</CARDINAL> - <CARDINAL>30,000</CARDINAL> <GPE>Taiwan</GPE> expats in <GPE>Dongguan</GPE> have in little more than a decade turned a county of banana and lichee plantations into a big city with exports behind only <GPE>Shenzhen</GPE> \\'s and <GPE>Shanghai</GPE> \\'s . <end_output>\\n\\n### USER : <start_input> Although the Taiwan firms in Dongguan have left home , their success can largely be attributed to an ethos they transplanted from Taiwan - that \" victory goes to those who strive the hardest . \" <end_input>\\n### ASSISTANT : <start_output> Although the <GPE>Taiwan</GPE> firms in <GPE>Dongguan</GPE> have left home , their success can largely be attributed to an ethos they transplanted from <GPE>Taiwan</GPE> - that \" victory goes to those who strive the hardest . \" <end_output>\\n\\n### USER : <start_input> With 27 departures a day , these buses run by a Taiwan firm out of Dongguan take Taiwan expats to their adopted home , which boasts the largest concentration of Taiwan firms in the PRC . <end_input>\\n### ASSISTANT : <start_output> With <CARDINAL>27</CARDINAL> departures a day , these buses run by a <GPE>Taiwan</GPE> firm out of <GPE>Dongguan</GPE> take <GPE>Taiwan</GPE> expats to their adopted home , which boasts the largest concentration of <GPE>Taiwan</GPE> firms in the <GPE>PRC</GPE> . <end_output>\\n\\n### USER : <start_input> \" We make our money here , but we pay taxes in Taiwan , and most of our families and children do most of their consumer spending in Taiwan , \" insists TBAD chairperson Chang Mei - liang . <end_input>\\n### ASSISTANT : <start_output> \" We make our money here , but we pay taxes in <GPE>Taiwan</GPE> , and most of our families and children do most of their consumer spending in <GPE>Taiwan</GPE> , \" insists <ORG>TBAD</ORG> chairperson <PERSON>Chang Mei - liang</PERSON> . <end_output>\\n\\n### ASSISTANT : I understand I need to rewrite the sentence and wrap the named entity with\"<[tag]>\" and \"</[tag]>\" where \"[tag]\" is one of the 18 tags of the OntoNote5 dataset. Now, provide me the sentence ? \\n### USER : <start_input> Although low land and labor costs are Dongguan \\'s main attractions , Taiwan firms also choose the locale for the networks of people and producers that have been built up among Taiwanese in Dongguan over the last ten years . <end_input>\\n### ASSISTANT : <start_output> ', 'None')] Although low land and labor costs are <GPE>Dongguan</GPE> 's main attractions , <GPE>Taiwan</GPE> firms also choose the locale for the networks of people and producers that have been built up among <GPE>Taiwan</GPE>ese in <GPE>Dongguan</GPE> over <DATE>the last ten years</DATE> .\n",
      "----------------------------------------------------\n",
      "\n",
      "------------tagger-------------------------\n",
      "---------------------raw---------------------\n",
      "\n",
      "[('### SYSTEM : The task is to tag all the named entites that were extracted from a sentence.\\n    The types of the entities have to be one of the OntoNote5 dataset that you can find here : [\\'CARDINAL\\', \\'ORDINAL\\', \\'WORK_OF_ART\\', \\'PERSON\\', \\'LOC\\', \\'DATE\\', \\'PERCENT\\', \\'PRODUCT\\', \\'MONEY\\', \\'FAC\\', \\'TIME\\', \\'ORG\\', \\'QUANTITY\\', \\'LANGUAGE\\', \\'GPE\\', \\'LAW\\', \\'NORP\\', \\'EVENT\\'].\\n### USER : I want you to tag the named entites that were extracted from a sentence with the following character :  \\n    \\'1\\' for \\'CARDINAL\\' entities,\\n    \\'2\\' for \\'ORDINAL\\' entities,\\n    \\'3\\' for \\'WORK_OF_ART\\' entities,\\n    \\'4\\' for \\'PERSON\\' entities,\\n    \\'5\\' for \\'LOC\\' entities,\\n    \\'6\\' for \\'DATE\\' entities,\\n    \\'7\\' for \\'PERCENT\\' entities,\\n    \\'8\\' for \\'PRODUCT\\' entities,\\n    \\'9\\' for \\'MONEY\\' entities,\\n    \\'0\\' for \\'FAC\\' entities,\\n    \\'A\\' for \\'TIME\\' entities,\\n    \\'B\\' for \\'ORG\\' entities,\\n    \\'C\\' for \\'QUANTITY\\' entities,\\n    \\'D\\' for \\'LANGUAGE\\' entities,\\n    \\'E\\' for \\'GPE\\' entities,\\n    \\'F\\' for \\'LAW\\' entities,\\n    \\'G\\' for \\'NORP\\' entities,\\n    \\'H\\' for \\'EVENT\\' entities\\n### ASSISTANT : What is the format of the output ?\\n### USER : Output a json with the named entities as keys and the tag as values. For example, with the input \"[Japan]\" in \"Japan is a country\", you would answer \\'{ \"Japan\" : \"E\" }\\'. \\n### ASSISTANT : Can you provide me examples ?  \\n### USER : There are examples : \\n### USER : <start_input> [\\'Mason\\'] in \\'The question is , if group conflicts still exist -LRB- as undeniably they do -RRB- , and if Mr. Mason \\'s type of ethnic humor is passe , then what other means do we have for letting off steam ?\\' <end_input>\\n### ASSISTANT : <start_output> { \\n\\'Mason\\' : \\'4\\',} <end_output>\\n\\n### USER : <start_input> [\\'first\\', \\'Guangdong\\', \"the 1980\\'s\", \\'Peafowl Flying Towards the Southeast\\', \\'Guangdong\\'] in \\'\" Taking the first step \" in Guangdong \\'s reform and opening up in the 1980\\'s was closely related to the situation at that time of the \" Peafowl Flying Towards the Southeast \" -LRB- human talents from all over , one after another , going to Guangdong -RRB- .\\' <end_input>\\n### ASSISTANT : <start_output> { \\n\\'first\\' : \\'2\\',\\n   \\'Guangdong\\' : \\'E\\',\\n   \\'the 1980\\'s\\' : \\'6\\',\\n   \\'Peafowl Flying Towards the Southeast\\' : \\'3\\',\\n   \\'Guangdong\\' : \\'E\\',} <end_output>\\n\\n### USER : <start_input> [\\'People Patterns\\', \\'Sept. 20\\'] in \\'In response to your overly optimistic , outdated piece on how long unemployment lasts -LRB- People Patterns , Sept. 20 -RRB- : I am in the communications field , above entry level .\\' <end_input>\\n### ASSISTANT : <start_output> { \\n\\'People Patterns\\' : \\'3\\',\\n   \\'Sept. 20\\' : \\'6\\',} <end_output>\\n\\n### USER : <start_input> [\\'Alice Lu\\', \\'the International Family Life Education Center\\'] in \\'Life is a process that moves from the \" outward \" to the \" inward , \" says Alice Lu , director of the International Family Life Education Center , getting to the heart of the matter .\\' <end_input>\\n### ASSISTANT : <start_output> { \\n\\'Alice Lu\\' : \\'4\\',\\n   \\'the International Family Life Education Center\\' : \\'B\\',} <end_output>\\n\\n### USER : <start_input> [\\'Tim Boucher\\', \\'Fantastic Planet\\', \\'Peter Pan\\'] in \\'Some of the assumptions I \\'ve seen -LRB- such as a couple made by Tim Boucher and Fantastic Planet in last year \\'s postings linked here -RRB- may have looked like they worked to support their thesis , but in actuality have either a tenuous or no connection to the core Peter Pan mythos .\\' <end_input>\\n### ASSISTANT : <start_output> { \\n\\'Tim Boucher\\' : \\'4\\',\\n   \\'Fantastic Planet\\' : \\'B\\',\\n   \\'Peter Pan\\' : \\'4\\',} <end_output>\\n\\n### ASSISTANT : I take the named entities previously extracted in the sentence and add to each named entity one of the 18 character corresponding to one of the tags. Now provide me the list of extracted entities and the sentence ? \\n### USER : <start_input> \"A in l\" <end_input>\\n### ASSISTANT : <start_output> { ', 'None')] {\n",
      "Dongguan : ? //The character corresponsing to the entity tag\n",
      "   Taiwan : ? //The character corresponsing to the entity tag\n",
      "   Taiwanese : ? //The character corresponsing to the entity tag\n",
      "   Dongguan : ? //The character corresponsing to the entity tag\n",
      "   the last ten years : ? //The character corresponsing to the entity tag\n",
      "}\n",
      "----------------------------------------------------\n",
      "---------------------prompt++---------------------\n",
      "\n",
      "[('### SYSTEM : The task is to tag all the named entites that were extracted from a sentence.\\n    A named entity refers to a specific, named object, concept, location, person, organization, or other entities that have a proper name. Named entities are typically unique and distinguishable entities that can be explicitly named or referred to in text. Named entities are stopwords like \\'the\\', verbs like \\'serving\\' or question words like \\'why\\'. \\n    The goal of named entity extraction is to identify and classify these entities within a given text.\\n    We are working with 18 types of entities of the OntoNote5 dataset that are listed below with their description :\\n        \"CARDINAL\": \"Numerals that do not fall under another type (e.g. 1, 100, twenty-nine).\",\\n        \"ORDINAL\": \"Words or expressions indicating order (e.g. first, 60th).\",\\n        \"WORK_OF_ART\": \"Titles of creative works like books, films or artistic work.\",\\n        \"PERSON\": \"Names of people, including fictional and real characters.\",\\n        \"LOC\": \"Geographical locations, both physical and political.\",\\n        \"DATE\": \"Temporal expressions indicating dates or periods, weekday, months,\",\\n        \"PERCENT\": \"Percentage values (e.g. 70%).\",\\n        \"PRODUCT\": \"Names of products or services.\",\\n        \"MONEY\": \"Monetary values, including currency symbols.\",\\n        \"FAC\": \"Named facilities, such as buildings, airports, or highways.\",\\n        \"TIME\": \"Temporal expressions indicating times of the day.\",\\n        \"ORG\": \"Names of organizations, institutions, or companies.\",\\n        \"QUANTITY\": \"Measurements or counts, including units (e.g. 10 grams, 1 litre)\",\\n        \"LANGUAGE\": \"Names of languages.\",\\n        \"GPE\": \"Geopolitical entities, such as countries, cities, or states.\",\\n        \"LAW\": \"Legal references, including laws and legal concepts.\",\\n        \"NORP\": \"Nationalities, religious group, or political groups. Can be adjective for nationality like \"Canadian\".\",\\n        \"EVENT\": \"Named occurrences and social, political, cultural, or genera incidents.\\n### USER : I want you to tag the named entites that were extracted from a sentence with the following character :  \\n    \\'1\\' for \\'CARDINAL\\' entities,\\n    \\'2\\' for \\'ORDINAL\\' entities,\\n    \\'3\\' for \\'WORK_OF_ART\\' entities,\\n    \\'4\\' for \\'PERSON\\' entities,\\n    \\'5\\' for \\'LOC\\' entities,\\n    \\'6\\' for \\'DATE\\' entities,\\n    \\'7\\' for \\'PERCENT\\' entities,\\n    \\'8\\' for \\'PRODUCT\\' entities,\\n    \\'9\\' for \\'MONEY\\' entities,\\n    \\'0\\' for \\'FAC\\' entities,\\n    \\'A\\' for \\'TIME\\' entities,\\n    \\'B\\' for \\'ORG\\' entities,\\n    \\'C\\' for \\'QUANTITY\\' entities,\\n    \\'D\\' for \\'LANGUAGE\\' entities,\\n    \\'E\\' for \\'GPE\\' entities,\\n    \\'F\\' for \\'LAW\\' entities,\\n    \\'G\\' for \\'NORP\\' entities,\\n    \\'H\\' for \\'EVENT\\' entities\\n### ASSISTANT : What is the format of the output ?\\n### USER : Output a json with the named entities as keys and the tag as values. For example, with the input \"[Japan]\" in \"Japan is a country\", you would answer \\'{ \"Japan\" : \"E\" }\\'. \\n### ASSISTANT : Can you provide me examples ?  \\n### USER : There are examples : \\n### USER : <start_input> [\\'Mason\\'] in \\'The question is , if group conflicts still exist -LRB- as undeniably they do -RRB- , and if Mr. Mason \\'s type of ethnic humor is passe , then what other means do we have for letting off steam ?\\' <end_input>\\n### ASSISTANT : <start_output> { \\n\\'Mason\\' : \\'4\\',} <end_output>\\n\\n### USER : <start_input> [\\'first\\', \\'Guangdong\\', \"the 1980\\'s\", \\'Peafowl Flying Towards the Southeast\\', \\'Guangdong\\'] in \\'\" Taking the first step \" in Guangdong \\'s reform and opening up in the 1980\\'s was closely related to the situation at that time of the \" Peafowl Flying Towards the Southeast \" -LRB- human talents from all over , one after another , going to Guangdong -RRB- .\\' <end_input>\\n### ASSISTANT : <start_output> { \\n\\'first\\' : \\'2\\',\\n   \\'Guangdong\\' : \\'E\\',\\n   \\'the 1980\\'s\\' : \\'6\\',\\n   \\'Peafowl Flying Towards the Southeast\\' : \\'3\\',\\n   \\'Guangdong\\' : \\'E\\',} <end_output>\\n\\n### USER : <start_input> [\\'People Patterns\\', \\'Sept. 20\\'] in \\'In response to your overly optimistic , outdated piece on how long unemployment lasts -LRB- People Patterns , Sept. 20 -RRB- : I am in the communications field , above entry level .\\' <end_input>\\n### ASSISTANT : <start_output> { \\n\\'People Patterns\\' : \\'3\\',\\n   \\'Sept. 20\\' : \\'6\\',} <end_output>\\n\\n### USER : <start_input> [\\'Alice Lu\\', \\'the International Family Life Education Center\\'] in \\'Life is a process that moves from the \" outward \" to the \" inward , \" says Alice Lu , director of the International Family Life Education Center , getting to the heart of the matter .\\' <end_input>\\n### ASSISTANT : <start_output> { \\n\\'Alice Lu\\' : \\'4\\',\\n   \\'the International Family Life Education Center\\' : \\'B\\',} <end_output>\\n\\n### USER : <start_input> [\\'Tim Boucher\\', \\'Fantastic Planet\\', \\'Peter Pan\\'] in \\'Some of the assumptions I \\'ve seen -LRB- such as a couple made by Tim Boucher and Fantastic Planet in last year \\'s postings linked here -RRB- may have looked like they worked to support their thesis , but in actuality have either a tenuous or no connection to the core Peter Pan mythos .\\' <end_input>\\n### ASSISTANT : <start_output> { \\n\\'Tim Boucher\\' : \\'4\\',\\n   \\'Fantastic Planet\\' : \\'B\\',\\n   \\'Peter Pan\\' : \\'4\\',} <end_output>\\n\\n### ASSISTANT : I take the named entities previously extracted in the sentence and add to each named entity one of the 18 character corresponding to one of the tags. Now provide me the list of extracted entities and the sentence ? \\n### USER : <start_input> \"A in l\" <end_input>\\n### ASSISTANT : <start_output> { ', 'None')] {\n",
      "Dongguan : ? //The character corresponsing to the entity tag\n",
      "   Taiwan : ? //The character corresponsing to the entity tag\n",
      "   Taiwanese : ? //The character corresponsing to the entity tag\n",
      "   Dongguan : ? //The character corresponsing to the entity tag\n",
      "   the last ten years : ? //The character corresponsing to the entity tag\n",
      "}\n",
      "----------------------------------------------------\n",
      "\n",
      "------------get-entities-------------------------\n",
      "---------------------raw---------------------\n",
      "\n",
      "[('### SYSTEM : The task is to extract named entities in a sentence.\\n    The types of the entities have to be one of the OntoNote5 dataset that you can find here : [\\'CARDINAL\\', \\'ORDINAL\\', \\'WORK_OF_ART\\', \\'PERSON\\', \\'LOC\\', \\'DATE\\', \\'PERCENT\\', \\'PRODUCT\\', \\'MONEY\\', \\'FAC\\', \\'TIME\\', \\'ORG\\', \\'QUANTITY\\', \\'LANGUAGE\\', \\'GPE\\', \\'LAW\\', \\'NORP\\', \\'EVENT\\'].\\n### USER : I want you to extract all the named entities in the text that could be tagged by one of the tag of the OntoNote5 dataset.\\n### ASSISTANT : What is the format of the output ?\\n### USER : I want you to output a python list of STRINGs that contains all the named entities in the sentence. For example, with the sentence \"Japan is a country\" as input, you would answer \"[\\'Japan\\']\". \\n### ASSISTANT : Can you provide me examples ?  \\n### USER : There are examples : \\n### USER : <start_input> With 3,000 Taiwan - owned businesses here , and 10 - 20,000 Taiwanese business people and their dependants coming in and out every day , the Dong - guan area has already developed an economic circle in which Taiwan firms can conduct most of their business among themselves . <end_input>\\n### ASSISTANT : <start_output> [\\'3,000\\', \\'Taiwan\\', \\'10 - 20,000\\', \\'Taiwanese\\', \\'Dong - guan\\', \\'Taiwan\\'] <end_output>\\n\\n### USER : <start_input> Invoking the Taiwanese business battle cry of \" victory to those who strive the hardest , \" 20,000 - 30,000 Taiwan expats in Dongguan have in little more than a decade turned a county of banana and lichee plantations into a big city with exports behind only Shenzhen \\'s and Shanghai \\'s . <end_input>\\n### ASSISTANT : <start_output> [\\'Taiwanese\\', \\'20,000\\', \\'30,000\\', \\'Taiwan\\', \\'Dongguan\\', \\'Shenzhen\\', \\'Shanghai\\'] <end_output>\\n\\n### USER : <start_input> Although the Taiwan firms in Dongguan have left home , their success can largely be attributed to an ethos they transplanted from Taiwan - that \" victory goes to those who strive the hardest . \" <end_input>\\n### ASSISTANT : <start_output> [\\'Taiwan\\', \\'Dongguan\\', \\'Taiwan\\'] <end_output>\\n\\n### USER : <start_input> With 27 departures a day , these buses run by a Taiwan firm out of Dongguan take Taiwan expats to their adopted home , which boasts the largest concentration of Taiwan firms in the PRC . <end_input>\\n### ASSISTANT : <start_output> [\\'27\\', \\'Taiwan\\', \\'Dongguan\\', \\'Taiwan\\', \\'Taiwan\\', \\'PRC\\'] <end_output>\\n\\n### USER : <start_input> \" We make our money here , but we pay taxes in Taiwan , and most of our families and children do most of their consumer spending in Taiwan , \" insists TBAD chairperson Chang Mei - liang . <end_input>\\n### ASSISTANT : <start_output> [\\'Taiwan\\', \\'Taiwan\\', \\'TBAD\\', \\'Chang Mei - liang\\'] <end_output>\\n\\n### ASSISTANT : Ok now I understand I need to only output a list with all the named entities. Now provide me the sentence. \\n### USER : <start_input> Although low land and labor costs are Dongguan \\'s main attractions , Taiwan firms also choose the locale for the networks of people and producers that have been built up among Taiwanese in Dongguan over the last ten years . <end_input>\\n### ASSISTANT : <start_output> [', 'None')] ['Dongguan', 'Taiwan', 'Taiwanese', 'Dongguan', 'the last ten years']\n",
      "----------------------------------------------------\n",
      "---------------------prompt++---------------------\n",
      "\n",
      "[('### SYSTEM : The task is to extract named entities in a sentence.\\n    A named entity refers to a specific, named object, concept, location, person, organization, or other entities that have a proper name. Named entities are typically unique and distinguishable entities that can be explicitly named or referred to in text. Named entities are stopwords like \\'the\\', verbs like \\'serving\\' or question words like \\'why\\'. \\n    The goal of named entity extraction is to identify and classify these entities within a given text.\\n    We are working with 18 types of entities of the OntoNote5 dataset that are listed below with their description :\\n        \"CARDINAL\": \"Numerals that do not fall under another type (e.g. 1, 100, twenty-nine).\",\\n        \"ORDINAL\": \"Words or expressions indicating order (e.g. first, 60th).\",\\n        \"WORK_OF_ART\": \"Titles of creative works like books, films or artistic work.\",\\n        \"PERSON\": \"Names of people, including fictional and real characters.\",\\n        \"LOC\": \"Geographical locations, both physical and political.\",\\n        \"DATE\": \"Temporal expressions indicating dates or periods, weekday, months,\",\\n        \"PERCENT\": \"Percentage values (e.g. 70%).\",\\n        \"PRODUCT\": \"Names of products or services.\",\\n        \"MONEY\": \"Monetary values, including currency symbols.\",\\n        \"FAC\": \"Named facilities, such as buildings, airports, or highways.\",\\n        \"TIME\": \"Temporal expressions indicating times of the day.\",\\n        \"ORG\": \"Names of organizations, institutions, or companies.\",\\n        \"QUANTITY\": \"Measurements or counts, including units (e.g. 10 grams, 1 litre)\",\\n        \"LANGUAGE\": \"Names of languages.\",\\n        \"GPE\": \"Geopolitical entities, such as countries, cities, or states.\",\\n        \"LAW\": \"Legal references, including laws and legal concepts.\",\\n        \"NORP\": \"Nationalities, religious group, or political groups. Can be adjective for nationality like \"Canadian\".\",\\n        \"EVENT\": \"Named occurrences and social, political, cultural, or genera incidents.\\n### USER : I want you to extract all the named entities in the text that could be tagged by one of the tag of the OntoNote5 dataset.\\n### ASSISTANT : What is the format of the output ?\\n### USER : I want you to output a python list of STRINGs that contains all the named entities in the sentence. For example, with the sentence \"Japan is a country\" as input, you would answer \"[\\'Japan\\']\". \\n### ASSISTANT : Can you provide me examples ?  \\n### USER : There are examples : \\n### USER : <start_input> With 3,000 Taiwan - owned businesses here , and 10 - 20,000 Taiwanese business people and their dependants coming in and out every day , the Dong - guan area has already developed an economic circle in which Taiwan firms can conduct most of their business among themselves . <end_input>\\n### ASSISTANT : <start_output> [\\'3,000\\', \\'Taiwan\\', \\'10 - 20,000\\', \\'Taiwanese\\', \\'Dong - guan\\', \\'Taiwan\\'] <end_output>\\n\\n### USER : <start_input> Invoking the Taiwanese business battle cry of \" victory to those who strive the hardest , \" 20,000 - 30,000 Taiwan expats in Dongguan have in little more than a decade turned a county of banana and lichee plantations into a big city with exports behind only Shenzhen \\'s and Shanghai \\'s . <end_input>\\n### ASSISTANT : <start_output> [\\'Taiwanese\\', \\'20,000\\', \\'30,000\\', \\'Taiwan\\', \\'Dongguan\\', \\'Shenzhen\\', \\'Shanghai\\'] <end_output>\\n\\n### USER : <start_input> Although the Taiwan firms in Dongguan have left home , their success can largely be attributed to an ethos they transplanted from Taiwan - that \" victory goes to those who strive the hardest . \" <end_input>\\n### ASSISTANT : <start_output> [\\'Taiwan\\', \\'Dongguan\\', \\'Taiwan\\'] <end_output>\\n\\n### USER : <start_input> With 27 departures a day , these buses run by a Taiwan firm out of Dongguan take Taiwan expats to their adopted home , which boasts the largest concentration of Taiwan firms in the PRC . <end_input>\\n### ASSISTANT : <start_output> [\\'27\\', \\'Taiwan\\', \\'Dongguan\\', \\'Taiwan\\', \\'Taiwan\\', \\'PRC\\'] <end_output>\\n\\n### USER : <start_input> \" We make our money here , but we pay taxes in Taiwan , and most of our families and children do most of their consumer spending in Taiwan , \" insists TBAD chairperson Chang Mei - liang . <end_input>\\n### ASSISTANT : <start_output> [\\'Taiwan\\', \\'Taiwan\\', \\'TBAD\\', \\'Chang Mei - liang\\'] <end_output>\\n\\n### ASSISTANT : Ok now I understand I need to only output a list with all the named entities. Now provide me the sentence. \\n### USER : <start_input> Although low land and labor costs are Dongguan \\'s main attractions , Taiwan firms also choose the locale for the networks of people and producers that have been built up among Taiwanese in Dongguan over the last ten years . <end_input>\\n### ASSISTANT : <start_output> [', 'None')] ['Dongguan', 'Taiwan', 'Taiwanese', 'Dongguan', 'the last ten years']\n",
      "----------------------------------------------------\n",
      "\n",
      "------------@@##-------------------------\n",
      "---------------------raw---------------------\n",
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'C'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/myhome/Master-thesis/analysing_results.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B127.0.0.1/myhome/Master-thesis/analysing_results.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m LLMModel\u001b[39m.\u001b[39;49mshow_prompts()\n",
      "File \u001b[0;32m/myhome/Master-thesis/llm/LLMModel.py:112\u001b[0m, in \u001b[0;36mLLMModel.show_prompts\u001b[0;34m(pts, nb_few_shots, verifier, dataset_loader, tags, with_gold)\u001b[0m\n\u001b[1;32m    110\u001b[0m pt \u001b[39m=\u001b[39m i_pt(fst, with_precision \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, prompt_template \u001b[39m=\u001b[39m prompt_template_ontonotes, plus_plus \u001b[39m=\u001b[39m plus_plus)\n\u001b[1;32m    111\u001b[0m gold \u001b[39m=\u001b[39m pt\u001b[39m.\u001b[39mget_gold(data_test, tag \u001b[39m=\u001b[39m tags[\u001b[39m0\u001b[39m])\n\u001b[0;32m--> 112\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlatex_escape(pt\u001b[39m.\u001b[39;49mget_prompts_runnable(data_test[\u001b[39m0\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39mtext\u001b[39;49m\u001b[39m'\u001b[39;49m],\u001b[39m \u001b[39;49mtags[\u001b[39m0\u001b[39;49m][\u001b[39m0\u001b[39;49m]))\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mgold[\u001b[39m0\u001b[39m]\u001b[39m \u001b[39m\u001b[39mif\u001b[39;00m\u001b[39m \u001b[39mwith_gold\u001b[39m \u001b[39m\u001b[39melse\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    113\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m----------------------------------------------------\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/myhome/Master-thesis/ner/llm_ner/prompt_techniques/pt_gpt_ner.py:32\u001b[0m, in \u001b[0;36mPT_GPT_NER.get_prompts_runnable\u001b[0;34m(self, sentence, tags)\u001b[0m\n\u001b[1;32m     30\u001b[0m prompts \u001b[39m=\u001b[39m []\n\u001b[1;32m     31\u001b[0m \u001b[39mfor\u001b[39;00m tag \u001b[39min\u001b[39;00m tags :\n\u001b[0;32m---> 32\u001b[0m     few_shots \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_few_shots(sentence, tag, nearest_neighbors)\n\u001b[1;32m     33\u001b[0m     prompt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprompt_template[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__str__\u001b[39m()]\u001b[39m.\u001b[39mformat(tag\u001b[39m=\u001b[39mmapping_abbr_string_ner[tag], \n\u001b[1;32m     34\u001b[0m                                 precision \u001b[39m=\u001b[39m precision_ner[tag]\u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(tags) \u001b[39m==\u001b[39m \u001b[39m4\u001b[39m \u001b[39melse\u001b[39;00m ONTONOTE5_TAGS_PRECISION[tag],\n\u001b[1;32m     35\u001b[0m                                 few_shots \u001b[39m=\u001b[39m few_shots,\n\u001b[1;32m     36\u001b[0m                                 sentence \u001b[39m=\u001b[39m sentence)\n\u001b[1;32m     37\u001b[0m     prompts\u001b[39m.\u001b[39mappend(prompt)\n",
      "File \u001b[0;32m/myhome/Master-thesis/ner/llm_ner/prompt_techniques/pt_abstract.py:80\u001b[0m, in \u001b[0;36mPromptTechnique.get_few_shots\u001b[0;34m(self, sentence, tag, nearest_neighbors)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_few_shots\u001b[39m(\u001b[39mself\u001b[39m, sentence : \u001b[39mstr\u001b[39m, tag : \u001b[39mstr\u001b[39m, nearest_neighbors : \u001b[39mlist\u001b[39m)\u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[0;32m---> 80\u001b[0m     nearest_neighbors \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprocess_nearest_neighbors(nearest_neighbors, tag)\n\u001b[1;32m     81\u001b[0m     nearest_neighbors \u001b[39m=\u001b[39m [nn \u001b[39mfor\u001b[39;00m nn \u001b[39min\u001b[39;00m nearest_neighbors \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m{\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m nn[\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mand\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m}\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m nn[\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m]]\n\u001b[1;32m     82\u001b[0m     \u001b[39mif\u001b[39;00m nearest_neighbors :\n",
      "File \u001b[0;32m/myhome/Master-thesis/ner/llm_ner/prompt_techniques/pt_gpt_ner.py:22\u001b[0m, in \u001b[0;36mPT_GPT_NER.process_nearest_neighbors\u001b[0;34m(self, nearest_neighbors, tag)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprocess_nearest_neighbors\u001b[39m(\u001b[39mself\u001b[39m, nearest_neighbors :\u001b[39mlist\u001b[39m, tag):\n\u001b[0;32m---> 22\u001b[0m     nearest_neighbors \u001b[39m=\u001b[39m [{\n\u001b[1;32m     23\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m : row[\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     24\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39moutput_text\u001b[39m\u001b[39m\"\u001b[39m : row[\u001b[39m'\u001b[39m\u001b[39mllama_text\u001b[39m\u001b[39m'\u001b[39m][tag]} \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m nearest_neighbors]\n\u001b[1;32m     25\u001b[0m     \u001b[39mreturn\u001b[39;00m nearest_neighbors\n",
      "File \u001b[0;32m/myhome/Master-thesis/ner/llm_ner/prompt_techniques/pt_gpt_ner.py:24\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprocess_nearest_neighbors\u001b[39m(\u001b[39mself\u001b[39m, nearest_neighbors :\u001b[39mlist\u001b[39m, tag):\n\u001b[1;32m     22\u001b[0m     nearest_neighbors \u001b[39m=\u001b[39m [{\n\u001b[1;32m     23\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m : row[\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m---> 24\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39moutput_text\u001b[39m\u001b[39m\"\u001b[39m : row[\u001b[39m'\u001b[39;49m\u001b[39mllama_text\u001b[39;49m\u001b[39m'\u001b[39;49m][tag]} \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m nearest_neighbors]\n\u001b[1;32m     25\u001b[0m     \u001b[39mreturn\u001b[39;00m nearest_neighbors\n",
      "\u001b[0;31mKeyError\u001b[0m: 'C'"
     ]
    }
   ],
   "source": [
    "LLMModel.show_prompts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at results of confidence with the tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ner.utils import load\n",
    "\n",
    "res = load (\"ner/saves/results/conll2003_cleaned/mistral-7b-v0.1/multi_prompt-get-entities-tagger/sentence_3_None_1538_50_1_False.pkl\")\n",
    "\n",
    "cm, f1, precision, recall, y_true, y_pred, y_conf= res.res_insts[0].get_scores(with_y = True)\n",
    "conf = []\n",
    "for sent in res.res_insts[0].results:\n",
    "    conf.extend([s[2] for s in sent])\n",
    "\n",
    "len(y_conf), len(y_true), len(y_pred)\n",
    "# [i for i, tag in enumerate(y_pred) if tag == 'None']\n",
    "right = [y_true[i] == y_pred[i] for i in range(len(y_true))]\n",
    "rand = [i for i in range(len(right))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Example list\n",
    "my_list = list(zip(y_conf, right))\n",
    "\n",
    "# Use Counter to count occurrences\n",
    "entry_counts = Counter(sorted(my_list))\n",
    "\n",
    "# Print the counts\n",
    "for entry, count in entry_counts.items():\n",
    "    print(f'{entry}: {count} times')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "df_conf = pd.DataFrame(np.array([right, y_conf]).T, columns = ['Right', 'Confidence'])\n",
    "\n",
    "df_conf = pd.DataFrame(df_conf.groupby(['Right', 'Confidence'])['Right'].count()).rename(columns = {'Right' : \"count\"}).reset_index()\n",
    "sns.set(rc={'figure.figsize':(10,10)})\n",
    "order = ['high', 'medium-high', 'medium', 'medium-low', 'low']\n",
    "sns.catplot(data=df_conf, x=\"Confidence\", y=\"count\", hue=\"Right\", kind=\"bar\",aspect=1.5, order = order)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing specific result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ResultInstance' object has no attribute 'tags'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/myhome/Master-thesis/analysing_results.ipynb Cell 18\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B127.0.0.1/myhome/Master-thesis/analysing_results.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m result \u001b[39m=\u001b[39m load_result(model, PT_OutputList\u001b[39m.\u001b[39mname(), FST_Sentence\u001b[39m.\u001b[39mname(), nb_few_shots\u001b[39m=\u001b[39m \u001b[39m10\u001b[39m, with_precision \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m10_True\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B127.0.0.1/myhome/Master-thesis/analysing_results.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m result\u001b[39m.\u001b[39mres_insts :\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B127.0.0.1/myhome/Master-thesis/analysing_results.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     r\u001b[39m.\u001b[39;49mshow_cm()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B127.0.0.1/myhome/Master-thesis/analysing_results.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     r\u001b[39m.\u001b[39manalyse_results()\n",
      "File \u001b[0;32m/myhome/Master-thesis/ner/llm_ner/ResultInstance.py:41\u001b[0m, in \u001b[0;36mResultInstance.show_cm\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mshow_cm\u001b[39m(\u001b[39mself\u001b[39m) :\n\u001b[0;32m---> 41\u001b[0m     show_cm_multi(\u001b[39m*\u001b[39m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_scores(), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, tags \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtags)\n",
      "File \u001b[0;32m/myhome/Master-thesis/ner/llm_ner/ResultInstance.py:34\u001b[0m, in \u001b[0;36mResultInstance.get_scores\u001b[0;34m(self, with_y)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_scores\u001b[39m(\u001b[39mself\u001b[39m, with_y \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m     33\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf1 :\n\u001b[0;32m---> 34\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcm, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf1, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprecision, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrecall, y_true, y_pred, nes \u001b[39m=\u001b[39m get_metrics_all(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgold, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtags)\n\u001b[1;32m     35\u001b[0m     \u001b[39mif\u001b[39;00m with_y :\n\u001b[1;32m     36\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcm, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf1, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprecision, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrecall, y_true, y_pred\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ResultInstance' object has no attribute 'tags'"
     ]
    }
   ],
   "source": [
    "model  = \"mistral-7b-v0.1\"\n",
    "result = load_result(model, PT_OutputList.name(), FST_Sentence.name(), nb_few_shots= 10, with_precision = \"10_True\")\n",
    "\n",
    "for r in result.res_insts :\n",
    "    r.show_cm()\n",
    "    r.analyse_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ner.Datasets.Conll2003Dataset import Conll2003Dataset\n",
    "from ner.Datasets.MyDataset import MyDataset\n",
    "data = MyDataset.my_load_dataset(dataset=Conll2003Dataset, split = 'test', cleaned= True)\n",
    "[(d['text'], d['spans']) for d in data if str(d['spans']) == \"\"\"[['Switzerland', 'LOC'], [\"Alfonse D'Amato\", 'PER'], ['U.S. Senate Banking Committee', 'ORG'], ['Poland', 'LOC'], ['Polish', 'MISC'], ['Swiss', 'MISC'], ['Poland', 'LOC']]\"\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(d['text'], d['spans']) for d in data if 'Hansenne' in d['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

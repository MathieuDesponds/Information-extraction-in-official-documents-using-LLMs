{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ner.Datasets.utils import *\n",
    "from ner.Datasets.Conll2003Dataset import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_tr = Conll2003Dataset(utils, split = 'train')\n",
    "# data_te = Conll2003Dataset(utils, split = 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data_te = Conll2003Dataset(split = 'test', cleaned = True)\n",
    "clean_data_tr = Conll2003Dataset(split = 'train', cleaned = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_conll_dataset(clean_data_te)\n",
    "save_conll_dataset(clean_data_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = load_conll_dataset(cleaned= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train.dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing datasets for finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function <lambda> at 0x7f1aed503eb0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a724e0d734b449cb9711a3e984b19205",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ner.utils import load, dump\n",
    "from llm.LLMModel import MistralAIInstruct\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "model = MistralAIInstruct(without_model=True)\n",
    "\n",
    "dataset = load(\"ner/saves/datasets/conll2003_for-ft_cleaned_discussion_2000.pkl\")\n",
    "# dataset[0]['text']\n",
    "dataset = dataset.map(lambda row : {'text' : model.construct_prompt_for_mistralAIInstruct(row['text']) })\n",
    "dump(dataset, \"ner/saves/datasets/conll2003_for-ft_cleaned_discussion_mistral-instruct_2000.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '<s>[INST] The task is to extract all the named entites in the following sentence.\\nYour goal is to extract all the enities that are either person, organization, location or miscallaneous and output the entities in a list of tuples. In each tuple put the named entity and the tag alongside it.\\n [/INST]Yes I can do that. Can you provide me examples ?  \\n</s>[INST] Yes of course, there are some examples : \\n<start_input> Yr / yr rise ( % ) +1.2 +1.5 +7.1 119.6 - <end_input>\\n [/INST]<start_output> [] <end_output>\\n\\nOk now I understand I need to only output a list with the entities that are in the sentence and the tag along it. Can you now provide me the sentence ? \\n</s>[INST] <start_input> PPI ( pct ) June +0.7 m / m;+21.5yr / yr ( May +1.7;+22.0 ) <end_input>\\n [/INST]<start_output> [] <end_output></s>'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ner.llm_ner.prompt_techniques import *\n",
    "\n",
    "runs = 2000\n",
    "pt = PT_GPT_NER(None)\n",
    "res2 = pt.process_dataset_for_finetuning(runs=runs)\n",
    "pt = PT_OutputList(None)\n",
    "res2 = pt.process_dataset_for_finetuning(runs=runs)\n",
    "pt = PT_Wrapper(None)\n",
    "res2 = pt.process_dataset_for_finetuning(runs=runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing few-shots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_train, dataset_llama_50 = load_conll_dataset(split = 'test')\n",
    "# dataset_test = load_conll_dataset(split = 'test', cleaned=True)\n",
    "dataset_test_train, dataset_test_test = dataset_test.train_test_split(test_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ner.Llama2_NER import Llama2_NER_FewShots_Entity\n",
    "ner_ent = Llama2_NER_FewShots_Entity(None, utils, dataset_test_train, nb_few_shots= 16, with_verify=False, prompt_type=\"discussion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_llama_50.select([8,10,22,24,25,44,49])\n",
    "for i, sample in enumerate(dataset_test_test) :\n",
    "    print(sample['text'])\n",
    "    print(sample['spans'])\n",
    "    print(ner_ent.get_prompts(sample['text'], [], 5))\n",
    "    print()\n",
    "    print(\"----------------------------------------------------\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

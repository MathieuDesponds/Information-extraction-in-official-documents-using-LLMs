{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "\n",
    "from myMongoClient import MyMongoClient, BANQUE_DOCUMENT_FOLDER\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = \"documents-100039\"\n",
    "organisation_id = int(db[-6:])\n",
    "\n",
    "mongo_client = MyMongoClient(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "\n",
    "nlp_spacy = spacy.load(\"en_core_web_trf\")\n",
    "\n",
    "# Function to extract entities from a given text using SpaCy\n",
    "def extract_entities_spacy(text, split_paragraph):\n",
    "    texts = text.split('\\n') if split_paragraph else [text]\n",
    "    entities = []\n",
    "    for text in texts :\n",
    "        if text :\n",
    "            doc = nlp_spacy(text)\n",
    "            entities.extend([(ent.text, ent.label_, ent.label_) for ent in doc.ents])\n",
    "    return entities\n",
    "\n",
    "\n",
    "tagger_flair_ontonote = SequenceTagger.load(\"flair/ner-english-ontonotes\")\n",
    "\n",
    "# Function to extract entities from a given text using Flair\n",
    "def extract_entities_flair(text, tagger, split_paragraph = False):\n",
    "    texts = text.split('\\n') if split_paragraph else [text]\n",
    "    entities = []\n",
    "    for text in texts :\n",
    "        if text :\n",
    "            sentence = Sentence(text)\n",
    "            tagger.predict(sentence)\n",
    "            entities.extend([(entity.text, entity.get_labels()[0].value) for entity in sentence.get_spans('ner')])\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from myMongoClient import MyMongoClient, load, dump\n",
    "gold_labels = load(\"data/labels_results/2024-02-02-gold_labels_filenames_clean.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_documents(path) :\n",
    "    documents = {}\n",
    "    for doc in mongo_client.get_all_documents(BANQUE_DOCUMENT_FOLDER):\n",
    "        doc_id = doc['_id']\n",
    "        doc_content = mongo_client.get_document_content(document_id=doc_id)\n",
    "        # entities = extract_entities_flair(doc_content, tagger_flair_ontonote, split_paragraph= True)\n",
    "        entities = extract_entities_spacy(doc_content, split_paragraph= True)\n",
    "        documents[doc_id] = {'doc_content' : doc_content,\n",
    "                              'entities' : entities, \n",
    "                            #   'entities_full_doc' : extract_entities_spacy(doc_content, tagger_flair_ontonote, split_paragraph= False),\n",
    "                              'entities_full_doc' : extract_entities_spacy(doc_content, split_paragraph= False),\n",
    "                              'gold_labels' : gold_labels['labels'][doc_id] if doc_id in gold_labels['labels'] else {}}\n",
    "    dump(documents, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path =  \"data/labels_results/documents_spacy_entities.pkl\"\n",
    "documents = dump_documents(path) #load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = documents['NP7dYhy+sWTjSoVq5wi4SQ==']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime \n",
    "def is_valid_date(date_string):\n",
    "    try:\n",
    "        # Attempt to parse the date string\n",
    "        date = datetime.fromisoformat(date_string).strftime('%Y-%m-%d')\n",
    "        return date\n",
    "    except ValueError:\n",
    "        # If the parsing fails, it's not a valid date\n",
    "        return False\n",
    "    \n",
    "def is_float(value):\n",
    "    try:\n",
    "        float_string = value.replace(\"'\", \"\")\n",
    "        float_string = float_string.replace(\",\", \".\")\n",
    "        float_value = float(float_string)\n",
    "        return float_value\n",
    "    except ValueError:\n",
    "        return False\n",
    "    \n",
    "def is_int(value):\n",
    "    try:\n",
    "        int_string = value.replace(\"'\", \"\")\n",
    "        int_value = int(int_string)\n",
    "        return int_value\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def parse_values(value) :\n",
    "    date = is_valid_date(value)\n",
    "    if date :\n",
    "        return date\n",
    "\n",
    "    int_val = is_int(value)\n",
    "    if int_val :\n",
    "        return int_val\n",
    "    \n",
    "    float_val = is_float(value)\n",
    "    value = float_val if float_val else value\n",
    "\n",
    "    return value\n",
    "\n",
    "nb_value_checked, value_found_split, value_found_doc = {},{}, {}\n",
    "for doc_id, doc in documents.items():\n",
    "    entities = set([parse_values(ent) for ent, tag in doc['entities']])\n",
    "    entities_full_doc = set([parse_values(ent) for ent, tag in doc['entities_full_doc']])\n",
    "    gold_values = [(gold_label,parse_values(gold_value)) for gold_label, gold_value in doc['gold_labels'].items() \n",
    "                   if gold_label not in ['language', 'client', 'document type','immeuble']]\n",
    "\n",
    "    for gold_label, gold_value in gold_values :\n",
    "        value_split, value_doc = int(gold_value in entities), int(gold_value in entities_full_doc)\n",
    "        value_found_split[gold_label] = value_found_split[gold_label] + value_split if gold_label in value_found_split else value_split\n",
    "        value_found_doc[gold_label] = value_found_doc[gold_label] + value_doc if gold_label in value_found_doc else value_doc\n",
    "        nb_value_checked[gold_label] = nb_value_checked[gold_label] + 1 if gold_label in nb_value_checked else 1\n",
    "\n",
    "score_by_field_split = {key : val/nb_value_checked[key] for key, val in value_found_split.items()}\n",
    "score_by_field_doc = {key : val/nb_value_checked[key] for key, val in value_found_doc.items()}\n",
    "score_split = sum(value_found_split.values())/sum(nb_value_checked.values())\n",
    "score_doc = sum(value_found_doc.values())/sum(nb_value_checked.values())\n",
    "\n",
    "score_split,score_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-05 16:20:49.978495: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-05 16:20:50.838518: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "\n",
    "from myMongoClient import MyMongoClient, BANQUE_DOCUMENT_FOLDER\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = \"documents-100039\"\n",
    "organisation_id = int(db[-6:])\n",
    "\n",
    "mongo_client = MyMongoClient(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-05 16:21:41,202 SequenceTagger predicts: Dictionary with 75 tags: O, S-PERSON, B-PERSON, E-PERSON, I-PERSON, S-GPE, B-GPE, E-GPE, I-GPE, S-ORG, B-ORG, E-ORG, I-ORG, S-DATE, B-DATE, E-DATE, I-DATE, S-CARDINAL, B-CARDINAL, E-CARDINAL, I-CARDINAL, S-NORP, B-NORP, E-NORP, I-NORP, S-MONEY, B-MONEY, E-MONEY, I-MONEY, S-PERCENT, B-PERCENT, E-PERCENT, I-PERCENT, S-ORDINAL, B-ORDINAL, E-ORDINAL, I-ORDINAL, S-LOC, B-LOC, E-LOC, I-LOC, S-TIME, B-TIME, E-TIME, I-TIME, S-WORK_OF_ART, B-WORK_OF_ART, E-WORK_OF_ART, I-WORK_OF_ART, S-FAC\n"
     ]
    }
   ],
   "source": [
    "tagger_flair_ontonote = SequenceTagger.load(\"flair/ner-english-ontonotes\")\n",
    "\n",
    "# Function to extract entities from a given text using Flair\n",
    "def extract_entities_flair(text, tagger, split_paragraph = False):\n",
    "    texts = text.split('\\n') if split_paragraph else [text]\n",
    "    entities = []\n",
    "    for text in texts :\n",
    "        if text :\n",
    "            sentence = Sentence(text)\n",
    "            tagger.predict(sentence)\n",
    "            entities.extend([(entity.text, entity.get_labels()[0].value) for entity in sentence.get_spans('ner')])\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from myMongoClient import MyMongoClient, load, dump\n",
    "gold_labels = load(\"data/labels_results/2024-02-02-gold_labels_filenames_clean.pkl\")\n",
    "documents = load(\"data/labels_results/documents_flair_entities.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_documents() :\n",
    "    documents = {}\n",
    "    for doc in mongo_client.get_all_documents(BANQUE_DOCUMENT_FOLDER):\n",
    "        doc_id = doc['_id']\n",
    "        doc_content = mongo_client.get_document_content(document_id=doc_id)\n",
    "        entities = extract_entities_flair(doc_content, tagger_flair_ontonote, split_paragraph= True)\n",
    "        documents[doc_id] = {'doc_content' : doc_content,\n",
    "                              'entities' : entities, \n",
    "                              'entities_full_doc' : extract_entities_flair(doc_content, tagger_flair_ontonote, split_paragraph= False),\n",
    "                              'gold_labels' : gold_labels['labels'][doc_id] if doc_id in gold_labels['labels'] else {}}\n",
    "    dump(documents, \"data/labels_results/documents_flair_entities.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = documents['NP7dYhy+sWTjSoVq5wi4SQ==']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.26601941747572816, 0.06796116504854369)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime \n",
    "def is_valid_date(date_string):\n",
    "    try:\n",
    "        # Attempt to parse the date string\n",
    "        date = datetime.fromisoformat(date_string).strftime('%Y-%m-%d')\n",
    "        return date\n",
    "    except ValueError:\n",
    "        # If the parsing fails, it's not a valid date\n",
    "        return False\n",
    "    \n",
    "def is_float(value):\n",
    "    try:\n",
    "        float_string = value.replace(\"'\", \"\")\n",
    "        float_string = float_string.replace(\",\", \".\")\n",
    "        float_value = float(float_string)\n",
    "        return float_value\n",
    "    except ValueError:\n",
    "        return False\n",
    "    \n",
    "def is_int(value):\n",
    "    try:\n",
    "        int_string = value.replace(\"'\", \"\")\n",
    "        int_value = int(int_string)\n",
    "        return int_value\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def parse_values(value) :\n",
    "    date = is_valid_date(value)\n",
    "    if date :\n",
    "        return date\n",
    "\n",
    "    int_val = is_int(value)\n",
    "    if int_val :\n",
    "        return int_val\n",
    "    \n",
    "    float_val = is_float(value)\n",
    "    value = float_val if float_val else value\n",
    "\n",
    "    return value\n",
    "\n",
    "nb_value_checked, value_found_split, value_found_doc = {},{}, {}\n",
    "for doc_id, doc in documents.items():\n",
    "    entities = set([parse_values(ent) for ent, tag in doc['entities']])\n",
    "    entities_full_doc = set([parse_values(ent) for ent, tag in doc['entities_full_doc']])\n",
    "    gold_values = [(gold_label,parse_values(gold_value)) for gold_label, gold_value in doc['gold_labels'].items() \n",
    "                   if gold_label not in ['language', 'client', 'document type','immeuble']]\n",
    "\n",
    "    for gold_label, gold_value in gold_values :\n",
    "        value_split, value_doc = int(gold_value in entities), int(gold_value in entities_full_doc)\n",
    "        value_found_split[gold_label] = value_found_split[gold_label] + value_split if gold_label in value_found_split else value_split\n",
    "        value_found_doc[gold_label] = value_found_doc[gold_label] + value_doc if gold_label in value_found_doc else value_doc\n",
    "        nb_value_checked[gold_label] = nb_value_checked[gold_label] + 1 if gold_label in nb_value_checked else 1\n",
    "\n",
    "score_by_field_split = {key : val/nb_value_checked[key] for key, val in value_found_split.items()}\n",
    "score_by_field_doc = {key : val/nb_value_checked[key] for key, val in value_found_doc.items()}\n",
    "score_split = sum(value_found_split.values())/sum(nb_value_checked.values())\n",
    "score_doc = sum(value_found_doc.values())/sum(nb_value_checked.values())\n",
    "\n",
    "score_split,score_doc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

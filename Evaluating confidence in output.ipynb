{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm.LLMModel import *\n",
    "from ner.llm_ner.prompt_techniques.pt_multi_pt import PT_Multi_PT, PT_2Time_Tagger\n",
    "from ner.llm_ner.prompt_techniques.pt_discussion import PT_OutputList\n",
    "from ner.Datasets.Conll2003Dataset import Conll2003Dataset\n",
    "from ner.Datasets.MyDataset import MyDataset\n",
    "from ner.llm_ner.few_shots_techniques import *\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from ner.evaluating_confidence import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = MyDataset.my_load_dataset(dataset=Conll2003Dataset, split = 'train', cleaned= True)\n",
    "data_test =  MyDataset.my_load_dataset(dataset=Conll2003Dataset, split = 'test', cleaned= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MistralAI(llm_loader = Llama_LlamaCpp())\n",
    "fst = FST_Sentence(data_train, 3)\n",
    "multi_pt = PT_2Time_Tagger(fst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = data_test[18]\n",
    "logits_for_tags, output, index, values = get_logits_for_tags(sentence, model, pt = multi_pt)\n",
    "logits_for_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_tokens = list(model.model.model.eval_tokens)[-output['usage']['completion_tokens']:]\n",
    "generated_logits = list(model.model.model.eval_logits)[-output['usage']['completion_tokens']:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[logits[28753] for logits in generated_logits ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_for_tags = [{'gold_tag' : gold_tag, 'tags_logits': {tag: generated_logits[idx][mapping_letter_tokens[tag][1]] for tag in mapping_letter_tokens.keys()}} for idx, gold_tag in zip(index,values)]\n",
    "logits_for_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher n = 0 et n = 2 o√π LOC est attendu mais on donne du ORG\n",
    "n = 2\n",
    "sentence = data_test[n]['text']\n",
    "print(data_test[n]['text'])\n",
    "print(data_test[n]['spans'])\n",
    "get_logits_for_tags(sentence, model, pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Washington is the president of the United States\"\n",
    "sentence_o = \" [['Washington', 'LOC'], ['United States', 'LOC']] \"\n",
    "prompt = llama_ner.get_prompts(sentence=sentence, tags = [], n = 0)\n",
    "\n",
    "output = llm(prompt, stop = [\"<end_output>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ner.evaluating_confidence import get_logits_for_tags\n",
    "sentences = [\n",
    "    \"Washington is the president of the United States\",\n",
    "    \"John is an important person living in Paris\"\n",
    "]\n",
    "for sent in sentences :\n",
    "    print(get_logits_for_tags(sent, llm, llama_ner))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model.detokenize([464, 28753, 647])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model.model.tokenize(\"'World Cup': 'P'\".encode()))'World Cup': 'P'\n",
    "# print(model.model.tokenize(\"'World Cup': 'P'\".encode()))\n",
    "\n",
    "print(model.model.tokenize(\"'World Cup': 'P', \".encode()))\n",
    "print(model.model.tokenize(\"': 'M', \".encode()))\n",
    "print(model.model.tokenize(\": 'L', \".encode()))\n",
    "print(model.model.tokenize(\": 'O', \".encode()))\n",
    "print(model.model.tokenize(\": 'N', \".encode()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(model.model.eval_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model.model.detokenize(list(model.model.model.eval_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_data_for_confidence()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_test =  MyDataset.my_load_dataset(dataset=Conll2003Dataset, split = 'test', cleaned= True)\n",
    "data_test.select(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from ner.evaluating_confidence import *\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "all_data = load_generated_data_for_confidence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = [] # (right/false, confidence)\n",
    "for data_point in all_data:\n",
    "    for entity_point in data_point['logits_for_tags'] :\n",
    "        points.append(\n",
    "            (entity_point['gold tag'] == entity_point['outputted_tag'],\n",
    "            entity_point['confidence'][entity_point['outputted_tag']])\n",
    "        )\n",
    "true_values =  [pair[1] for pair in points if pair[0]]\n",
    "false_values = [pair[1] for pair in points if not pair[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Syria'\n",
    "[(data_point['text'], data_point['spans']) for data_point in data_test.dataset if text in data_point['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[[entity for entity in data['logits_for_tags'] if entity['gold tag'] != entity['outputted_tag'] ] for data in all_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_point in all_data:\n",
    "    gold_tags = {key.lower() : val for key, val in dict(data_point['spans']).items()}\n",
    "    for entity_point in data_point['logits_for_tags'] :\n",
    "        entity = entity_point['entity'][0].lower()\n",
    "        entity_point['gold tag'] = gold_tags[entity] if entity in gold_tags else 'None'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_point in all_data:\n",
    "    for entity_point in data_point['logits_for_tags'] :\n",
    "        entity_point = add_confidence_to_results(entity_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(*points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_confidence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dp in all_data:\n",
    "    for ent in dp['logits_for_tags'] :\n",
    "        ent = add_confidence_to_results(ent)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

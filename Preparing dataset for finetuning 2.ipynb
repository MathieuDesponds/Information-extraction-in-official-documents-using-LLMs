{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./ner/saves/datasets/ontonote5_test_1403.pkl\n",
      "./ner/saves/datasets/ontonote5_train_9873.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d942e292d3ab4fd4930940cde30f4f0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/9873 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "343it [05:26,  1.05it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/ubuntu/llm-project/Master-thesis/Preparing dataset for finetuning 2.ipynb Cell 1\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B194.182.171.183/home/ubuntu/llm-project/Master-thesis/Preparing%20dataset%20for%20finetuning%202.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mfor\u001b[39;00m plus_plus \u001b[39min\u001b[39;00m [\u001b[39mTrue\u001b[39;00m] :\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B194.182.171.183/home/ubuntu/llm-project/Master-thesis/Preparing%20dataset%20for%20finetuning%202.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m     \u001b[39m# PT_GPT_NER(None,plus_plus=plus_plus),\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B194.182.171.183/home/ubuntu/llm-project/Master-thesis/Preparing%20dataset%20for%20finetuning%202.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39mfor\u001b[39;00m pt \u001b[39min\u001b[39;00m [PT_Wrapper(\u001b[39mNone\u001b[39;00m,plus_plus\u001b[39m=\u001b[39mplus_plus), PT_Tagger(\u001b[39mNone\u001b[39;00m,plus_plus\u001b[39m=\u001b[39mplus_plus), PT_GetEntities(\u001b[39mNone\u001b[39;00m,plus_plus\u001b[39m=\u001b[39mplus_plus),  PT_OutputList(\u001b[39mNone\u001b[39;00m,plus_plus\u001b[39m=\u001b[39mplus_plus)] :\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B194.182.171.183/home/ubuntu/llm-project/Master-thesis/Preparing%20dataset%20for%20finetuning%202.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m         pt\u001b[39m.\u001b[39;49mprocess_dataset_for_finetuning(dataset \u001b[39m=\u001b[39;49m train, precision \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m++\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39mif\u001b[39;49;00m plus_plus \u001b[39melse\u001b[39;49;00m \u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m , runs \u001b[39m=\u001b[39;49m runs, fst \u001b[39m=\u001b[39;49m FST_Sentence,nb_few_shots \u001b[39m=\u001b[39;49m [\u001b[39m2\u001b[39;49m,\u001b[39m3\u001b[39;49m])\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B194.182.171.183/home/ubuntu/llm-project/Master-thesis/Preparing%20dataset%20for%20finetuning%202.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m         pt\u001b[39m.\u001b[39mprocess_dataset_for_finetuning(dataset \u001b[39m=\u001b[39m train, precision \u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m++_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m plus_plus \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mnoshots\u001b[39m\u001b[39m\"\u001b[39m, fst \u001b[39m=\u001b[39m FST_NoShots, runs \u001b[39m=\u001b[39m runs, nb_few_shots\u001b[39m=\u001b[39m[\u001b[39m0\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B194.182.171.183/home/ubuntu/llm-project/Master-thesis/Preparing%20dataset%20for%20finetuning%202.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m## Ou ## \u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B194.182.171.183/home/ubuntu/llm-project/Master-thesis/Preparing%20dataset%20for%20finetuning%202.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B194.182.171.183/home/ubuntu/llm-project/Master-thesis/Preparing%20dataset%20for%20finetuning%202.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m# plus_plus = False\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B194.182.171.183/home/ubuntu/llm-project/Master-thesis/Preparing%20dataset%20for%20finetuning%202.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39m# for pt in [PT_GPT_NER(None,plus_plus=plus_plus), PT_OutputList(None,plus_plus=plus_plus), PT_Wrapper(None,plus_plus=plus_plus), PT_Tagger(None,plus_plus=plus_plus), PT_GetEntities(None,plus_plus=plus_plus)] :\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B194.182.171.183/home/ubuntu/llm-project/Master-thesis/Preparing%20dataset%20for%20finetuning%202.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39m#     pt.process_dataset_for_finetuning(dataset = train, precision = \"noshots\", fst = FST_NoShots, runs = runs, nb_few_shots=[0])\u001b[39;00m\n",
      "File \u001b[0;32m~/llm-project/Master-thesis/ner/llm_ner/prompt_techniques/pt_abstract.py:106\u001b[0m, in \u001b[0;36mPromptTechnique.process_dataset_for_finetuning\u001b[0;34m(self, precision, dataset, fst, runs, save, test_size, nb_few_shots)\u001b[0m\n\u001b[1;32m    104\u001b[0m     data_tr_tr\u001b[39m.\u001b[39mselect(\u001b[39mrange\u001b[39m(\u001b[39m1600\u001b[39m))\n\u001b[1;32m    105\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfst \u001b[39m=\u001b[39m fst(data_tr_tr, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m--> 106\u001b[0m     processed_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprocess_dataset_for_finetuning_helper(data_tr_te, nb_few_shots)\n\u001b[1;32m    107\u001b[0m     all_datas\u001b[39m.\u001b[39mappend(processed_data)\n\u001b[1;32m    109\u001b[0m merged_datasets \u001b[39m=\u001b[39m concatenate_datasets(all_datas)\n",
      "File \u001b[0;32m~/llm-project/Master-thesis/ner/llm_ner/prompt_techniques/pt_abstract.py:123\u001b[0m, in \u001b[0;36mPromptTechnique.process_dataset_for_finetuning_helper\u001b[0;34m(self, dataset_test, nb_few_shots)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[39mfor\u001b[39;00m i, sample \u001b[39min\u001b[39;00m tqdm(\u001b[39menumerate\u001b[39m(dataset_test)) :\n\u001b[1;32m    122\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfst\u001b[39m.\u001b[39mnb_few_shots \u001b[39m=\u001b[39m random\u001b[39m.\u001b[39mchoice(nb_few_shots)\n\u001b[0;32m--> 123\u001b[0m     \u001b[39mfor\u001b[39;00m prompt, tag \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_prompts_runnable(sample[\u001b[39m'\u001b[39;49m\u001b[39mtext\u001b[39;49m\u001b[39m'\u001b[39;49m], tags \u001b[39m=\u001b[39;49m dataset_test\u001b[39m.\u001b[39;49mget_tags()):\n\u001b[1;32m    124\u001b[0m         gold \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_gold(dataset_test, tag)\n\u001b[1;32m    125\u001b[0m         output\u001b[39m.\u001b[39mappend({\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m : \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mprompt\u001b[39m}\u001b[39;00m\u001b[39m{\u001b[39;00mgold[i]\u001b[39m}\u001b[39;00m\u001b[39m <end_output>\u001b[39m\u001b[39m\"\u001b[39m})\n",
      "File \u001b[0;32m~/llm-project/Master-thesis/ner/llm_ner/prompt_techniques/pt_wrapper.py:27\u001b[0m, in \u001b[0;36mPT_Wrapper.get_prompts_runnable\u001b[0;34m(self, sentence, tags)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_prompts_runnable\u001b[39m(\u001b[39mself\u001b[39m, sentence, tags \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m---> 27\u001b[0m     nearest_neighbors \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfst\u001b[39m.\u001b[39;49mget_nearest_neighbors(sentence)\n\u001b[1;32m     28\u001b[0m     prompt \u001b[39m=\u001b[39m  \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprompt_template[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__str__\u001b[39m()]\u001b[39m.\u001b[39mformat(sentence \u001b[39m=\u001b[39m sentence,\n\u001b[1;32m     29\u001b[0m                                         few_shots \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_few_shots(sentence, [], nearest_neighbors),\n\u001b[1;32m     30\u001b[0m                                         precisions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_precision())\n\u001b[1;32m     31\u001b[0m     \u001b[39mreturn\u001b[39;00m [(prompt, \u001b[39m\"\u001b[39m\u001b[39mNone\u001b[39m\u001b[39m\"\u001b[39m)]\n",
      "File \u001b[0;32m~/llm-project/Master-thesis/ner/llm_ner/few_shots_techniques.py:75\u001b[0m, in \u001b[0;36mFST_Sentence.get_nearest_neighbors\u001b[0;34m(self, sentence)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfew_shots_save[sentence][:\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnb_few_shots]\n\u001b[1;32m     74\u001b[0m sentence_embedding \u001b[39m=\u001b[39m sentence_transformer\u001b[39m.\u001b[39mencode(sentence)\n\u001b[0;32m---> 75\u001b[0m similarities \u001b[39m=\u001b[39m cosine_similarity([sentence_embedding], \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_dataset[\u001b[39m'\u001b[39;49m\u001b[39msentence_embedding\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m     76\u001b[0m top_k_indices \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margsort(similarities[\u001b[39m0\u001b[39m])[\u001b[39m-\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnb_few_shots:][::\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m     77\u001b[0m nearest_neighbors \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_dataset[\u001b[39mint\u001b[39m(i)] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mlist\u001b[39m(top_k_indices)]\n",
      "File \u001b[0;32m~/llm-project/Master-thesis/ner/Datasets/MyDataset.py:13\u001b[0m, in \u001b[0;36mMyDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, idx):\n\u001b[0;32m---> 13\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py:2803\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2801\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, key):  \u001b[39m# noqa: F811\u001b[39;00m\n\u001b[1;32m   2802\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2803\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem(key)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py:2788\u001b[0m, in \u001b[0;36mDataset._getitem\u001b[0;34m(self, key, **kwargs)\u001b[0m\n\u001b[1;32m   2786\u001b[0m formatter \u001b[39m=\u001b[39m get_formatter(format_type, features\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info\u001b[39m.\u001b[39mfeatures, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mformat_kwargs)\n\u001b[1;32m   2787\u001b[0m pa_subtable \u001b[39m=\u001b[39m query_table(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data, key, indices\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_indices \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_indices \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m-> 2788\u001b[0m formatted_output \u001b[39m=\u001b[39m format_table(\n\u001b[1;32m   2789\u001b[0m     pa_subtable, key, formatter\u001b[39m=\u001b[39;49mformatter, format_columns\u001b[39m=\u001b[39;49mformat_columns, output_all_columns\u001b[39m=\u001b[39;49moutput_all_columns\n\u001b[1;32m   2790\u001b[0m )\n\u001b[1;32m   2791\u001b[0m \u001b[39mreturn\u001b[39;00m formatted_output\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/formatting/formatting.py:629\u001b[0m, in \u001b[0;36mformat_table\u001b[0;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n\u001b[1;32m    627\u001b[0m python_formatter \u001b[39m=\u001b[39m PythonFormatter(features\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    628\u001b[0m \u001b[39mif\u001b[39;00m format_columns \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 629\u001b[0m     \u001b[39mreturn\u001b[39;00m formatter(pa_table, query_type\u001b[39m=\u001b[39;49mquery_type)\n\u001b[1;32m    630\u001b[0m \u001b[39melif\u001b[39;00m query_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcolumn\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    631\u001b[0m     \u001b[39mif\u001b[39;00m key \u001b[39min\u001b[39;00m format_columns:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/formatting/formatting.py:398\u001b[0m, in \u001b[0;36mFormatter.__call__\u001b[0;34m(self, pa_table, query_type)\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mformat_row(pa_table)\n\u001b[1;32m    397\u001b[0m \u001b[39melif\u001b[39;00m query_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcolumn\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 398\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mformat_column(pa_table)\n\u001b[1;32m    399\u001b[0m \u001b[39melif\u001b[39;00m query_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbatch\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    400\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mformat_batch(pa_table)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/formatting/formatting.py:441\u001b[0m, in \u001b[0;36mPythonFormatter.format_column\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mformat_column\u001b[39m(\u001b[39mself\u001b[39m, pa_table: pa\u001b[39m.\u001b[39mTable) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mlist\u001b[39m:\n\u001b[0;32m--> 441\u001b[0m     column \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpython_arrow_extractor()\u001b[39m.\u001b[39;49mextract_column(pa_table)\n\u001b[1;32m    442\u001b[0m     column \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpython_features_decoder\u001b[39m.\u001b[39mdecode_column(column, pa_table\u001b[39m.\u001b[39mcolumn_names[\u001b[39m0\u001b[39m])\n\u001b[1;32m    443\u001b[0m     \u001b[39mreturn\u001b[39;00m column\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/formatting/formatting.py:147\u001b[0m, in \u001b[0;36mPythonArrowExtractor.extract_column\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mextract_column\u001b[39m(\u001b[39mself\u001b[39m, pa_table: pa\u001b[39m.\u001b[39mTable) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mlist\u001b[39m:\n\u001b[0;32m--> 147\u001b[0m     \u001b[39mreturn\u001b[39;00m pa_table\u001b[39m.\u001b[39;49mcolumn(\u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49mto_pylist()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from ner.llm_ner.prompt_techniques.pt_abstract import PromptTechnique\n",
    "from ner.llm_ner.prompt_techniques.pt_discussion import PT_OutputList\n",
    "from ner.llm_ner.prompt_techniques.pt_gpt_ner import PT_GPT_NER\n",
    "from ner.llm_ner.prompt_techniques.pt_wrapper import PT_Wrapper\n",
    "from ner.llm_ner.prompt_techniques.pt_multi_pt import PT_Multi_PT, PT_2Time_Tagger\n",
    "from ner.llm_ner.prompt_techniques.pt_tagger import PT_Tagger\n",
    "from ner.llm_ner.prompt_techniques.pt_get_entities import PT_GetEntities\n",
    "from ner.llm_ner.few_shots_techniques import *\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from ner.Datasets.OntoNotes5Dataset import OntoNote5Dataset\n",
    "train, test = OntoNote5Dataset.my_load_dataset()\n",
    "\n",
    "runs = 2000\n",
    "for plus_plus in [True] :\n",
    "    # PT_GPT_NER(None,plus_plus=plus_plus),\n",
    "    for pt in [PT_Wrapper(None,plus_plus=plus_plus), PT_Tagger(None,plus_plus=plus_plus), PT_GetEntities(None,plus_plus=plus_plus),  PT_OutputList(None,plus_plus=plus_plus)] :\n",
    "        pt.process_dataset_for_finetuning(dataset = train, precision = \"++\" if plus_plus else \"\" , runs = runs, fst = FST_Sentence,nb_few_shots = [2,3])\n",
    "        pt.process_dataset_for_finetuning(dataset = train, precision = (\"++_\" if plus_plus else \"\") + \"noshots\", fst = FST_NoShots, runs = runs, nb_few_shots=[0])\n",
    "\n",
    "## Ou ## \n",
    "\n",
    "# plus_plus = False\n",
    "# for pt in [PT_GPT_NER(None,plus_plus=plus_plus), PT_OutputList(None,plus_plus=plus_plus), PT_Wrapper(None,plus_plus=plus_plus), PT_Tagger(None,plus_plus=plus_plus), PT_GetEntities(None,plus_plus=plus_plus)] :\n",
    "#     print(pt)\n",
    "#     pt.process_dataset_for_finetuning(dataset = train, precision = \"\" , runs = runs)\n",
    "#     pt.process_dataset_for_finetuning(dataset = train, precision = \"noshots\", fst = FST_NoShots, runs = runs, nb_few_shots=[0])\n",
    "\n",
    "# plus_plus = True\n",
    "# for pt in [PT_GPT_NER(None,plus_plus=plus_plus), PT_OutputList(None,plus_plus=plus_plus), PT_Wrapper(None,plus_plus=plus_plus), PT_Tagger(None,plus_plus=plus_plus), PT_GetEntities(None,plus_plus=plus_plus)] :\n",
    "#     pt.process_dataset_for_finetuning(dataset = train, precision = \"noshots\", fst = FST_NoShots, runs = runs, nb_few_shots=[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
